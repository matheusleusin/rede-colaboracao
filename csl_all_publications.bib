@comment{List of conferences:
  ACII2013 => 
    Affective BCI Workshop, International Conference on Affective Computing and Intelligent Interaction, Geneva, Switzerland
  ACL 2013 =>
    The 51st Annual Meeting of the Association for Computational Linguistics, Sofia, Bulgaria
  AMTA 2008 =>
    Eighth Conference of the Association for Machine Translation in the Americas, Waikiki, Hawai'i
  Biodevices 2019 =>
    12th International Conference on Biomedical Electronics and Devices
  Biosignals 2008 =>
    1st International Conference on Bio-inspired Systems and Signal Processing, Madeira, Portugal
  Biosignals 2009 =>
    2nd International Conference on Bio-inspired Systems and Signal Processing, Porto, Portugal
  BIOSIGNALS 2012 =>
    5th International Conference on Bio-inspired Systems and Signal Processing
  BIOSIGNALS 2013 =>
    6th International Conference on Bio-inspired Systems and Signal Processing
  BIOSIGNALS 2014 =>
    7th International Conference on Bio-inspired Systems and Signal Processing
  BIOSIGNALS 2015 =>
    8th International Conference on Bio-inspired Systems and Signal Processing
  BIOSIGNALS 2018 =>
    11th International Conference on Bio-inspired Systems and Signal Processing, Madeira, Portugal
  CHISIG =>
    23nd conference of the computer-human interaction special interest group of Australia on Computer-human interaction: design (OZCHI 2009), Melbourne, Australia
  EMBC 2014 =>
    36th Annual International Conference of the IEEE Engineering in Medicine  and Biology Society
  EMBC'12 =>
    International Conference of the IEEE Engineering in Medicine and Biology Society, San Diego, USA
  EMBC'13 =>
    International Conference of the IEEE Engineering in Medicine and Biology Society, Osaka, Japan
    International Conference of the IEEE Engineering in Medicine and Biology Society, Osaka, Japan
    International Conference of the IEEE Engineering in Medicine and Biology Society, Osaka, Japan
  IALP =>
    The International Conference on Asian Language Processing, Hanoi, Vietnam
  ICASSP =>
    IEEE International Conference on Acoustics, Speech and Signal Processing
  ICASSP 2012 =>
    37th International Conference on Acoustics, Speech, and Signal Processing, Kyoto, Japan
  ICASSP 2013 =>
    The 38th International Conference on Acoustics, Speech, and Signal Processing
  ICASSP 2014 =>
    International Conference on Acoustics, Speech, and Signal Processing
    The 39th International Conference on Acoustics, Speech, and Signal Processing
  ICASSP 2015 =>
    The 40th International Conference on Acoustics, Speech, and Signal Processing, Brisbane, Australia
  ICMI'14 =>
    14th ACM International Conference on Multimodal Interaction
  ICONIP 2012 =>
    19th International Conference on Neural Information Processing, Doha, Qatar
  Interspeech 2010 =>
    11th Annual Conference of the International Speech Communication Association, Makuhari, Japan
    11th Annual Conference of the International Speech Communication Association, Makuhari, Japan
  Interspeech 2012 =>
    13th Annual Conference of the International Speech Communication Association, Portland, Oregon
  Interspeech 2013 =>
    14th Annual Conference of the International Speech Communication Association, Lyon, France
  Interspeech 2014 =>
    The 15th Annual Conference of the International     Speech Communication Association, Singapore
    The 15th Annual Conference of the International Speech Communication Association, Singapore
  ISWC '12 =>
    16th International Symposium on Wearable Computers
  IUI '12 =>
    International Conference on Intelligent User Interfaces
  IWSLT 2011 =>
    The International Workshop on Spoken Language Translation, San Francisco, USA
  JEP =>
    Journies d'E'tude sur la Parole Invited paper and keynote talk
  LREC 2014 =>
    The 9th edition of the Language Resources and Evaluation Conference, Reykjavik, Iceland
  MLMI =>
    4th Joint Workshop on Machine Learning and Multimodal Interaction, Lecture Notes in Computer Science
  Multimedia Interaction Human Machine Interface =>
    Proceedings of ICME
  Side event of Biosignals 2010 conference =>
    First International Workshop on Bio-inspired Human-Machine Interfaces and Healthcare Applications
  SLSP 2013 =>
    The 1st International Conference on Statistical Language and Speech Processing
  SLT 2012 =>
    The Fourth IEEE Workshop on Spoken Language Technology
  SLTU 2014 =>
    The 4th Workshop on Spoken Language Technologies for Under-resourced Languages, St. Petersburg, Russia
  SLTU'12 =>
    The third International Workshop on Spoken Languages Technologies for Under-resourced Languages
    The third International Workshop on Spoken Languages Technologies for Under-resourced Languages, Cape Town, South Africa
  UbiComp 2013 =>
    2013 ACM International Joint Conference on Pervasive and Ubiquitous Computing
  und Kommunikationstechnologien in der Sportmotorik, 11. Tagung der dvs-Sektion Sportmotorik =>
    Informations
  VISAPP 2012 =>
    International Conference on Computer Vision Theory and Applications 2012
}

@comment{List of conferences with no shortname:
  1. Fachtagung Biophysiologische Interfaces
  10th Annual Conference of the International Speech Communication Association
  11th Annual Conference of the International Speech Communication Association
  14th Annual Conference of the International Speech Communication Association, Lyon, France
  155th Meeting of the Acoustical Society of America
  15th European Signal Processing Conference
  16th International Congress of Phonetic Sciences
  18th IEEE International Symposium on Robot and Human Interactive Communication
  1999 Proceedings of the International Conference on Speech Processing
  19th International Conference on Pattern Recognition
  1st International Workshop on Spoken Dialog Systems
  2009 International Conference on Affective Computing & Intelligent Interaction
  20th International Conference on Pattern Recognition
  21st Swedish Phonetics Conference
  2nd International Conference on Multi-modal Interfaces
  2nd Workshop on Spoken Languages Technologies for Under-resourced Languages
  33rd Annual German Conference on Artificial Intelligence 2010
  33rd IEEE International Conference on Acoustics, Speech, and Signal Processing
  4th Biennial Workshop on DSP for In-Vehicle Systems and Safety
  4th International Conference on Applied Human Factors and Ergonomics
  4th International Conference on Speech Prosody
  5th Joint Workshop on Multimodal Interaction and Related Machine Learning Algorithms
  6th International Conference on Language Resources and Evaluation
  8th IEEE-RAS International Conference on Humanoid Robots, Workshop Imitation and Coaching in Humanoid Robots
  9th Annual Conference of the International Speech Communication Association
  9th IEEE-RAS International Conference on Humanoid Robots, Workshop Imitation and Coaching in Humanoid Robots
  9th SIGdial Workshop on Discourse and Dialogue
  Adaptation for Speech Processing Systems
  Affective Computing and Intelligent Interaction 2011, ACII 2011
  ARPA Workshop on Speech and Natural Language Technology
  Automatic Speech Recognition and Understanding
  Biomechanik â Grundlagenforschung und Anwendung, Tagung der dvs-Sektion Biomechanik
  Computers, Linguistics, and Phonetics between Language and Speech. Proceedings of the 4th Conference on NLP
  Conference on Speech and Language Systems for Human Communication
  Continuous Speech Recognition Systems
  diverse Workshops 2007
  EARS Rich Transcription Workshop
  Elektronische Sprachsignalverarbeitung ESSV
  First Augmented Human International Conference
  French-German Workshop on Humanoid and Legged Robots, HLR 2006
  Human Language Technology & North American Chapter of the Association for Computational Linguistics
  Human Language Technology Conference
  ICASSP
  IEEE International Conference on Acoustics, Speech and Signal Processing
  IEEE Workshop on Spoken Language Technology
  IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS 2011
  In proceedings of the 19th Swedish Phonetics Conference
  In proceedings of the 5th ELRA International Conference on Language Resources and Evaluation
  In proceedings of the 5th Slovenian and 1st International Language Technologies Conference
  In proceedings of the 8th ISCA/ACL SIGdial Workshop on Discourse and Dialogue
  In proceedings of the 9th ISCA International Conference on Spoken Language Processing
  International BCI Meeting 2013, Asilomar, USA
  International BCI Meeting 2013, Asilomar, USA
  International Conference of Spoken Language Processing
  International Conference on Bio-inspired Systems and Signal Processing
  International Conference on Bio-inspired Systems and Signal Processing 2013
  International Conference on Intelligent User Interfaces 2013, Santa Monica, USA
  International Conference on Multimodal Interaction, ICMI 2011
  International Conference on Multimodal Interfaces
  International Conference on Social Robotics
  International IEEE EMBS Neural Engineering Conference 2013, San Diego, USA
  International Workshop on East-Asien Language Resources and Evaluation
  International Workshop on Spoken Langage Translation
  Interspeech 2010
  Interspeech 2011
  Invited keynote talk at the ISCA Tutorial and Research Workshop on Multilingual Speech and Language Processing
  Invited paper, Special Session on Multilinguality in Speech Processing, Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing
  Landessymposium
  Multilingual Information Retrieval Dialogs: 2nd SQEL Workshop
  Neural Information Processing Systems
  NIST Meeting Recognition Workshop
  NIST SRE Workshop 2008
  Non-native Speech
  Nordic Prosody X
  Panel Session on Automatic Speech Recognition and Understanding
  Presented at the 3rd Joint Workshop on Multimodal Interaction and Related Machine Learning Algorithms
  Proceedings of 2014 APSIPA Annual Summit and Conference
  Proceedings of ACL
  Proceedings of International Workshop of Spoken Language Translation
  Proceedings of Interspeech
  Proceedings of the 1st Workshop on Text, Speech, and Dialogue, ; TSD
  Proceedings of the 3rd Conference on Natural Language Processing and Speech Technology
  Proceedings of the 5th European Conference on Speech Communication and Technology, Vol. 1
  Proceedings of the 6th European Conference on Speech Communication and Technology
  Proceedings of the 7th European Conference on Speech Communication and Technology
  Proceedings of the 8th European Conference on Speech Communication and Technology
  Proceedings of the Automatic Speech Recognition and Understanding Workshop
  Proceedings of the DARPA Broadcast News Transcription and Understanding
  Proceedings of the Eurospeech
  Proceedings of the HLT-NAACL 2007
  Proceedings of the Human Language Technologies
  Proceedings of the Human Language Technology Meeting
  Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing
  Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, Vol. 1
  Proceedings of the International Conference of Spoken Language Processing
  Proceedings of the International Conference of Spoken Language Processing , Vol. 5
  Proceedings of the International Conference on Multimodal Input
  Proceedings of the International Conference on Multimodal Interfaces
  Proceedings of the ISCA Tutorial and Researc Workshop on Multilingual Speech and Language Processing
  Proceedings of the Speech Research Symposium SRS XV
  Proceedings of the Speech-to-Speech Translation Workshop on the 40th Anniversary Meeting of the Association for Computational Linguistics
  Proceedings of the Workshop of Automatic Speech Recognition Understanding
  Proceedings of the Workshop on Hands-Free Speech Communication
  Proceedings of the Workshop on Multilingual Speech Communication
  SLTU: Workshop on Spoken Language Technologies for Under-Resourced Languages
  SPECOM Speech and Computer
  Sportinformatik trifft Sporttechnologie, Tagung der dvs-Sektion Sportinformatik in Kooperation mit der deutschen interdisziplin
  Sportinformatik trifft Sporttechnologie, Tagung der dvs-Sektion Sportinformatik in Kooperation mit der Deutschen Interdisziplinären Vereinigung für Sporttechnologie
  Workshop on Multi-lingual Interoperability in Speech Technology
  Workshop on Speech and Communication
}

@mastersthesis{zahner2014konvertierung,
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/MA_Zahner_Druckversion_bunt_korrigiert.pdf},
  school={Karlsruher Institut für Technologie},
  title={Konvertierung von myoelektrischen Signalen der Gesichtsmuskulatur zu Sprache: Ein Unit Selection-Ansatz},
  year={2014},
  supervisor={Wand, Michael and Janke, Matthias and Schultz, Tanja},
  author={Zahner, Marlene},
  abstract={In dieser Masterarbeit wird ein neuer Ansatz zur Konvertierung von Muskelsignalen zu hörbarer Sprache vorgestellt. Allein die elektrischen Signale der Gesichtsmuskulatur werden mittels Oberflächenelektroden aufgezeichnet, ohne dass der Sprecher hörbare Laute artikulieren muss. Anschließend werden die Signale in kurze Abschnitte unterteilt und mit bereits aufgezeichneten EMG-Signalen verglichen, die wiederum mit Sprachsegmenten verknüpft sind. Die gewählten Sprachsegmente werden dann erneut zu Sprache zusammengesetzt. Diese Vorgehensweise des Wählens und Zusammensetzens bereits vorhandener Sprachabschnitte wird Unit Selection genannt. Der Vorteil, Muskelsignale in Sprache umzuwandeln liegt darin, dass man auch in lauten Umgebungen oder für einen Sprecher mit Sprachbehinderungen hörbare akustische Signale erzeugen kann, die zu einem bestimmten Empfänger geleitet werden können. Beistehende werden hierbei nicht belästigt und die Privatsphäre wird ebenfalls gewahrt. Frühere Experimente haben die Machbarkeit der Umwandlung myoelektrischer Signale zu Sprache gezeigt, jedoch existieren Probleme vor allem bei der Natürlichkeit der erzeugten Sprache. Durch das hier vorgestellte Verfahren sollen sowohl Verstäandlichkeit als auch Natürlichkeit der konvertierten Sprache gegenüber bereits existierenden Ansätzen verbessert werden. Die Evaluation der konvertierten Sprache zeigt in einer objektiven Evaluationsmethode eine Steigerung von durchschnittlich 13% gegenüber einem bereits existierenden Ansatz. Ein Hörtest zur subjektiven Bewertung der Natürlichkeit bestätigt ebenfalls die Verbesserung der konvertierten Sprache durch den hier vorgestellten Ansatz.}
}

@mastersthesis{diener2015improving,
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/diener2015improving.pdf},
  school={Karlsruher Institut für Technologie},
  title={Improving Unit Selection based EMG-to-Speech Conversion},
  year={2015},
  supervisor={Janke, Matthias and Schultz, Tanja},
  author={Diener, Lorenz},
  abstract={This master’s thesis introduces a new approach to improve the unit-selection based conversion of facial myoelectric signals to audible speech. Surface electromyography is the recording of electric signals generated by muscle activity using surface electrodes attached to the skin. Past work has shown that it is feasible to generate audible speech signals from facial electromyographic activity generated during speech production, using several different approaches. This work focuses on the unit-selection approach to conversion, where the speech signal is reconstructed by concatenating pieces of target audio data selected by a similarity criterion calculated on the parallel sequence of source electromyographic data. A novel approach, based on optimizing the database that units are selected from by using unit clustering to generate more prototypical units and improve the selection process, is introduced and evaluated. In total, we obtain a qualitative improvement of up to 14.92 percent relative over a baseline unit selection system, while improving the time taken for conversion by up to 98%.}
}
@phdthesis{herff2016speech,
  school={University of Bremen},
  title={Speech Processes for Brain-Computer Interfaces},
  year={2016},
  supervisor={Schultz, Tanja and Krusienski, Dean J},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Herff2016Diss.pdf},
  author={Herff, Christian}
}
@article{doi:10.1080/2326263X.2016.1275488,
author = {Jane E. Huggins and Christoph Guger and Mounia Ziat and Thorsten O. Zander and Denise Taylor and Michael Tangermann and Aureli Soria-Frisch and John Simeral and Reinhold Scherer and Rüdiger Rupp and Giulio Ruffini and Douglas K. R. Robinson and Nick F. Ramsey and Anton Nijholt and Gernot Müller-Putz and Dennis J. McFarland and Donatella Mattia and Brent J. Lance and Pieter-Jan Kindermans and Iñaki Iturrate and Christian Herff and Disha Gupta and An H. Do and Jennifer L. Collinger and Ricardo Chavarriaga and Steven M. Chase and Martin G. Bleichner and Aaron Batista and Charles W. Anderson and Erik J. Aarnoutse},
title = {Workshops of the Sixth International Brain–Computer Interface Meeting: brain–computer interfaces past, present, and future},
journal = {Brain-Computer Interfaces},
volume = {4},
number = {1-2},
pages = {3-36},
year = {2017},
doi = {10.1080/2326263X.2016.1275488},
url={https://www.csl.uni-bremen.de/cms/images/documents/publications/bci_workshops.pdf},
eprint = {http://dx.doi.org/10.1080/2326263X.2016.1275488}
}
@inproceedings{herff2017NAT,
  title={EVALUATING FNIRS-BASED WORKLOAD DISCRIMINATION IN A REALISTIC DRIVING SCENARIO},
  year={2017},
  booktitle={The First Biannual Neuroadaptive Technology Conference},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/NAT2017_cherff.pdf},
  author={Herff, Christian and Putze, Felix and Schultz, Tanja},
}
@inproceedings{herff2017musicBCI,
  title={Signal Characterization for a Musical Rhythm BCI},
  year={2017},
  booktitle={Engineering in Medicine and Biology Society (EMBC), 2016 39th Annual International Conference of the IEEE},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Herff2017MusicBCI.pdf},
  author={Herff, Steffen A. and Johnson, Garett D. and Milne, Andrew J. and Herff, Christian and Kim, Jee H. and Shih, Jerry J. and Krusienski, Dean J.},
}
@Inbook{Herff2017Award,
author={Herff, Christian and de Pesters, Adriana and Heger, Dominic and Brunner, Peter and Schalk, Gerwin and Schultz, Tanja},
editor={Guger, Christoph and Allison, Brendan and Ushiba, Junichi},
title={Towards Continuous Speech Recognition for BCI},
bookTitle={Brain-Computer Interface Research: A State-of-the-Art Summary 5},
year={2017},
publisher={Springer International Publishing},
address={Cham},
pages={21--29},
isbn={978-3-319-57132-4},
doi={10.1007/978-3-319-57132-4_3},
url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Herff2017Award.pdf}
}

@ARTICLE{Herff2016Review,
AUTHOR={Herff, Christian and Schultz, Tanja},
TITLE={Automatic Speech Recognition from Neural Signals: A Focused Review},
JOURNAL={Frontiers in Neuroscience},
VOLUME={10},
PAGES={429},
YEAR={2016},
url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Herff2016Review.pdf},
DOI={10.3389/fnins.2016.00429},
ISSN={1662-453X},
ABSTRACT={Speech interfaces have become widely accepted and are nowadays integrated in various real-life applications and devices. They have become a part of our daily life. However, speech interfaces presume the ability to produce intelligible speech, which might be impossible due to either loud environments, bothering bystanders or incapabilities to produce speech (i.e.~patients suffering from locked-in syndrome). For these reasons it would be highly desirable to not speak but to simply envision oneself to say words or sentences. Interfaces based on imagined speech would enable fast and natural communication without the need for audible speech and would give a voice to otherwise mute people.

This focused review analyzes the potential of different brain imaging techniques to recognize speech from neural signals by applying Automatic Speech Recognition technology. We argue that modalities based on metabolic processes, such as functional Near Infrared Spectroscopy and functional Magnetic Resonance Imaging, are less suited for Automatic Speech Recognition from neural signals due to low temporal resolution but are very useful for the investigation of the underlying neural mechanisms involved in speech processes. In contrast, electrophysiologic activity is fast enough to capture speech processes and is therefor better suited for ASR. Our experimental results indicate the potential of these signals for speech recognition from neural data with a focus on invasively measured brain activity (electrocorticography). As a first example of Automatic Speech Recognition techniques used from neural signals, we discuss the \emph{Brain-to-text} system.}
}
@INPROCEEDINGS{HerffEMBC2016,
author={Herff, C. and Johnson, G. and Diener, L. and Shih, J. and Krusienski, D. and Schultz, T.},
booktitle={Engineering in Medicine and Biology Society (EMBC), 2016 38th Annual International Conference of the IEEE},
title={Towards direct speech synthesis from ECoG: A pilot study},
year={2016},
url={https://www.csl.uni-bremen.de/cms/images/documents/publications/HerffEMBC_16.pdf},
poster={http://www.csl.uni-bremen.de/cms/images/documents/publications/Herff_EMBC16_poster.pdf},
month={Aug},
abstract={Most current Brain-Computer Interfaces (BCIs) achieve high information transfer rates using spelling paradigms based on stimulus-evoked potentials. Despite the success of this interfaces, this mode of communication can be cumbersome and unnatural. Direct synthesis of speech from neural activity represents a more natural mode of communi- cation that would enable users to convey verbal messages in real-time. In this pilot study with one participant, we demonstrate that electrocoticography (ECoG) intracranial activity from temporal areas can be used to resynthesize speech in real-time. This is accomplished by reconstructing the audio magnitude spectrogram from neural activity and subsequently creating the audio waveform from these reconstructed spectrograms. We show that significant correlations between the original and reconstructed spectrograms and temporal waveforms can be achieved. While this pilot study uses audibly spoken speech for the models, it represents a first step towards speech synthesis from speech imagery.}
}
@INPROCEEDINGS{diener2016initial,
author={Diener, L. and Herff, C. and Janke, M. and Schultz, T.},
booktitle={Engineering in Medicine and Biology Society (EMBC), 2016 38th Annual International Conference of the IEEE},
title={An Initial Investigation into the Real-Time Conversion of Facial Surface EMG Signals to Audible Speech},
year={2016},
url={https://www.csl.uni-bremen.de/cms/images/documents/publications/DienerEMBC_16.pdf},
poster={http://www.csl.uni-bremen.de/cms/images/documents/publications/DienerEMBC_16_poster.pdf},
month={Aug},
abstract={This paper presents early-stage results of our investigations into the direct conversion of facial surface electromyographic (EMG) signals into audible speech in a real-time setting, enabling novel avenues for research and system improvement through real-time feedback. The system uses a pipeline approach to enable online acquisition of EMG data, extraction of EMG features, mapping of EMG features to audio features, synthesis of audio waveforms from audio features and output of the audio waveforms via speakers or headphones. Our system allows for performing EMG-to-Speech conversion with low latency and on a continuous stream of EMG data, enabling near instantaneous audio output during audible as well as silent speech production. In this paper, we present an analysis of our systems components for latency incurred, as well as the trade-offs between conversion quality, latency and training duration required.}
}
@inproceedings{herff2016music,
  title={Music rhythm reconstruction from ECoG},
  year={2016},
  booktitle={International BCI Meeting 2016, Asilomar, USA},
  doi={10.3217/978-3-85125-467-9-212},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Herff_BCIMeeting16.pdf},
  author={Herff, Christian and Johnson, Garett and Shih, Jerry and Schultz, Tanja and Krusienski, Dean},
}
@ARTICLE{10.3389/fnhum.2015.00617,
 AUTHOR={Von Lühmann, Alexander  and  Herff, Christian  and  Heger, Dominic  and  Schultz, Tanja},
TITLE={Towards a wireless open source instrument:functional Near-Infrared Spectroscopy in mobile neuroergonomics and BCI applications},
JOURNAL={Frontiers in Human Neuroscience},
VOLUME={9},
YEAR={2015},
NUMBER={617},
URL={http://www.frontiersin.org/human_neuroscience/10.3389/fnhum.2015.00617/abstract},
DOI={10.3389/fnhum.2015.00617},
url={https://www.csl.uni-bremen.de/cms/images/documents/publications/fnhum-09-00617.pdf},
ISSN={1662-5161},
ABSTRACT={Brain-Computer Interfaces (BCIs) and neuroergonomics research have high requirements regarding robustness and mobility. Additionally, fast applicability and customization are desired. Functional Near-Infrared Spectroscopy (fNIRS) is an increasingly established technology with a potential to satisfy these conditions. EEG acquisition technology, currently one of the main modalities used for mobile brain activity assessment, is widely spread and open for access and thus easily customizable. fNIRS technology on the other hand has either to be bought as a predefined commercial solution or developed from scratch using published literature. To help reducing time and effort of future custom designs for research purposes, we present our approach toward an open source multichannel stand-alone fNIRS instrument for mobile NIRS-based neuroimaging, neuroergonomics and BCI/BMI applications. The instrument is low-cost, miniaturized, wireless and modular and openly documented on www.opennirs.org. It provides features such as scalable channel number, configurable regulated light intensities, programmable gain and lock-in amplification. In this paper, the system concept, hardware, software and mechanical implementation of the lightweight stand-alone instrument are presented and the evaluation and verification results of the instrument's hardware and physiological fNIRS functionality are described. Its capability to measure brain activity is demonstrated by qualitative signal assessments and a quantitative mental arithmetic based BCI study with 12 subjects.}}

@inproceedings{heger2015continuous,
  title={Continuous Speech Recognition from ECoG},
  author={Heger, Dominic and Herff, Christian and Pesters, Adriana de and Telaar, Dominic and Brunner, Peter and Schalk, Gerwin and Schultz, Tanja},
  booktitle={Sixteenth Annual Conference of the International Speech Communication Association},
  year={2015},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/IS2015_brain2text.pdf},
  abstract={Continuous speech production is a highly complex process involving many parts of the human brain. To date, no fundamental representation that allows for decoding of continuous speech from neural signals has been presented. Here we show that techniques from automatic speech recognition can be applied to decode a textual representation of spoken words from neural signals. We model phones as the fundamental unit of the speech process in invasively measured brain activity (intracranial electrocorticographic (ECoG)) recordings. These phone models give insights into timings and locations of neural processes associated with the continuous production of speech and can be used in a speech recognizer to decode the neural data into their textual representations. When restricting the dictionary to small subsets, Word Error Rates as low as 25% can be achieved. As the brain activity data sets are fairly small, alternative approaches to Gaussian models are investigated by relying on robust, regularized discriminative models.}
}

@article{thurer_increased_2015,
	title = {Increased gamma band power during movement planning coincides with motor memory retrieval},
	issn = {1095-9572},
	doi = {10.1016/j.neuroimage.2015.10.008},
	abstract = {The retrieval of motor memory requires a previous memory encoding and subsequent consolidation of the specific motor memory. Previous work showed that motor memory seems to rely on different memory components (e.g., implicit, explicit). However, it is still unknown if explicit components contribute to the retrieval of motor memories formed by dynamic adaptation tasks and which neural correlates are linked to memory retrieval. We investigated the lower and higher gamma bands of subjects' electroencephalography during encoding and retrieval of a dynamic adaptation task. A total of 24 subjects were randomly assigned to a treatment and control group. Both groups adapted to a force field A on day 1 and were re-exposed to the same force field A on day 3 of the experiment. On day 2, treatment group learned an interfering force field B whereas control group had a day rest. Kinematic analyses showed that control group improved their initial motor performance from day 1 to day 3 but treatment group did not. This behavioral result coincided with an increased higher gamma band power in the electrodes over prefrontal areas on the initial trials of day 3 for control but not treatment group. Intriguingly, this effect vanished with the subsequent re-adaptation on day 3. We suggest that improved re-test performance in a dynamic motor adaptation task is contributed by explicit memory and that gamma bands in the electrodes over the prefrontal cortex are linked to these explicit components. Furthermore, we suggest that the contribution of explicit memory vanishes with the subsequent re-adaptation while task automaticity increases.},
	language = {ENG},
	journal = {NeuroImage},
	author = {Thürer, Benjamin and Stockinger, Christian and Focke, Anne and Putze, Felix and Schultz, Tanja and Stein, Thorsten},
	month = oct,
	year = {2015},
	pmid = {26458517},
	keywords = {Consolidation, electroencephalography (eeg), Explicit memory, Force field, Reaching movement, Sensorimotor learning}
}

@article{putze_adaptive_2014,
	title = {Adaptive cognitive technical systems},
	volume = {234},
	issn = {1872-678X},
	doi = {10.1016/j.jneumeth.2014.06.029},
	abstract = {Adaptive cognitive technical systems are capable of sensing the internal state of its user and of adapting its behavior appropriately to those measurements to improve the usability of the system. One important example of such user state is the user's mental workload level. This paper gives an introduction to the topic of workload recognition and adaptation. It reviews the literature on recognition of workload from physiological signals and on how those user state estimates are employed to improve human-machine interaction.},
	journal = {Journal of Neuroscience Methods},
	author = {Putze, Felix and Schultz, Tanja},
	year = {2014},
}

@inproceedings{reich_real-time_2011,
	title = {A Real-Time Speech Command Detector for a Smart Control Room},
	booktitle = {Proceedings of 12th {Annual} {Conference} of the {International} {Speech} {Communication} {Association}},
	author = {Reich, Daniel and Putze, Felix and Heger, Dominic and Ijsselmuiden, Joris and Stiefelhagen, Rainer and Schultz, Tanja},
	year = {2011},
	pages = {2641--2644}
}

@incollection{putze_cognitive_2012,
	title = {Cognitive dialog systems for dynamic environments: {Progress} and challenges},
	booktitle = {Digital {Signal} {Processing} for {In}-{Vehicle} {Systems} and {Safety}},
	publisher = {Springer},
	author = {Putze, Felix and Schultz, Tanja},
	year = {2012},
	pages = {133--143}
}

@inproceedings{putze_combining_2012,
	address = {Berlin, Germany},
	title = {Combining cognitive modeling and {EEG} to predict user behavior in a search task},
	booktitle = {Proceedings of the {International} {Conference} on {Cognitive} {Modeling}},
	author = {Putze, Felix and Holt, Daniel V. and Funke, Joachim and Schultz, Tanja},
	year = {2012},
	pages = {303}
}

@inproceedings{putze_design_2015,
	address = {New York, NY, USA},
	series = {{CHI} '15},
	title = {Design and {Evaluation} of a {Self}-{Correcting} {Gesture} {Interface} {Based} on {Error} {Potentials} from {EEG}},
	isbn = {978-1-4503-3145-6},
	abstract = {Any user interface which automatically interprets the user's input using natural modalities like gestures makes mistakes. System behavior depending on such mistakes will confuse the user and lead to an erroneous interaction flow. The automatic detection of error potentials in electroencephalographic data recorded from a user allows the system to detect such states of confusion and automatically bring the interaction back on track. In this work, we describe the design of such a self-correcting gesture interface, implement different strategies to deal with detected errors, use a simulation approach to analyze performance and costs of those strategies and execute a user study to evaluate user satisfaction. We show that self-correction significantly improves gesture recognition accuracy at lower costs and with higher acceptance than manual correction.},
	booktitle = {Proceedings of the 33rd {Annual} {ACM} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Putze, Felix and Amma, Christoph and Schultz, Tanja},
	year = {2015},
	keywords = {adaptive interface, error-potentials, gesture recognition, self-correction, simulation, user study},
	url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Putze_GestureError2015.pdf},
	pages = {3375--3384},
}

@inproceedings{putze_dummy_2015,
	address = {Hongkong, China},
	title = {Dummy {Model} based {Workload} {Modeling}},
	booktitle = {Proceedings of {IEEE} {International} {Conference} on {Systems}, {Man} and {Cybernetics}},
	author = {Putze, Felix and Pröpper, Robert and Schultz, Tanja},
	url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Putze_Dummy2015.pdf},
	year = {2015}
}

@article{putze_hybrid_2014,
	title = {Hybrid {fNIRS}-{EEG} based classification of auditory and visual perception processes},
	volume = {8},
	journal = {Frontiers in neuroscience},
	author = {Putze, Felix and Hesslinger, Sebastian and Tse, Chun-Yu and Huang, YunYing and Herff, Christian and Guan, Cuntai and Schultz, Tanja},
	url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Putze_Hybrid2014.pdf},
	year = {2014}
}

@inproceedings{putze_investigating_2014,
	address = {Istanbul, Turkey},
	title = {Investigating {Intrusiveness} of {Workload} {Adaptation}},
	booktitle = {Proceedings of {International} {Conference} on {Multimodal} {Interfaces}},
	author = {Putze, Felix and Schultz, Tanja},
	url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Putze_Intrusiveness2014.pdf},
	year = {2014}
}

@inproceedings{propper_jam:_2011,
	title = {{JAM}: {Java}-based {Associative} {Memory}},
	copyright = {©2011 Springer Science+Business Media, LLC},
	abstract = {In dynamic environments, conversational dialog systems have to deal with ambiguous input, topic shifts and the users’ limited memory resources. Therefore, systems need to model cognitive processes of its users to predict “what is on the user’s mind”. In this paper, we introduce JAM, a cognitive model of associative memory designed for the application in dialog systems. JAM is able to estimate dynamic processes like association, concept drifts and forgetting of information. We describe the data structures and algorithms developed to support these operations and present evaluation results, including the outcome of a survey conducted to compare the results of JAM to human associations.},
	language = {en},
	urldate = {2014-08-05},
	booktitle = {Proceedings of the {Paralinguistic} {Information} and its {Integration} in {Spoken} {Dialogue} {Systems} {Workshop}},
	author = {Pröpper, Robert and Putze, Felix and Schultz, Tanja},
	month = jan,
	year = {2011},
	keywords = {Language Translation and Linguistics, Signal, Image and Speech Processing, User Interfaces and Human Computer Interaction},
	url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Putze_Memory2011.pdf},
	pages = {143--155}
}

@inproceedings{putze_model-based_2015,
	address = {Hongkong, China},
	title = {Model-based {Evaluation} of {Playing} {Strategies} in a {Memo} {Game} for {Elderly} {Users}},
	booktitle = {Proceedings of {IEEE} {International} {Conference} on {Systems}, {Man} and {Cybernetics}},
	author = {Putze, Felix and Ehret, Sonja and Miller-Teynor, Heike and Kruse, Andreas and Schultz, Tanja},
	url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Putze_Memo2015.pdf},
	year = {2015}
}

@inproceedings{putze_model-based_2014,
	address = {Hamburg, Germany},
	title = {Model-based {Identification} of {EEG} {Markers} for {Learning} {Opportunities} in an {Associative} {Learning} {Task} with {Delayed} {Feedback}},
	booktitle = {Proceedings of 24th {International} {Conference} on {Artificial} {Neural} {Networks}},
	author = {Putze, Felix and Holt, Daniel V. and Schultz, Tanja and Funke, Joachim},
	url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Putze_Learning2014.pdf},
	year = {2014}
}

@inproceedings{hild_spatio-temporal_2014,
	title = {Spatio-{Temporal} {Event} {Selection} in {Basic} {Surveillance} {Tasks} using {Eye} {Tracking} and {EEG}},
	booktitle = {Proceedings of the 7th {Workshop} on {Eye} {Gaze} in {Intelligent} {Human} {Machine} {Interaction}: {Eye}-{Gaze} \& {Multimodality}},
	publisher = {ACM},
	author = {Hild, Jutta and Putze, Felix and Kaufman, David and Kühnle, Christian and Schultz, Tanja and Beyerer, Jürgen},
	year = {2014},
	url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Putze_Gaze2014.pdf},
	pages = {3--8}
}

@book{schultz_technische_2014a,
	title = {Technische {Unterstuetzung} fuer {Menschen} mit {Demenz} : {Symposium} 30.09. - 01.10.2013},
	isbn = {978-3-7315-0258-6},
	shorttitle = {Technische {Unterstuetzung} fuer {Menschen} mit {Demenz}},
	language = {de},
	publisher = {KIT Scientific Publishing},
	author = {Schultz, Tanja and Putze, Felix and Kruse, Andreas},
	year = {2014}
}

@incollection{schultz_technische_2014,
	address = {Karlsruhe, Germany},
	title = {Technische {Unterstützung} für {Menschen} mit {Demenz} - {Ein} Überblick},
	booktitle = {Technische {Unterstützung} für {Menschen} mit {Demenz}},
	publisher = {KIT Scientific Publishing},
	author = {Schultz, Tanja and Putze, Felix and Mikut, Ralf and Weinberger, Nora and Boch, Katrin and Schmitt, Eric and Decker, Michael and Lind-Matthäus, Dagmar and Metz, Brigitte},
	year = {2014},
	pages = {1--18}
}

@incollection{mikut_data-mining-methoden_2014,
	address = {Karlsruhe, Germany},
	title = {Data-{Mining}-{Methoden} für die {Demenzforschung}: {Stand} und {Potentiale}},
	booktitle = {Technische {Unterstützung} für {Menschen} mit {Demenz}},
	publisher = {KIT Scientific Publishing},
	author = {Mikut, Ralf and Reischl, Markus and Putze, Felix and Schultz, Tanja},
	year = {2014},
	pages = {89--104}
}

@incollection{putze_aktiv:_2014,
	address = {Karlsruhe, Germany},
	title = {{AKTIV}: {Multimodal} {Interaction} {System} to {Engage} {Patients} with {Dementia}},
	booktitle = {Technische {Unterstützung} für {Menschen} mit {Demenz}},
	publisher = {KIT Scientific Publishing},
	author = {Putze, Felix and Tapaswi, Makarand and Martinez, Manel and Telaar, Dominic and Heger, Dominic and Sarfraz, Saquib and Schultz, Tanja and Stiefelhagen, Rainer},
	year = {2014},
	pages = {105--122}
}

@inproceedings{escaida_navarro_telemanipulation_2015,
	address = {Hamburg, Germany},
	title = {Telemanipulation with {Force}-{Based} {Display} of {Proximity} {Fields}},
	booktitle = {Proceedings of {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	author = {Escaida Navarro, Stefan and Heger, Franz and Putze, Felix and Beyl, Tim and Schultz, Tanja and Hein, Björn},
	year = {2015}
}

@inproceedings{diener2015direct,
  title={Direct Conversion from Facial Myoelectric Signals to Speech using Deep Neural Networks},
  author={Diener, Lorenz and Janke, Matthias and Schultz, Tanja},
  note={IJCNN 2015},
  booktitle={International Joint Conference on Neural Networks},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Direct_Conversion_from_Facial_Myoelectric_Signals_to_Speech_using_Deep_Neural_Networks.pdf},
  abstract={This paper presents our first results using Deep Neural Networks for surface electromyographic (EMG) speech synthesis. The proposed approach enables a direct mapping from EMG signals captured from the articulatory muscle movements to the acoustic speech signal. Features are processed from multiple EMG channels and are fed into a feed forward neural network to achieve a mapping to the target acoustic speech output. We show that this approach is feasible to generate speech output from the input EMG signal and compare the results to a prior mapping technique based on Gaussian mixture models. The comparison is conducted via objective Mel-Cepstral distortion scores and subjective listening test evaluations. It shows that the proposed Deep Neural Network approach gives substantial improvements for both evaluation criteria.},
  keywords={electromyography, silent speech interface, deep neural networks},
  pages={1--7},
  doi={10.1109/IJCNN.2015.7280404},
  year={2015},
}

@INPROCEEDINGS{HennrichEMBC2015,
author={Hennrich, J. and Herff, C. and Heger, D. and Schultz, T.},
booktitle={Engineering in Medicine and Biology Society (EMBC), 2015 37th Annual International Conference of the IEEE},
title={Investigating Deep Learning for Fnirs Based BCI},
year={2015},
url={https://www.csl.uni-bremen.de/cms/images/documents/publications/EMBC2015_Hennrich.pdf},
abstract={Functional Near infrared Spectroscopy (fNIRS) is a relatively young modality for measuring brain activity which has recently shown promising results for building Brain Computer Interfaces (BCI). Due to its infancy, there are still no standard approaches for meaningful features and classifiers for single trial analysis of fNIRS. Most studies are limited to established classifiers from EEG-based BCIs and very simple features. The feasibility of more complex and powerful classification approaches like Deep Neural Networks has, to the best of our knowledge, not been investigated for fNIRS based BCI. These networks have recently become increasingly popular, as they outperformed conventional machine learning methods for a variety of tasks, due in part to advances in training methods for neural networks. In this paper, we show how Deep Neural Networks can be used to classify brain activation patterns measured by fNIRS and compare them with previously used methods.},
keywords={Neural networks in biosignal processing and classification, Biomedical signal classification},
month={Aug},
}
@INPROCEEDINGS{7146565,
author={Heger, D. and Herff, C. and Putze, F. and Schultz, T.},
booktitle={Neural Engineering (NER), 2015 7th International IEEE/EMBS Conference on},
title={Joint optimization for discriminative, compact and robust Brain-Computer Interfacing},
year={2015},
pages={82-85},
url={https://www.csl.uni-bremen.de/cms/images/documents/publications/ner_2015_paper_heger.pdf},
abstract={We present a new pattern recognition framework for Brain-Computer Interfacing that learns discriminative brain activity patterns, compact modeling, and robustness against signal variabilities by a single joint optimization. We present an algorithm based on the Alternating Direction Method of Multipliers, which finds an optimal solution for this approach extremely efficiently. A first evaluation using a publicly available EEG motor imagery data corpus with 105 subjects shows that our framework outperformed state-of-the-art methods and successfully performed subject transfer.},
keywords={brain-computer interfaces;electroencephalography;medical signal processing;neurophysiology;optimisation;pattern recognition;EEG motor imagery data corpus;alternating direction method of multipliers;compact modeling;discriminative brain activity patterns;pattern recognition framework;robust brain-computer interfacing;single joint optimization;Brain;Electroencephalography;Feature extraction;Optimization;Pattern recognition;Robustness;Training},
doi={10.1109/NER.2015.7146565},
month={April},}

@INPROCEEDINGS{7146546,
author={Herff, C. and Fortmann, O. and Chun-Yu Tse and Xiaoqin Cheng and Putze, F. and Heger, D. and Schultz, T.},
booktitle={Neural Engineering (NER), 2015 7th International IEEE/EMBS Conference on},
title={Hybrid fNIRS-EEG based discrimination of 5 levels of memory load},
year={2015},
pages={5-8},
url={https://www.csl.uni-bremen.de/cms/images/documents/publications/ner_2015_paper_cherff.pdf},
abstract={In this study, we show that both electroencephalograhy (EEG) and functional Near-Infrared Spectroscopy (fNIRS) can be used to discriminate between 5 levels of memory load. We induce memory load with the memory updating task, which is known to robustly generate memory load and allows us to define 5 different levels of load. Typical experiments only discriminate between low and high workload or up to a maximum of three classes. To the best of our knowledge, the memory updating task has not been used in combination with brain activity measurements before. Here, accuracies of up to 93% are achieved for the binary classification between very high and very low workload. On average, two levels of workload could be discriminated with 74% accuracy. Classification between the full five classes yielded 44% accuracy on average. Despite the fact that EEG results consistently outperformed the results obtained with fNIRS, we could show that the feature-level fusion of both modalities increased robustness of classification results. A reliable discrimination between different levels of memory load could be used to adapt user interfaces or present the right amount of information to a learner.},
keywords={cognition;electroencephalography;feature extraction;infrared spectroscopy;medical signal processing;neurophysiology;sensor fusion;signal classification;user interfaces;5-level memory load discrimination;binary classification accuracy;brain activity measurements;classification robustness;electroencephalograhy;feature-level fusion;five-class classification accuracy;functional near-infrared spectroscopy;high memory workload discrimination;hybrid fNIRS-EEG based discrimination;low memory workload discrimination;memory load generation;memory updating task;three-class workload discrimination;two-level workload discrimination accuracy;user interface;Accuracy;Brain;Electrodes;Electroencephalography;Feature extraction;Robustness;Spectroscopy},
doi={10.1109/NER.2015.7146546},
month={April},}

@inproceedings{diener2015codebook,
  title={Codebook Clustering for Unit Selection Based EMG-to-Speech Conversion},
  author={Diener, Lorenz and Janke, Matthias and Schultz, Tanja},
  note={Interspeech 2015},
  booktitle={Sixteenth Annual Conference of the International Speech Communication Association},
  pages={2420--2424},
  abstract={This paper reports on our recent advances in using Unit Selection to directly synthesize speech from facial surface electromyographic (EMG) signals generated by movement of the articulatory muscles during speech production. We achieve a robust Unit Selection mapping by using a more sophisticated unit codebook. This codebook is generated from a set of base units using a two stage unit clustering process. The units are first clustered based on the audio and afterwards on the EMG feature vectors they cover, and a new codebook is generated using these cluster assignments. We evaluate different cluster counts for both stages and revisit our evaluation of unit sizes in light of this clustering approach. Our final system achieves a significantly better Mel-Cepstral distortion score than the Unit Selection based EMG-to-Speech conversion system from our previous work while, due to the reduced codebook size, taking less time to perform the conversion.},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Codebook_Clustering_for_Unit_Selection Based_EMG-to-Speech_Conversion.pdf},
  keywords={electromyography, silent speech interface, unit selection},
  year={2015}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/reports_1307.php}
@comment{Additional data: LTI Technical Report CMU-LTI-07-017, Carnegie Mellon University, Pittsburgh PA, USA}
@techreport{laskowski2007a,
  year={2007},
  title={A Supervised Factorial Acoustic Model for Simultaneous Multiparticipant Vocal Activity Detection in Close-Talk Microphone Recordings of Meetings},
  author={Laskowski, Kornel and Burger, Susanne}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/1855_2899.php}
@mastersthesis{sun2014prosodic,
  school={Karlsruher Institut für Technologie},
  title={Prosodic Features for Code-Switching Speech Recognition},
  year={2014},
  supervisor={Telaar, Dominic and Vu, Thang and Schultz, Tanja},
  author={Sun, Jing}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/1855_2898.php}
@mastersthesis{adel2014integration,
  school={Karlsruher Institut für Technologie},
  title={Integration of Syntactic and Semantic Features into Statistical Code-Switching Language Models},
  year={2014},
  supervisor={Telaar, Dominic and Vu, Thang and Kirchhoff, Katrin and Schultz, Tanja},
  author={Adel, Heike}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/1855_2688.php}
@mastersthesis{schulte2013kompensation,
  school={Karlsruher Institut für Technologie},
  title={Kompensation unterschiedlicher Elektrodenpositionierungen in der EMG-basierten Sprachverarbeitung},
  year={2013},
  supervisor={Wand, Michael and Janke, Matthias and Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/MA_Schulte-FinalVersion.pdf},
  author={Schulte, Christopher}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/1855_2809.php}
@mastersthesis{waldkirch2013entwicklung,
  school={Karlsruher Institut für Technologie},
  title={Entwicklung von Strategien zur Fehlererkennung und Fehlerbehandlung für ein gestenbasiertes Eingabesystem},
  year={2013},
  supervisor={Putze, Felix and Schultz, Tanja},
  author={Waldkirch, Christian}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/1855_2808.php}
@mastersthesis{colling2013recognition,
  school={Karlsruher Institut für Technologie},
  year={2013},
  title={Recognition of Player Deficits using Game-Triggered Intervention and Bayesian Networks},
  supervisor={Putze, Felix and Schultz, Tanja},
  author={Colling, Steven}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/1855_2062.php}
@mastersthesis{müller2012implementierung,
  school={Karlsruher Institut für Technologie},
  title={Implementierung und Evaluation session-invarianter EEG-basierter Workload Erkennung},
  year={2012},
  supervisor={Putze, Felix and Schultz, Tanja},
  author={Müller, Markus}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/books_2934.php}
@comment{Additional data: <a id="block2938" name="block2938"><!-- Sprungmarke --></a><h1>Video</h1><div class="text"><p><video controls="true" height="376" width="504"><source src="http://i19pc11.ira.uka.de/fileadmin/Demo-Videos/brain2text-720p.mp4" type="video/mp4" /></video></p><p>&nbsp;</p></div>}
@ARTICLE{10.3389/fnins.2015.00217,
 AUTHOR={Herff, Christian  and  Heger, Dominic  and  de Pesters, Adriana  and  Telaar, Dominic  and  Brunner, Peter  and  Schalk, Gerwin  and  Schultz, Tanja},
 TITLE={Brain-to-text: Decoding spoken phrases from phone representations in the brain},
JOURNAL={Frontiers in Neuroscience},
VOLUME={9},
YEAR={2015},
NUMBER={217},
url={https://www.csl.uni-bremen.de/cms/images/documents/publications/fnins-09-00217.pdf},
DOI={10.3389/fnins.2015.00217},
ISSN={1662-453X} ,
ABSTRACT={It has long been speculated whether communication between humans and machines based on natural speech related cortical activity is possible. Over the past decade, studies have suggested that it is feasible to recognize isolated aspects of speech from neural signals, such as auditory features, phones or one of a few isolated words. However, until now it remained an unsolved challenge to decode continuously spoken speech from the neural substrate associated with speech and language processing. Here, we show for the first time that continuously spoken speech can be decoded into the expressed words from intracranial electrocorticographic (ECoG) recordings.Specifically, we implemented a system, which we call Brain-To-Text that models single phones, employs techniques from automatic speech recognition (ASR), and thereby transforms brain activity while speaking into the corresponding textual representation. Our results demonstrate that our system can achieve word error rates as low as 25% and phone error rates below 50%. Additionally, our approach contributes to the current understanding of the neural basis of continuous speech production by identifying those cortical regions that hold substantial information about individual phones. In conclusion, the Brain-To-Text system described in this paper represents an important step toward human-machine communication based on imagined speech.}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/books_2925.php}
@article{adel2015syntactic,
  number={3},
  title={Syntactic and Semantic Features For Code-Switching Factored Language Models},
  volume={23},
  year={2015},
  journal={IEEE/ACM Transactions on Audio, Speech and Language Processing},
  author={Adel, Heike and Vu, Ngoc Thang and Kirchhoff, Katrin and Telaar, Dominic and Schultz, and Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/books_2920.php}
@article{stahlberg2014word,
  title={Word Segmentation and Pronunciation Extraction from Phoneme Sequences Through Cross-Lingual Word-to-Phoneme Alignment},
  year={2014},
  journal={Computer Speech & Language, Elservier},
  author={Stahlberg, Felix and Schlippe, Tim and Vogel, Stephan and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/books_2900.php}
@article{wand2013application,
  title={Application of Electrode Arrays for Artifact Removal in an Electromyographic Silent Speech Interface},
  pages={300 - 312},
  year={2013},
  note={BIOSTEC 2013},
  journal={Biomedical Engineering Systems and Technologies International Joint Conference, Barcelona, Spain (Also in: Revised Selected Papers Communications in Computer and Information Science, Vol. 452)},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/WandJankeSchultz_Application_Electrode_Arrays.pdf},
  abstract={An electromygraphic (EMG) Silent Speech Interface is a system which recognizes speech by capturing the electric potentials of the human articulatory muscles, thus enabling the user to communicate silently. This study deals with the introduction of multi-channel electrode arrays to the EMG recording system, which requires meticulous dealing with the resulting high-dimensional data. As a first application of the technology, Independent Component Analysis (ICA) is applied for automated artifact detection and removal. Without the artifact removal component, the system achieves optimal average Word Error Rates of 40.1% for 40 training sentences and 10.9% for 160 training sentences on EMG signals of audible speech. On a subset of the corpus, we evaluate the ICA artifact removal method, improving the Word Error Rate by 10.7% relative.},
  author={Wand, Michael and Janke, Matthias and Heistermann, Till and Schulte, Christopher and ,  and Himmelsbach, Adam and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/books_2874.php}
@article{wand2014tackling,
  volume={61},
  year={2014},
  title={Tackling Speaking Mode Varieties in EMG-Based Speech Recognition},
  number={10},
  journal={IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING},
  abstract={An electromyographic (EMG) silent speech recognizer is a system that recognizes speech by capturing the electric potentials of the human articulatory muscles, thus enabling the user to communicate silently. After having established a baseline EMG-based continuous speech recognizer, in this paper, we investigate speaking mode variations, i.e., discrepancies between audible and silent speech that deteriorate recognition accuracy. We introduce multimode systems that allow seamless switching between audible and silent speech, investigate different measures which quantify speaking mode differences, and present the spectral mapping algorithm, which improves the word error rate (WER) on silent speech by up to 14.3% relative. Our best average silent speech WER is 34.7%, and our best WER on audibly spoken speech is 16.8%.},
  author={Wand, Michael and Schultz, Matthias Janke; Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/books_2752.php}
@article{doi:10.1080/2326263X.2014.912884,
  author = {Dominic Heger and Christian Herff and Felix Putze and Reinhard Mutter and Tanja Schultz},
  title = {Continuous affective states recognition using functional near infrared spectroscopy},
  journal = {Brain-Computer Interfaces},
  volume = {1},
  number = {2},
  pages = {113-125},
  year = {2014},
  doi = {10.1080/2326263X.2014.912884},
  URL = {http://www.csl.uni-bremen.de/cms/images/documents/publications/BCI_Heger2014.pdf},
  eprint = { http://dx.doi.org/10.1080/2326263X.2014.912884},
  abstract = {Monitoring the affective states of a person can be highly relevant for numerous disciplines, including adaptive user interfaces, entertainment, ergonomics, medicine and therapy. In many situations, the affective state of a user is not easily observable from outside by audio or video, but may be identified by a brain-computer interface (BCI). Functional near-infrared spectroscopy (fNIRS) is a brain imaging modality gaining rising attention in the BCI community. However, fNIRS emotion recognition studies have only analyzed stimulus-locked effects. For realistic human-machine interaction scenarios, the point of time of an emotion-triggering event and the time span of an affective state are unknown. In this paper, we investigate a BCI that monitors the affective states of the user continuously over time (i.e. asynchronous BCI). In our study, fNRIS signals from eight subjects have been recorded at eight prefrontal locations in response to three different classes of affect induction by emotional audio-visual stimuli plus a neutral class. Our system evaluates short windows of 5 s length to continuously recognize affective states. We analyze hemodynamic responses, present a careful evaluation of binary classification tasks, compare time-domain and wavelet-based signal features, and investigate classification accuracies over time. }
}

@comment{Old page: http://csl.anthropomatik.kit.edu/books_2671.php}
@ARTICLE{10.3389/fnhum.2013.00935,
  AUTHOR={Herff, Christian  and  Heger, Dominic  and  Fortmann, Ole  and  Hennrich, Johannes  and  Putze, Felix  and  Schultz, Tanja},
  TITLE={Mental workload during n-back task - quantified in the prefrontal cortex using fNIRS},
  JOURNAL={Frontiers in Human Neuroscience},
  VOLUME={7},
  YEAR={2014},
  NUMBER={935},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/fnhum_cherff.pdf},
  DOI={10.3389/fnhum.2013.00935},
  ISSN={1662-5161} ,
  ABSTRACT={When interacting with technical systems, users experience mental workload. Particularly in multitasking scenarios (e.g., interacting with the car navigation system while driving) it is desired to not distract the users from their primary task. For such purposes, human-machine interfaces (HCIs) are desirable which continuously monitor the users' workload and dynamically adapt the behavior of the interface to the measured workload. While memory tasks have been shown to elicit hemodynamic responses in the brain when averaging over multiple trials, a robust single trial classification is a crucial prerequisite for the purpose of dynamically adapting HCIs to the workload of its user. The prefrontal cortex (PFC) plays an important role in the processing of memory and the associated workload. In this study of 10 subjects, we used functional Near-Infrared Spectroscopy (fNIRS), a non-invasive imaging modality, to sample workload activity in the PFC. The results show up to 78% accuracy for single-trial discrimination of three levels of workload from each other. We use an n-back task (n ? {1, 2, 3}) to induce different levels of workload, forcing subjects to continuously remember the last one, two, or three of rapidly changing items. Our experimental results show that measuring hemodynamic responses in the PFC with fNIRS, can be used to robustly quantify and classify mental workload. Single trial analysis is still a young field that suffers from a general lack of standards. To increase comparability of fNIRS methods and results, the data corpus for this study is made available online.}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/books_2653.php}
@article{amma2013airwriting,
  number={2},
  title={Airwriting: Bringing text entry to wearable computers},
  volume={20},
  pages={50-55},
  year={2013},
  doi={10.1145/2540048    },
  journal={XRDS: Crossroads, The ACM Magazine for students},
  author={Amma, Christoph and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/books_2650.php}
@article{schultz2013biosignale,
  number={11},
  title={Biosignale-basierte Mensch-Maschine-Schnittstellen},
  year={2013},
  volume={61},
  pages={760 - 769},
  journal={at - Automatisierungstechnik,    2013},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Biosignals.TSchultz.10012014.pdf},
  author={Schultz, Tanja and Amma, Christoph and Heger, Dominic and Putze, Felix and Wand, Michael}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/books_2514.php}
@article{besacier2014automatic,
  volume={56},
  pages={85-100},
  year={2014},
  title={Automatic Speech Recognition for Under-resourced Languages: A Survey},
  journal={Speech Communication,   January 2014},
  author={Besacier, Laurent and Barnard, Etienne and Karpov, Alexey and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/books_2396.php}
@article{schlippe2014web,
  title={Web-based Tools and Methods for Rapid Pronunciation Dictionary Creation},
  volume={56},
  pages={101},
  year={2014},
  journal={Speech Communication,  â118, January 2014.},
  author={Schlippe, Tim and Ochs, Sebastian and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/books_2219.php}
@article{amma2013airwriting,
  year={2013},
  doi={10.1007/s00779-013-0637-3},
  title={Airwriting: a wearable handwriting recognition system},
  journal={Personal and Ubiquitous Computing, available online first with},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/AmmaGeorgiSchultz_PUC2013.pdf},
  author={Amma, Christoph and Georgi, Marcus and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/books_1982.php}
@article{heger2011an,
  number={4},
  year={2011},
  pages={415-425},
  volume={3},
  title={An EEG Adaptive Information System for an Empathic Robot},
  journal={International Journal of Social Robotics, Special Issue Towards an Effective Design of Social Robot,   (2011)},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/paper.pdf},
  author={Heger, Dominic and Putze, Felix and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/books_1032.php}
@article{tam2008bilingual,
  year={2008},
  doi={10.1007/s10590-008-9045-2},
  title={Bilingual-LSA based Adaptation for Statistical Machine Translation},
  journal={Machine Translation, Springer Netherlands,  preprint},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/MT2008-TamLaneSchultz.pdf},
  author={Tam, Yik-Cheung and Lane, Ian and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/books_1043.php}
@article{schultz2001language,
  year={2001},
  volume={35},
  pages={31-51},
  title={Language Independent and Language Adaptive Acoustic Modeling for Speech Recognition},
  number={1-2},
  journal={Speech Communication},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SchultzSpecom26062000.ps.gz},
  author={Schultz, Tanja and Waibel, Alex}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/books_1035.php}
@article{stein2008kinematische,
  title={Kinematische Analyse menschlicher Alltagsbewegungen für die Mensch-Maschine-Interaktion},
  pages={49-58)},
  year={2008},
  journal={In J. Edelmann-Nusser, E. F. Moritz, V. Senner, & K. Witte (2009). Sporttechnologie zwischen Theorie und Praxis V (. Aachen: Shaker Verlag.},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Sporttechnologie2008.pdf},
  author={Stein, Thorsten and Fischer, Andreas and Boesnach, Ingo and Gehrig, Dirk and Köhler, Hildegard and Schwameder, Hermann}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/books_1029.php}
@article{schultz2010modeling,
  number={4},
  volume={52},
  pages={341 - 353},
  year={2010},
  title={Modeling Coarticulation in EMG-based Continuous Speech Recognition},
  journal={Speech Communication Journal},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SchultzWand-SCJ10-ModelingCoarticulation.pdf},
  author={Schultz, Tanja and Wand, Michael}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/books_1040.php}
@article{schultz2006multilingual,
  title={Multilingual Speech Processing},
  year={2006},
  journal={Elsevier, Academic Press, ISBN 13: 978-0-12-088501-5},
  author={Schultz, Tanja and Kirchhoff, Katrin}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/books_1044.php}
@article{waibel2000multilingual,
  year={2000},
  title={Multilingual Speech Recognition},
  journal={Verbmobil: Foundations of Speech-to-Speech Translation, Wolfgang Wahlster (Ed.), Springer Verlag},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/WSMmulti.6.ps.gz},
  author={Waibel, Alex and Soltau, Hagen and Schultz, Tanja and Schaaf, Thomas and Metze, Florian}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/books_1037.php}
@article{schultz2007speaker,
  year={2007},
  title={Speaker Characteristics},
  journal={In: C. Müller (Ed.) Speaker Classification, Lecture Notes in Computer Science / Artificial Intelligence, Springer, Heidelberg - Berlin - New York, Volume 4343.},
  author={Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/books_1046.php}
@article{geutner1995integrating,
  title={Integrating Different Learning Approaches into a Multilingual Spoken Language Translation System},
  pages={117-131},
  year={1995},
  journal={Connectionist, statistical and symbolic approaches to learning for natural language processing, Lecture Notes in Artificial Intelligence,  Springer},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/nlp_learning.ps.gz},
  author={Geutner, Petra and Suhm, B and Buø, F.D and Kemp, Thomas and Tomokiyo-Mayfield, Laura and McNair, A.E and Rogina, Ivica and Schultz, Tanja and Sloboda, T and Ward, W and Woszczyna, Monika and Waibel, Alex}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/books_1030.php}
@article{denby2010silent,
  number={4},
  title={Silent Speech Interfaces},
  year={2010},
  volume={52},
  pages={270 - 287},
  journal={Speech Communication Journal},
  author={Denby, Bruce and Schultz, Tanja and Honda, Kiyoshi and Hueber, Thomas and Gilbert, Jim and Brumberg, Jon}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/books_1033.php}
@article{schultz2008automatic,
  title={Automatic Speech Recognition based on Electromyographic Biosignals},
  year={2008},
  journal={Selected from the BIOSTEC full papers to be published in:Communications in Computer and Information Science (CCIS) series publishedby Springer},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/CCIS08-JouSchultz-submitted.pdf},
  author={Schultz, Tanja and Jou, Szu-Chen (Stan)}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/books_1031.php}
@article{wand2010speaker,
  year={2010},
  title={Speaker-Adaptive Speech Recognition Based on Surface Electromyography},
  journal={Biomedical Engineering Systems and TechnologiesInternational Joint Conference, BIOSTEC2009, Porto, Portugal, January 14-17, 2009, Revised Selected PapersCommunications in Computer and Information Science , Vol. 52},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/WandSchultz_SpeakerAdaptiveSpeechRecognition_CCIS.pdf},
  author={Wand, Michael and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/books_1038.php}
@article{paulik2007translating,
  title={Translating language with technology's help},
  year={2007},
  pages={30 - 35},
  volume={26},
  journal={IEEE potentials - the magazine for high-tech inovators,  No.3,  MAY/JUNE 2007},
  author={Paulik, Matthias and Stüker, Sebastian and Fügen, Christian and Schultz, Tanja and Waibel, Alex}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/books_1045.php}
@article{waibel2000multilinguality,
  title={Multilinguality in Speech and Spoken Language Systems},
  year={2000},
  pages={1297-1313},
  volume={88(8)},
  journal={Proceedings of the IEEE, Special Issue on Spoken Language Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/IEEE1July2002.ps},
  author={Waibel, Alex and Geutner, Petra and Tomokiyo-Mayfield, Laura and Schultz, Tanja and Woszczyna, Monika}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/books_1034.php}
@article{fung2008multilingual,
  title={Multilingual Spoken Language Processing},
  year={2008},
  journal={IEEE Signal Processing Magazine [89] May 2008},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/810_IEEESignal_Processing.pdf},
  author={Fung, Pascale and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/books_1042.php}
@article{jekat2001evaluation,
  year={2001},
  title={Evaluation Sprachverarbeitender Systeme},
  journal={Computerlinguistik und Sprachtechnologie, Ralf Klabunde et.al (Ed.), Spektrum - Akademischer Verlag, Oktober 2001. ISNB 3827410274},
  author={Jekat, Susanne and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/books_1039.php}
@article{schultz2007multilingual,
  year={2007},
  title={Multilingual Speech Processing - Challenges and Solutions},
  number={1},
  journal={MultiLingual, #85 Volume 18  2007.MultiLingual Computing, Inc., 319 North First Avenue, Suite 2, Sandpoint, Idaho 83864-1495 USA},
  author={Schultz, Tanja and Kirchhoff, Katrin}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/books_1041.php}
@article{schultz2006flexible,
  title={Flexible Speech Translation Systems},
  year={2006},
  journal={IEEE Transactions on Audio, Speech, and Language Processing, Vol 14(2)},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Schultz-IEEE2006.pdf},
  author={Schultz, Tanja and Black, Alan W and Vogel, Stephan and Woszczyna, Monika}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/studienarbeiten_2731.php}
@studentresearchproject{breiter2014rapid,
  school={Karlsruher Institut für Technologie},
  title={Rapid Bootstrapping of Haitian Creole Large Vocabulary Continuous Speech Recognition},
  year={2014},
  supervisor={Schlippe, Tim and Vu, Ngoc Thang and Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SA_WojtekBreiter.pdf},
  author={Breiter, Wojtek}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/studienarbeiten_2819.php}
@studentresearchproject{majarle2014klassifizierung,
  school={Karlsruher Institut für Technologie},
  year={2014},
  title={Klassifizierung EEG basierter ereigniskorrelierter Potentiale aus visuellen und auditiven Aufgaben},
  supervisor={Putze, Felix and Schultz, Tanja},
  author={Majarle, Dimitri}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/studienarbeiten_2820.php}
@studentresearchproject{zwar2014confidence,
  school={Karlsruher Institut für Technologie},
  title={Confidence-based Methods to Improve Reliability and Fusion Performance of EEG-based Workload Recognition System},
  year={2014},
  supervisor={Putze, Felix and Schultz, Tanja},
  author={Zwar, Lena}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/studienarbeiten_2836.php}
@studentresearchproject{terziyska2013integrating,
  school={Karlsruher Institut für Technologie},
  title={Integrating MVAR based Connectivity Measures into EEG Single-trial Prediction},
  year={2013},
  supervisor={Heger, Dominik},
  author={Terziyska, Emiliyana}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/studienarbeiten_2821.php}
@studentresearchproject{zairi2013managemant,
  school={Karlsruher Institut für Technologie},
  year={2013},
  title={Managemant of the Text and Speech Resources in the Rapid Language Adaptation Toolkit},
  supervisor={Schlippe, Tim and Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SA_AdneneZairi.pdf},
  author={Zairi, Adnene}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/studienarbeiten_2428.php}
@studentresearchproject{lemcke2013keynounce,
  school={Karlsruher Institut für Technologie},
  title={Keynounce - A Game for Pronunciation Generation through Crowdsourcing},
  year={2013},
  supervisor={Schlippe, Tim and Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SA-Daniel-Lemcke.pdf},
  author={Lemcke, Daniel}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/studienarbeiten_2818.php}
@studentresearchproject{kintz2013datenanalyse,
  school={Karlsruher Institut für Technologie},
  title={Datenanalyse zur Vorbereitung einer Workload-Komponente für ACT-R},
  year={2013},
  supervisor={Putze, Felix and Schultz, Tanja},
  author={Kintz, Dorothea}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/studienarbeiten_2429.php}
@studentresearchproject{quaschningk2013analyzing,
  school={Karlsruher Institut für Technologie},
  title={Analyzing Single and Combined G2P Converter Outputs over Training Data},
  year={2013},
  supervisor={Schlippe, Tim and Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SA_WolfQuaschningk.pdf},
  author={Quaschningk, Wolf}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/studienarbeiten_2816.php}
@studentresearchproject{heßlinger2012analyzing,
  school={Karlsruher Institut für Technologie},
  year={2012},
  title={Analyzing n-back EEG Data with Auditory and Visual Stimuli using ICA-based Spatial Filtering},
  supervisor={Putze, Felix and Schultz, Tanja},
  author={Heßlinger,  and Sebastian, }
}

@comment{Old page: http://csl.anthropomatik.kit.edu/studienarbeiten_2812.php}
@studentresearchproject{bieler2011analyse,
  school={Karlsruher Institut für Technologie},
  title={Analyse und Wirkung von Musik anhand von EEG-Daten},
  year={2011},
  supervisor={Putze, Felix and Schultz, Tanja},
  author={Bieler, Jochen}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/studienarbeiten_2051.php}
@studentresearchproject{gren2011enhancing,
  school={Karlsruher Institut für Technologie},
  year={2011},
  title={Enhancing Language Models for ASR using RSS Feeds},
  supervisor={Schlippe, Tim and Vu, Ngoc Thang and Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SA_LukaszGren.pdf},
  author={Gren, Lukasz}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/studienarbeiten_2073.php}
@studentresearchproject{putze2011design,
  school={Karlsruher Institut für Technologie},
  year={2011},
  title={Design und Analyse eines computergestützten Flirtexperiments},
  supervisor={Schultz, Tanja},
  author={Putze, Susanne}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/studienarbeiten_2050.php}
@studentresearchproject{djomgang2011hausa,
  school={Karlsruher Institut für Technologie},
  title={Hausa Large Vocabulary Continuous Speech Recognition},
  year={2011},
  supervisor={Schlippe, Tim and Vu, Ngoc Thang and Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SA_EdyGuevaraKomgang.pdf},
  author={Djomgang, Edy Guevara Komgang}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/studienarbeiten_1289.php}
@studentresearchproject{mihaylova2010an,
  school={Karlsruher Institut für Technologie},
  year={2010},
  title={An Architecture of a Telephone-based System for Speech Data Collection},
  supervisor={Schlippe, Tim and Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SA_ZlatkaMihaylova.pdf},
  author={Mihaylova, Zlatka}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/studienarbeiten_1287.php}
@studentresearchproject{kara2010session,
  school={Karlsruher Institut für Technologie},
  year={2010},
  title={Session-adaptive Speech Recognition based on Surface Electromyography},
  supervisor={Wand, Michael and Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SA_Elkara.pdf},
  author={Kara, Kais}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/studienarbeiten_2049.php}
@studentresearchproject{gebhardt2009multilingual,
  school={Karlsruher Institut für Technologie},
  title={Multilingual Acoustic Model Combination using Rapid Language Adaption Toolkit (RLAT)},
  year={2009},
  supervisor={Schultz, Tanja and Schlippe, Tim},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SA_JanGebhardt.pdf},
  author={Gebhardt, Jan}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/studienarbeiten_1288.php}
@studentresearchproject{jarvis2010multimodale,
  school={Karlsruher Institut für Technologie},
  year={2010},
  title={Multimodale biosignalbasierte Workloaderkennung im Fahrzeug},
  supervisor={Putze, Felix and Schultz, Tanja},
  author={Jarvis, Jan-Philip}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/studienarbeiten_2072.php}
@studentresearchproject{schenkel2009mutual,
  school={Karlsruher Institut für Technologie},
  year={2009},
  title={Mutual information feature selection for speaker recognition},
  supervisor={Schultz, Tanja},
  author={Schenkel, Peter}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/studienarbeiten_2811.php}
@studentresearchproject{krupicka2009selection,
  school={Karlsruher Institut für Technologie},
  year={2009},
  title={Selection and Implementation of a Cognitive Memory Model},
  supervisor={Putze, Felix and Schultz, Tanja},
  author={Krupicka, Florian}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/studienarbeiten_1291.php}
@studentresearchproject{Öxler2009planung,
  school={Karlsruher Institut für Technologie},
  title={Planung und Aufbau eines realistischen Fahrsimulators für die Untersuchung von kognitiven Dialogsystemen - Schwerpunkt Software},
  year={2009},
  supervisor={Putze, Felix and Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/studienarbeit_rikard_01.pdf},
  author={Öxler, Rikard}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/studienarbeiten_1292.php}
@studentresearchproject{reinhold2009planung,
  school={Karlsruher Institut für Technologie},
  year={2009},
  title={Planung und Aufbau eines realistischen Fahrsimulators für die Untersuchung von kognitiven Dialogsystemen - Schwerpunkt Hardware},
  supervisor={Putze, Felix and Schultz, Tanja},
  author={Reinhold, Frieder}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/studienarbeiten_1290.php}
@studentresearchproject{he2009automatic,
  school={Karlsruher Institut für Technologie},
  title={Automatic Pronunciation Dictionary Generation from Wiktionary and Wikipedia},
  year={2009},
  supervisor={Schlippe, Tim and Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SA_QingyueHe.pdf},
  author={He, Qingyue}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/studienarbeiten_2071.php}
@studentresearchproject{telaar2008extractive,
  school={Karlsruher Institut für Technologie},
  year={2008},
  title={Extractive Speech Summarization on Mandarin Lectures},
  supervisor={Schultz, Tanja},
  author={Telaar, Dominic}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/studienarbeiten_1294.php}
@studentresearchproject{porbadnigk2008eeg,
  school={Karlsruher Institut für Technologie},
  title={EEG-based Speech Recognition: Impact of Experimental Design on Performance},
  year={2008},
  supervisor={Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SA-Porbadnigk.pdf},
  author={Porbadnigk, Anne}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/studienarbeiten_1293.php}
@studentresearchproject{schaaff2008challenges,
  school={Karlsruher Institut für Technologie},
  year={2008},
  title={Challenges on Emotion Induction with the International Affective Picture System},
  supervisor={Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SA-Schaaff.pdf},
  author={Schaaff, Kristina}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/studienarbeiten_1295.php}
@studentresearchproject{sitto2008evaluierung,
  school={Karlsruher Institut für Technologie},
  title={Evaluierung von Algorithmen zur automatischen Segmentierung menschlicher Bewegungen},
  year={2008},
  supervisor={Gehrig, Dirk and Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SA-Dirk.pdf},
  author={Sitto, Sandro}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/studienarbeiten_2070.php}
@studentresearchproject{wand2007wavelet,
  school={Karlsruher Institut für Technologie},
  title={Wavelet-based Preprocessing of Electroencephalographic and Electromyographic Signals for Speech Recognition},
  year={2007},
  supervisor={Schultz, Tanja},
  author={Wand, Michael}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/studienarbeiten_1296.php}
@comment{Additional data: Institut für Theoretische Informatik, Lehrstuhl Prof. Waibel, Universität Karlsruhe}
@studentresearchproject{wand2007wavelet,
  school={Karlsruher Institut für Technologie},
  year={2007},
  title={Wavelet-based Processing of EEG and EMG Signals for Speech Recognition},
  supervisor={Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SA-Wand.pdf},
  author={Wand, Michael}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/studienarbeiten_1297.php}
@comment{Additional data: Institut für Theoretische Informatik, Lehrstuhl Prof. Waibel, Universität Karlsruhe}
@studentresearchproject{callies2006further,
  school={Karlsruher Institut für Technologie},
  year={2006},
  title={Further Investigations on Unspoken Speech},
  supervisor={Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SA-Callies.pdf},
  author={Callies, Jan Peter}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/studienarbeiten_1298.php}
@comment{Additional data: Institut für Theoretische Informatik, Lehrstuhl Prof. Waibel, Universität Karlsruhe}
@studentresearchproject{mircheva2006bulgarian,
  school={Karlsruher Institut für Technologie},
  title={Bulgarian Speech Recognition and Multilingual Language Modeling},
  year={2006},
  supervisor={Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SA-Mircheva.pdf},
  author={Mircheva, Aneliya}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/studienarbeiten_1299.php}
@comment{Additional data: Institut für Logik, Komplexität und Deduktionssysteme, Lehrstuhl Prof. Waibel, Universität Karlsruhe}
@studentresearchproject{honal2003correction,
  school={Karlsruher Institut für Technologie},
  title={Correction of Disfluencies in Spontaneous Speech using a Noisy-Channel Approach},
  year={2003},
  supervisor={Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SA-Honal.pdf},
  author={Honal, Matthias}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/studienarbeiten_1300.php}
@comment{Additional data: Institut für Logik, Komplexität und Deduktionssysteme, Lehrstuhl Prof. Waibel, Universität Karlsruhe}
@studentresearchproject{stüker2002automatic,
  school={Karlsruher Institut für Technologie},
  title={Automatic Generation of Dictionaries - for New, Unseen Languages by Voting Phoneme Recognizers in Nine Different Languages},
  year={2002},
  supervisor={Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SA-Stueker.pdf},
  author={Stüker, Sebastian}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/studienarbeiten_1301.php}
@comment{Additional data: Institut für Logik, Komplexität und Deduktionssysteme, Lehrstuhl Prof. Waibel, Universität Karlsruhe}
@studentresearchproject{wolff1999adaption,
  school={Karlsruher Institut für Technologie},
  title={Adaption von Kontextentscheidungsbäumen auf neue Sprachen},
  year={1999},
  supervisor={Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SA-wolff.ps.gz},
  author={Wolff, Roald}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/studienarbeiten_1304.php}
@comment{Additional data: Institut für Logik, Komplexität und Deduktionssysteme, Lehrstuhl Prof. Waibel, Universität Karlsruhe}
@studentresearchproject{raschke1998automatische,
  school={Karlsruher Institut für Technologie},
  title={Automatische Generierung eines Aussprachewörterbuches und Initialisierung eines Erkenners für die kroatische Sprache},
  year={1998},
  supervisor={Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SA-raschke.ps.gz},
  author={Raschke, Stefan}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/studienarbeiten_1303.php}
@comment{Additional data: Institut für Logik, Komplexität und Deduktionssysteme, Lehrstuhl Prof. Waibel, Universität Karlsruhe}
@studentresearchproject{reichert1998lautschriftumsetzung,
  school={Karlsruher Institut für Technologie},
  year={1998},
  title={Lautschriftumsetzung und Worttrennung der chinesischen Schriftsprache},
  supervisor={Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SA-reichert.ps.gz http://www.csl.uni-bremen.de/cms/images/documents/publications/SA-reichert.pdf},
  author={Reichert, Jürgen}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/studienarbeiten_1305.php}
@comment{Additional data: Institut für Logik, Komplexität und Deduktionssysteme, Lehrstuhl Prof. Waibel, Universität Karlsruhe}
@studentresearchproject{soltau1996sprachenidentifikation,
  school={Karlsruher Institut für Technologie},
  year={1996},
  title={Sprachenidentifikation mit neuronalen Netzen},
  supervisor={Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SA-soltau.ps.gz},
  author={Soltau, Hagen}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/studienarbeiten_1306.php}
@comment{Additional data: Institut für Logik, Komplexität und Deduktionssysteme, Lehrstuhl Prof. Waibel, Universität Karlsruhe}
@studentresearchproject{schultz1994akustische,
  school={Karlsruher Institut für Technologie},
  title={Akustische Modellierung sprachlicher und nichtsprachlicher Geräusche},
  year={1994},
  supervisor={Rogina, Ivica},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/schultz_SA.pdf http://www.csl.uni-bremen.de/cms/images/documents/publications/schultz_SA.ps.gz},
  author={Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_2778.php}
@diplomathesis{he2014rlat,
  school={Karlsruher Institut für Technologie},
  title={RLAT Light - An Enhanced Version for Novices of the Rapid Language Adaptation Toolkit},
  year={2014},
  supervisor={Schlippe, Tim and Vu, Ngoc Thang and Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Diplomarbeit_QingyueHe.pdf},
  author={He, Qingyue}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_2726.php}
@diplomathesis{merz2014different,
  school={Karlsruher Institut für Technologie},
  year={2014},
  title={Different Methods for Efficient Semi-Automatic Pronunciation Generation},
  supervisor={Schlippe, Tim and Schultz, Tanja},
  author={Merz, Matthias}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_2787.php}
@diplomathesis{harnisch2014user,
  school={Karlsruher Institut für Technologie},
  title={User Simulation in Cognitive Dialog Systems: An Application of the Multiple Resource Model},
  year={2014},
  supervisor={Putze, Felix and Schultz, Tanja},
  author={Harnisch, Christian}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_2840.php}
@diplomathesis{rapp2014applying,
  school={Karlsruher Institut für Technologie},
  title={Applying Linear Signal Transformation Techniques to Improve BCI Robustness},
  year={2014},
  supervisor={Heger, Dominik},
  author={Rapp, Hannes}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_2366.php}
@diplomathesis{ikkert2013implementierung,
  school={Karlsruher Institut für Technologie},
  title={Implementierung und Evaluation  eines Large Margin Estimation Algorithmus für HMMs                   š},
  year={2013},
  supervisor={Wand, Michael and Vu, Thang and Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/DA_MichaelIkkert.pdf},
  author={Ikkert, Michael}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_2368.php}
@diplomathesis{johner2013erkennung,
  school={Karlsruher Institut für Technologie},
  title={Erkennung prosodischer Merkmale durch EMG-basierte Klassifikation der Gesichtsmuskulatur},
  year={2013},
  supervisor={Janke, Matthias and Wand, Michael and Schultz, Tanja},
  author={Johner, Christian}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_2825.php}
@diplomathesis{wellenbrock2013copulas,
  school={Karlsruher Institut für Technologie},
  title={Copulas für die Merkmalauswahl},
  year={2013},
  supervisor={Heger, Dominic and Herff, Christian},
  author={Wellenbrock, Christian}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_2788.php}
@diplomathesis{hesslinger2013hybrid,
  school={Karlsruher Institut für Technologie},
  title={Hybrid NIRS-EEG based classification of auditory and visual perception processes},
  year={2013},
  supervisor={Putze, Felix and Schultz, Tanja},
  author={Hesslinger, Sebastian}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_2425.php}
@diplomathesis{gren2013unsupervised,
  school={Karlsruher Institut für Technologie},
  year={2013},
  title={Unsupervised Language Model Adaptation for Automatic Speech Recognition of Broadcast News Using Web 2.0},
  supervisor={Schlippe, Tim and Vu, Ngoc Thang and Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/DA_LukaszGren.pdf},
  author={Gren, Lukasz}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_2790.php}
@diplomathesis{wei2012experimentelle,
  school={Karlsruher Institut für Technologie},
  title={Experimentelle Induktion und biosignalbasierte Erkennung Positiver und Negativer Stimmungen beim Autofahren},
  year={2012},
  supervisor={Putze, Felix and Heger, Dominic and Schultz, Tanja},
  author={Wei, Ying}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_2791.php}
@diplomathesis{engelmann2012untersuchung,
  school={Karlsruher Institut für Technologie},
  year={2012},
  title={Untersuchung des Zusammenhangs von EEG basierten ereigniskorrelierten Potentialen und physischer und kognitiver Fitness bei jungen Studierenden},
  supervisor={Putze, Felix and Heger, Dominic and Schultz, Tanja},
  author={Engelmann, Jeremias}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_1265.php}
@diplomathesis{sitto2011developing,
  school={Karlsruher Institut für Technologie},
  year={2011},
  title={Developing a Human Motion Recognition System by Applying Automatic Segmentation and Model Transfer},
  supervisor={Gehrig, Dirk and Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/DA_Sandro_Sitto.pdf},
  author={Sitto, Sandro}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_2480.php}
@diplomathesis{mihaylova2011lexical,
  school={Karlsruher Institut für Technologie},
  title={Lexical and Acoustic Adaptation for Multiple Non-Native English Accents},
  year={2011},
  supervisor={Schlippe, Tim and Vu, Ngoc Thang and Telaar, Dominic and Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/DA_ZlatkaMihaylova.pdf},
  author={Mihaylova, Zlatka}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_1624.php}
@diplomathesis{herff2011speech,
  school={Karlsruher Institut für Technologie},
  year={2011},
  title={Speech Related Activations in the Brain: Differentiating between Speaking Modes with fNIRS},
  supervisor={Putze, Felix and Heger, Dominic and Schultz, Tanja},
  author={Herff, Christian}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_2793.php}
@diplomathesis{pröpper2011adaption,
  school={Karlsruher Institut für Technologie},
  title={Adaption of cognitive models to dynamically changing mental workload},
  year={2011},
  supervisor={Putze, Felix and Schultz, Tanja},
  author={Pröpper, Robert}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_2046.php}
@diplomathesis{gebhardt2011speech,
  school={Karlsruher Institut für Technologie},
  year={2011},
  title={Speech Recognition on English-Mandarin Code-Switching Data using Factored Language Models  - with Port-of-Speech Tags, Language ID and Code-Switch Point Probability as Factors},
  supervisor={Schlippe, Tim and Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/DA_JanGebhardt.pdf},
  author={Gebhardt, Jan}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_2792.php}
@diplomathesis{reich2011a,
  school={Karlsruher Institut für Technologie},
  year={2011},
  title={A Real-Time Speech Command Detector for a Smart Control Room},
  supervisor={Putze, Felix and Heger, Dominic and Schultz, Tanja},
  author={Reich, Daniel}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_2794.php}
@diplomathesis{jarvis2011multimodal,
  school={Karlsruher Institut für Technologie},
  title={Multimodal Person Independent Recognition of Driver Mental Workload},
  year={2011},
  supervisor={Putze, Felix and Schultz, Tanja},
  author={Jarvis, Jan-Philipp}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_2114.php}
@diplomathesis{kraus2011cross,
  school={Karlsruher Institut für Technologie},
  year={2011},
  title={Cross-Language Bootstrapping based on completely Unsupervised Training},
  supervisor={Vu, Ngoc Thang and Schultz, Tanja},
  author={Kraus, Franziska}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_2839.php}
@diplomathesis{jungkurth2011design,
  school={Karlsruher Institut für Technologie},
  title={Design and Implemantation of a Motor Imagery based Brain-Computer Interface},
  year={2011},
  supervisor={Heger, Dominik},
  author={Jungkurth, Henning}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_2048.php}
@diplomathesis{blaicher2011smt,
  school={Karlsruher Institut für Technologie},
  title={SMT-based Text Generation for Code-Switching Language Models},
  year={2011},
  supervisor={Schlippe, Tim and Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/DA_FabianBlaicher.pdf},
  author={Blaicher, Fabian}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_1266.php}
@diplomathesis{janke2010spektrale,
  school={Karlsruher Institut für Technologie},
  title={Spektrale Methoden zur EMG-basierten Erkennung lautloser Sprache},
  year={2010},
  supervisor={Wand, Michael and Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/DA-Janke.pdf},
  author={Janke, Matthias}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_1268.php}
@diplomathesis{pruzinec2010facial,
  school={Karlsruher Institut für Technologie},
  title={Facial Expression Recognition using Surface Electromyography},
  year={2010},
  supervisor={Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/DA-Pruzinec.pdf},
  author={Pruzinec, Martin}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_1267.php}
@diplomathesis{feng2010initialization,
  school={Karlsruher Institut für Technologie},
  title={Initialization Methods for an EMG-based Silent Speech Recognizer},
  year={2010},
  supervisor={Wand, Michael and Schultz, Tanja},
  author={Feng, Gu}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_2069.php}
@diplomathesis{telaar2009multilingual,
  school={Karlsruher Institut für Technologie},
  year={2009},
  title={Multilingual Speech Recognition Using Bundled Phonetic Features},
  supervisor={Schultz, Tanja},
  author={Telaar, Dominic}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_1271.php}
@diplomathesis{porbadnigk2009predicting,
  school={Karlsruher Institut für Technologie},
  year={2009},
  title={Predicting the BOLD Response: A Computational Model of Humans Solving an Arithmetic Task},
  supervisor={Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/DA_Porbadnigk_03.pdf},
  author={Porbadnigk, Anne}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_2067.php}
@diplomathesis{zipperle2009automatische,
  school={Karlsruher Institut für Technologie},
  year={2009},
  title={Automatische inhaltsbasierte Klassifikation elektronischer Musik},
  supervisor={Schultz, Tanja},
  author={Zipperle, Christoph}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_2066.php}
@diplomathesis{vasilec2009geometrischer,
  school={Karlsruher Institut für Technologie},
  year={2009},
  title={Geometrischer Modellabgleich für die bildbasierte Formalauswertung},
  supervisor={Schultz, Tanja},
  author={Vasilec, Tsoncho}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_1270.php}
@diplomathesis{wielatt2009entwicklung,
  school={Karlsruher Institut für Technologie},
  year={2009},
  title={Entwicklung eines Werkzeuges zur Echtzeitvisualisierung von Biosignalen},
  supervisor={Wand, Michael and Fischer, Andreas and Schultz, Tanja and Schwameder, Hermann},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/ZA_Thomas_Wielatt.pdf},
  author={Wielatt, Thomas}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_1272.php}
@diplomathesis{könig2009systeme,
  school={Karlsruher Institut für Technologie},
  title={Systeme und Methoden zur Erfassung der persönlichen Fitness},
  year={2009},
  supervisor={Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/DA_Koenig_SystemeMethodenPersFitness.pdf},
  author={König, Nils}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_2068.php}
@diplomathesis{burgmer2009detecting,
  school={Karlsruher Institut für Technologie},
  year={2009},
  title={Detecting Code-Switch Events Based on Textual Features},
  supervisor={Schultz, Tanja},
  author={Burgmer, Christoph}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_2796.php}
@diplomathesis{heger2009towards,
  school={Karlsruher Institut für Technologie},
  title={Towards Automatic Recognition of Personality for Human-Machine Interaction},
  year={2009},
  supervisor={Putze, Felix and Schultz, Tanja},
  author={Heger, Dominic}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_1269.php}
@diplomathesis{amma2009airwriting,
  school={Karlsruher Institut für Technologie},
  title={Airwriting Recognition using Wearable Motion Sensors},
  year={2009},
  supervisor={Gehrig, Dirk and Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/DA_Amma.pdf},
  author={Amma, Christoph}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_2065.php}
@diplomathesis{stoimenov2009static,
  school={Karlsruher Institut für Technologie},
  year={2009},
  title={Static Search Space Modeling for Speech Recognition},
  supervisor={Schultz, Tanja},
  author={Stoimenov, Emilian}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_2045.php}
@diplomathesis{vu2009entwicklung,
  school={Karlsruher Institut für Technologie},
  year={2009},
  title={Entwicklung eines vietnamesischen Spracherkennungssysems für groe Vokabulare},
  supervisor={Schultz, Tanja and Schlippe, Tim},
  author={Vu, Ngoc Thang}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_1274.php}
@diplomathesis{dahlmeier2008investigations,
  school={Karlsruher Institut für Technologie},
  title={Investigations into the Use of Preposition Sense in Semantic Argument Classification},
  year={2008},
  supervisor={Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/DA-DanielDahlmeier.pdf},
  author={Dahlmeier, Daniel}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_1273.php}
@diplomathesis{schaaff2008eeg,
  school={Karlsruher Institut für Technologie},
  title={EEG-based Emotion Recognition},
  year={2008},
  supervisor={Wand, Michael and Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/DA-schaaff.pdf},
  author={Schaaff, Kristina}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_1275.php}
@comment{Additional data: Institut für Theoretische Informatik, Lehrstuhl Prof. Waibel, Universität Karlsruhe}
@diplomathesis{wester2006unspoken,
  school={Karlsruher Institut für Technologie},
  year={2006},
  title={Unspoken Speech - Speech Recognition based on Electroencephalography},
  supervisor={Schultz, Tanja},
  author={Wester, Marek}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_1276.php}
@comment{Additional data: Institut für Theoretische Informatik, Lehrstuhl Prof. Waibel, Universität Karlsruhe}
@diplomathesis{honal2005determining,
  school={Karlsruher Institut für Technologie},
  year={2005},
  title={Determining User State and Mental Task Demand from Electroencephalograpic Data},
  supervisor={Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/DA-Honal.pdf},
  author={Honal, Matthias}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_1277.php}
@comment{Additional data: Institut für Theoretische Informatik, Lehrstuhl Prof. Waibel, Universität Karlsruhe}
@diplomathesis{maier-hein2005speech,
  school={Karlsruher Institut für Technologie},
  year={2005},
  title={Speech Recognition using Surface Electromyography},
  supervisor={Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/DA-MaierHein.pdf},
  author={Maier-Hein, Lena}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_1278.php}
@comment{Additional data: Institut für Theoretische Informatik, Lehrstuhl Prof. Waibel, Universität Karlsruhe}
@diplomathesis{paulik2005machine,
  school={Karlsruher Institut für Technologie},
  title={Machine Translation Enhanced Automatic Speech Recognition},
  year={2005},
  supervisor={Fügen, Christian and Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/DA-Paulik.pdf},
  author={Paulik, Matthias}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_1280.php}
@comment{Additional data: Institut für Logik, Komplexität und Deduktionssysteme, Lehrstuhl Prof. Waibel, Universität Karlsruhe}
@diplomathesis{stüker2003multilingual,
  school={Karlsruher Institut für Technologie},
  title={Multilingual Articulatory Features},
  year={2003},
  supervisor={Metze, Florian and Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/DA-stueker.pdf},
  author={Stüker, Sebastian}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_1281.php}
@comment{Additional data: Institut für Logik, Komplexität und Deduktionssysteme, Lehrstuhl Prof. Waibel, Universität Karlsruhe}
@diplomathesis{abu-alwan2000arabic,
  school={Karlsruher Institut für Technologie},
  title={Arabic Speech Recognition},
  year={2000},
  supervisor={Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/DA-raschke.ps.gz},
  author={Abu-Alwan, Jamal}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_1282.php}
@comment{Additional data: Institut für Logik, Komplexität und Deduktionssysteme, Lehrstuhl Prof. Waibel, Universität Karlsruhe}
@diplomathesis{kiecza1999datengetriebene,
  school={Karlsruher Institut für Technologie},
  year={1999},
  title={Datengetriebene Bestimmung von Wörterbucheinheiten für koreanische Spracherkennung auf groen Wortschätzen (Data-driven determination of appropriate dictionary units for Korean LVCSR)},
  supervisor={Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/DA-kiecza.ps.gz},
  author={Kiecza, Daniel}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_1283.php}
@comment{Additional data: Institut für Logik, Komplexität und Deduktionssysteme, Lehrstuhl Prof. Waibel, Universität Karlsruhe}
@diplomathesis{reichert1998spracherkennung,
  school={Karlsruher Institut für Technologie},
  title={Spracherkennung im Chinesischen},
  year={1998},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/DA-reichert.ps.gz},
  author={Reichert, Jürgen}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_1284.php}
@comment{Additional data: Institut für Logik, Komplexität und Deduktionssysteme, Lehrstuhl Prof. Waibel, Universität Karlsruhe}
@diplomathesis{Çarki1998entwicklung,
  school={Karlsruher Institut für Technologie},
  year={1998},
  title={Entwicklung eines türkischen Spracherkennungssystems für groe Vokabulare},
  supervisor={Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/DA-carki.ps.gz},
  author={Çarki, Kenan}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_1285.php}
@comment{Additional data: Institut für Logik, Komplexität und Deduktionssysteme, Lehrstuhl Prof. Waibel, Universität Karlsruhe}
@diplomathesis{soltau1997erkennung,
  school={Karlsruher Institut für Technologie},
  title={Erkennung von Musikstilen},
  year={1997},
  supervisor={Schultz, Tanja},
  author={Soltau, Hagen}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/diplomarbeiten_1286.php}
@comment{Additional data: Institut für Logik, Komplexität und Deduktionssysteme, Lehrstuhl Prof. Waibel, Universität Karlsruhe}
@diplomathesis{schultz1995identifizierung,
  school={Karlsruher Institut für Technologie},
  title={Identifizierung von Sprachen -Exemplarisch aufgezeigt am Beispiel der Sprachen Deutsch, Englisch und Spanisch},
  year={1995},
  supervisor={Rogina, Ivica},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/schultz_DA.pdf http://www.csl.uni-bremen.de/cms/images/documents/publications/schultz_DA.ps.gz},
  author={Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2919.php}
@inproceedings{stahlberg2015cross,
  note={ICASSP 2015},
  title={Cross-lingual Lexical Language Discovery from Audio Data Using Multiple Translations},
  year={2015},
  booktitle={The 40th International Conference on Acoustics, Speech, and Signal Processing, Brisbane, Australia},
  author={Stahlberg, Felix and Schlippe, Tim and Vogel, Stephan and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2912.php}
@inproceedings{georgi2015recognizing,
  note={BIOSIGNALS 2015},
  year={2015},
  title={Recognizing Hand and Finger Gestures with IMU based Motion and EMG based Muscle Activity Sensing},
  booktitle={International Conference on Bio-inspired Systems and Signal Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/GeorgiAmmaSchultz_RecognizingHandAndFingerGesturesWithIMUBasedMotionAndEMGBasedMuscleActivitySensing.pdf},
  author={Georgi, Marcus and Amma, Christoph and Schultz, Tanja},
  doi={10.5220/0005276900990108},
  pages={99-108}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2904.php}
@inproceedings{srisuwan2014enhancement,
  title={Enhancement of EMG-based Thai Number Words Classification using Frame-based Time Domain Feature with Stacking Filter},
  year={2014},
  booktitle={Proceedings of 2014 APSIPA Annual Summit and Conference},
  abstract={In order to overcome a problem existing in a classical automatic speech recognition (e.g. ambient noise and loss of privacy), Electromyography (EMG) from speech production muscles was used in place of a human speech signal. We aim to investigate the EMG speech recognition based on Thai language. The earlier work, we used five channels of the EMG from the facial and neck muscles to classify 11 Thai number words based on Neural Network Classification. 15 features in time domain and frequency domain were employed for feature extraction. We obtained an average accuracy rate of 89.45% for audible speech and 78.55% for silent speech. However, it needs to be enhanced to get the best result. This paper proposes to improve an accuracy rate of EMG-based Thai number words classification. The ten subjects uttered 11 words in both an audible and a silent speech while five channels of the EMG signal were captured. Frame-based time domain features with a stacking filter was performed for feature extraction stage. After that, LDA was used to lessen a dimension of the feature vector. Hidden Markov Model (HMM) was employed in classification stage. The results show that using above techniques of feature extraction, feature dimensionality reduction and classification can improve an average accuracy rate by 3% absolute for audible speech when were compared to earlier work. We achieved an average classification rate of 92.45% and 75.73% for audible and silent speech respectively.},
  author={Srisuwan, Niyawadee Jib and Limsakul, Chusak and Phukpattaranont, Pornchai and Schultz, Tanja and Wand, Michael and Janke, Matthias}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2879.php}
@inproceedings{wand2014pattern,
  year={2014},
  title={Pattern Learning with Deep Neural Networks in EMG-based Speech Recognition},
  note={EMBC 2014},
  booktitle={36th Annual International Conference of the IEEE Engineering in Medicine  and Biology Society},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Wand_EMBC14_DNN_EMGSpeechRecognition.pdf},
  author={Wand, Michael and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2861.php}
@inproceedings{wand2014towards,
  title={Towards Real-life Application of EMG-based Speech Recognition by using Unsupervised Adaptation},
  year={2014},
  note={Interspeech 2014},
  booktitle={The 15th Annual Conference of the International     Speech Communication Association, Singapore},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/WandSchultz_IS14_EMGSpeechRecognitionUnsupervisedAdaptation.pdf},
  author={Wand, Michael and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2860.php}
@inproceedings{wand2014the,
  year={2014},
  title={The EMG-UKA Corpus for Electromyographic Speech Processing},
  note={Interspeech 2014},
  booktitle={The 15th Annual Conference of the International Speech Communication Association, Singapore},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/WandJankeSchultz_IS14_EMG-UKA-Corpus.pdf},
  abstract={This article gives an overview of the EMG-UKA corpus, a corpus of electromyographic (EMG) recordings of articulatory activity enabling speech processing (in particular speech recognition and synthesis) based on EMG signals, with the purpose of building Silent Speech interfaces. Data is available in multiple speaking modes, namely audibly spoken, whispered, and silently articulated speech. Besides the EMG data, synchronous acoustic data was additionally recorded to serve as a reference. The corpus comprises 63 recorded sessions from 8 speakers, the total amount of data is 7:32 hours. A trial subset, consisting of 1:52 hours of data, is freely available for download.},
  author={Wand, Michael and Janke, Matthias and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2858.php}
@inproceedings{zahner2014conversion,
  note={Interspeech 2014},
  year={2014},
  title={Conversion from Facial Myoelectric Signals to Speech: A Unit Selection Approach},
  booktitle={The 15th Annual Conference of the International     Speech Communication Association, Singapore},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/ZahnerJankeWandSchultz_IS14_MyoelectricSignalsUnitSelection.pdf},
  abstract={This  paper  reports  on  our  recent  research  on  surface  electromyographic (EMG) speech synthesis: a direct conversion of the EMG signals of the articulatory muscle movements to the acoustic speech signal.  In this work we introduce a unit selection approach which compares segments of the input EMG signal to a database of simultaneously recorded EMG/audio unit pairs and selects the best matching audio unit based on target and concatenation cost, which will be concatenated to synthesize an acoustic speech output.  We show that this approach is feasible to generate a proper speech output from the input EMG signal. We evaluate different properties of the units and investigate what amount of data is necessary for an initial transformation.  Prior work on EMG-to-speech conversion used a framebased approach from the voice conversion domain, which struggles with the generation of a natural $F_0$ contour. This problem may also be tackled by our unit selection approach.},
  author={Zahner, Marlene and Janke, Matthias and Wand, Michael and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2856.php}
@inproceedings{vu2014investigating,
  year={2014},
  title={Investigating the Learning Effect of Multilingual Bottle-Neck Features for ASR},
  note={Interspeech 2014},
  booktitle={The 15th Annual Conference of the International Speech Communication Association, Singapore},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/354_Paper.pdf},
  author={Vu, Ngoc Thang and Weiner, Jochen and Schultz, Tanja},
  abstract={Deep  neural  networks  (DNNs)  have  become  state-of-the-art techniques of automatic speech recognition in the last few years. They can be used at the preprocessing level (Tandem or Bottle-Neck features) or at the acoustic model level (hybrid Hidden Markov  Model/DNN).  Moreover,  they  allow  exploiting  multilingual  data  to  improve  monolingual systems. This paper presents our investigation of the learning effect of neural networks in the context of multilingual Bottle-Neck features.  For this, we perform a visual analysis of the output of the Bottle-Neck layer  of  a  neural  network  using  t-Distributed  Stochastic  Neighbor  Embedding.   Our  results  show  that  multilingual Bottle-Neck  features  seem  to  learn  phoneme  characteristics, such  as  the F1 and F2 formants  which  characterize  different vowels,  and other articulatory features,  such as fricatives and nasals which characterize consonants.  Furthermore, they seem to  normalize  language  dependent  variations  and  transfer  the learned representation to unseen languages.}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2854.php}
@inproceedings{vu2014improving,
  year={2014},
  title={Improving ASR Performance On Non-native Speech Using Multilingual and Crosslingual Information},
  note={Interspeech 2014},
  booktitle={The 15th Annual Conference of the International Speech Communication Association, Singapore},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/vu_interspeech2014_final.pdf},
  author={Vu, Ngoc Thang and Wang, Yuanfan and Klose, Marten and Mihaylova, Zlatka and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2828.php}
@inproceedings{adel2014combining,
  note={Interspeech 2014},
  year={2014},
  title={Combining Recurrent Neural Networks and Factored Language Models During Decoding of Code-Switching Speech},
  booktitle={The 15th Annual Conference of the International Speech Communication Association, Singapore},
  author={Adel, Heike and Telaar, Dominic and Vu, Ngoc Thang and Kirchhoff, Katrin and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2827.php}
@inproceedings{adel2014comparing,
  title={Comparing Approaches to Convert Recurrent Neural Networks into Backoff Language Models For Efficient Decoding},
  year={2014},
  note={Interspeech 2014},
  booktitle={The 15th Annual Conference of the International Speech Communication Association, Singapore},
  author={Adel, Heike and Kirchhoff, Katrin and Vu, Ngoc Thang and Telaar, Dominic and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2776.php}
@inproceedings{schlippe2014methods,
  note={Interspeech 2014},
  year={2014},
  title={Methods for Efficient Semi-Automatic Pronunciation Dictionary Bootstrapping},
  booktitle={The 15th Annual Conference of the International Speech Communication Association, Singapore},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Interspeech2014-Schlippe_SemiAutomaticDictBootstrapping.pdf},
  author={Schlippe, Tim and Merz, Matthias and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2775.php}
@inproceedings{telaar2014biokit,
  title={BioKIT - Real-time Decoder For Biosignal Processing},
  year={2014},
  note={Interspeech 2014},
  booktitle={The 15th Annual Conference of the International Speech Communication Association, Singapore},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/TelaarEtAl_IS14_BioKIT.pdf},
  abstract={We introduce BioKIT, a new Hidden Markov Model based toolkit to preprocess, model and interpret biosignals such as speech, motion, muscle and brain activities. The focus of this toolkit is to enable researchers from various communities to pursue their experiments and integrate real-time biosignal interpretation into their applications. BioKIT boosts a flexible two-layer structure with a modular C++ core that interfaces with a Python scripting layer, to facilitate development of new applications.  BioKIT employs sequence-level parallelization and memory sharing across threads. Additionally, a fully integrated error blaming component facilitates in-depth analysis. A generic terminology keeps the barrier to entry for researchers from multiple fields to a minimum. We describe our online-capable dynamic decoder and report on initial experiments on three different tasks. The presented speech recognition experiments employ Kaldi trained deep neural networks with the results set in relation to the real time factor needed to obtain them.},
  author={Telaar, Dominic and Wand, Michael and Gehrig, Dirk and Putze, Felix and Amma, Christoph and Heger, Dominic and Vu, Ngoc Thang and Erhardt, Mark and Schlippe, Tim and Janke, Matthias and Herff, Christian and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2763.php}
@INPROCEEDINGS{6944010,
author={Heger, D. and Herff, C. and Schultz, T.},
booktitle={Engineering in Medicine and Biology Society (EMBC), 2014 36th Annual International Conference of the IEEE},
title={Combining feature extraction and classification for fNIRS BCIs by regularized least squares optimization},
year={2014},
pages={2012-2015},
abstract={In this paper, we show that multiple operations of the typical pattern recognition chain of an fNIRS-based BCI, including feature extraction and classification, can be unified by solving a convex optimization problem. We formulate a regularized least squares problem that learns a single affine transformation of raw HbO2 and HbR signals. We show that this transformation can achieve competitive results in an fNIRS BCI classification task, as it significantly improves recognition of different levels of workload over previously published results on a publicly available n-back data set. Furthermore, we visualize the learned models and analyze their spatio-temporal characteristics.},
keywords={affine transforms;biochemistry;bioelectric potentials;brain-computer interfaces;electroencephalography;feature extraction;feature selection;infrared spectra;least mean squares methods;medical signal processing;molecular biophysics;optimisation;oxygen;proteins;spatiotemporal phenomena;O2;affine transformation;convex optimization problem;deoxygenated hemoglobin signals;fNIRS BCI classification task;feature classification;feature extraction;functional near-infrared spectroscopy;pattern recognition chain;regularized least squares optimization;spatiotemporal characteristic analysis;Analytical models;Brain models;Data models;Feature extraction;Optimization;Predictive models},
doi={10.1109/EMBC.2014.6944010},
ISSN={1557-170X},
month={Aug},}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2757.php}
@inproceedings{putze2013profiling,
  title={Profiling Arousal in Response to Complex Stimuli using Biosignals},
  year={2013},
  booktitle={International Conference on Bio-inspired Systems and Signal Processing 2013},
  author={Putze, Felix and Heger, Dominic and Müller, M. and Kajic, Ivana and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2756.php}
@inproceedings{putze2013session,
  year={2013},
  title={Session-independent EEG-based Workload Recognition},
  booktitle={International Conference on Bio-inspired Systems and Signal Processing 2013},
  author={Putze, Felix and Müller, M. and Heger, Dominic and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2755.php}
@INPROCEEDINGS{6853962,
author={Heger, D. and Terziyska, E. and Schultz, T.},
booktitle={Acoustics, Speech and Signal Processing (ICASSP), 2014 IEEE International Conference on},
title={Connectivity based feature-level filtering for single-trial EEG BCIs},
year={2014},
pages={2064-2068},
abstract={EEG-based Brain Computer interfaces (BCIs) often rely on power spectral density features to represent relevant aspects of brain activity. The information flow within human brain networks and the corresponding connectivity patterns may contain useful information to improve BCI performance, however they are typically not leveraged in current systems. In this paper, analyzes of information flow between independent sources of brain activity have been incorporated into the feature extraction stage of a BCI. For this purpose, connectivity measures based on multivariate autoregressive models have been estimated and are applied as filters to power spectral density based features. Two publicly available data sets have been used to evaluate the proposed feature extraction method: a two-back task and a motor imagery task. The results demonstrate significant performance improvements of the proposed method over band-power features and indicate that connectivity in brain networks can be used as powerful feature-level filters for BCIs.},
keywords={autoregressive processes;brain;brain-computer interfaces;electroencephalography;feature extraction;medical signal processing;EEG-based brain computer interfaces;band-power feature;brain activity;connectivity measure;connectivity pattern;electroencephalography;feature extraction method;feature-level filtering;human brain network;information flow;motor imagery task;multivariate autoregressive model;power spectral density feature;publicly available data set;single-trial EEG BCIs;two-back task;Brain models;Electroencephalography;Feature extraction;Time series analysis;Transfer functions;Connectivity;Granger causality;brain-computer interfaces;direct directed transfer function;electroencephalography},
doi={10.1109/ICASSP.2014.6853962},

month={May},}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2722.php}
@inproceedings{schultz2014globalphone,
  title={GlobalPhone: Pronunciation Dictionaries in 20 Languages},
  year={2014},
  note={LREC 2014},
  booktitle={The 9th edition of the Language Resources and Evaluation Conference, Reykjavik, Iceland},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/LREC2014-SchultzSchlippe_GlobalPhoneDicts.pdf},
  author={Schultz, Tanja and Schlippe, Tim}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2721.php}
@inproceedings{schlippe2014combining,
  note={SLTU 2014},
  title={Combining Grapheme-to-Phoneme Converter Outputs for Enhanced Pronunciation Generation in Low-Resource Scenarios},
  year={2014},
  booktitle={The 4th Workshop on Spoken Language Technologies for Under-resourced Languages, St. Petersburg, Russia},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SLTU2014-Schlippe_G2PConverterOutputCombination.pdf},
  author={Schlippe, Tim and Quaschningk, Wolf and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2720.php}
@inproceedings{leidig2014automatic,
  title={Automatic Detection of Anglicisms for the Pronunciation Dictionary Generation: A Case Study on our German IT Corpus},
  year={2014},
  note={SLTU 2014},
  booktitle={The 4th Workshop on Spoken Language Technologies for Under-resourced Languages, St. Petersburg, Russia},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SLTU2014-LeidigSchlippe_AnglicismDetection.pdf},
  author={Leidig, Sebastian and Schlippe, Tim and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2719.php}
@inproceedings{stahlberg2014towards,
  year={2014},
  title={Towards Automatic Speech Recognition without Pronunciation Dictionary, Transcribed Speech and Text Resources in the Target Language using Cross-Lingual Word-to-Phoneme Alignment},
  note={SLTU 2014},
  booktitle={The 4th Workshop on Spoken Language Technologies for Under-resourced Languages, St. Petersburg, Russia},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SLTU2014-StahlbergSchlippe_ASRWithoutResources.pdf},
  author={Stahlberg, Felix and Schlippe, Tim and Vogel, Stephan and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2718.php}
@inproceedings{adel2014features,
  title={Features for Factored Language Models for Code-Switching Speech},
  year={2014},
  note={SLTU 2014},
  booktitle={The 4th Workshop on Spoken Language Technologies for Under-resourced Languages, St. Petersburg, Russia},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/2768.php},
  author={Adel, Heike and Kirchhoff, Kartin and Telaar, Dominic and Vu, Ngoc Thang and Schlippe, Tim and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2682.php}
@inproceedings{janke2014fundamental,
  year={2014},
  title={Fundamental Frequency Generation for Whisper-to-Audible Speech Conversion},
  note={ICASSP 2014},
  booktitle={The 39th International Conference on Acoustics, Speech, and Signal Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Janke_ICASSP14_F0GenerationWhisper.pdf},
  abstract={In this work, we address the issues involved in whisper-to-audible speech conversion. Spectral mapping techniques using Gaussian mixture models or Artificial Neural Networks borrowed from voice conversion have been applied to transform whisper spectral features to normally phonated audible speech. However, the modeling and generation of fundamental frequency ($F_0$) and its contour in the converted speech is a major issue. Whispered speech does not contain explicit voicing characteristics and hence it is hard to derive a suitable $F_0$, making it difficult to generate a natural prosody after conversion. Our work addresses the $F_0$ modeling in whisper-to-speech conversion. We show that $F_0$ contours can be derived from the mapped spectral vectors, which can be used for the synthesis of a speech signal. We also present a hybrid unit selection approach for whisper-to-speech conversion. Unit selection is performed on the spectral vectors, where $F_0$ and its contour can be obtained as a byproduct without any additional modeling.},
  author={Janke, Matthias and Prahallad, Kishore and Wand, Michael and Heistermann, Till and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2678.php}
@inproceedings{wand2014compensation,
  title={Compensation of Recording Position Shifts for a Myoelectric Silent Speech Recognizer},
  year={2014},
  note={ICASSP 2014},
  booktitle={The 39th International Conference on Acoustics, Speech, and Signal Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Wand_ICASSP14_EMGArrayShift.pdf},
  abstract={A myoelectric Silent Speech Recognizer is a system which recognizes speech by capturing the electrical activity of the human articulatory muscles, thus enabling the user to communicate silently. We recently devised a recording setup based on electrode arrays with multiple measuring points. In this study we show that this allows to compensate for shifts of the recording position, which happen when the array is removed and reattached between system training and application. We present a method which determines the amount of recording position shift; compensation is performed by linear interpolation. We evaluate our method by running recognition experiments across recording sessions and obtain a Word Error Rate improvement of 14.3% relative on the development set and 12.9% relative on the evaluation set, compared to using classical session adaptation.},
  author={Wand, Michael and Schulte, Christopher and Janke, Matthias and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2658.php}
@inproceedings{heistermann2014spatial,
  title={Spatial Artifact Detection for Multi-Channel EMG-Based Speech Recognition},
  year={2014},
  note={BIOSIGNALS 2014},
  booktitle={7th International Conference on Bio-inspired Systems and Signal Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Heistermann_et_al_BS2014_SpatialArtifactDetection.pdf},
  abstract={We introduce a spatial artifact detection method for a surface electromyography (EMG) based speech recognition system. The EMG signals are recorded using grid-shaped electrode arrays affixed to the speakers face. Continuous speech recognition is performed on the basis of these signals. As the EMG data are high-dimensional, Independent Component Analysis (ICA) can be applied to separate artifact components from the content-bearing signal. The proposed artifact detection method classifies the ICA components by their spatial shape, which is analyzed using the spectra of the spatial patterns of the independent components. Components identified as artifacts can then be removed. Our artifact detection method reduces the word error rates (WER) of the recognizer significantly. We observe a slight advantage in terms of WER over the temporal signal based artifact detection method by (Wand et al., 2013a).},
  author={Heistermann, Till and Janke, Matthias and Wand, Michael and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2668.php}
@inproceedings{putze2013reliable,
  year={2013},
  title={Reliable Subject-Adapted Recognition of EEG Error Potentials Using Limited Calibration Data},
  booktitle={International IEEE EMBS Neural Engineering Conference 2013, San Diego, USA},
  author={Putze, Felix and Heger, Dominic and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2666.php}
@inproceedings{Putze:2013:LUA:2449396.2449415,
author = {Putze, Felix and Hild, Jutta and K\"{a}rgel, Rainer and Herff, Christian and Redmann, Alexander and Beyerer, J\"{u}rgen and Schultz, Tanja},
title = {Locating User Attention Using Eye Tracking and EEG for Spatio-temporal Event Selection},
booktitle = {Proceedings of the 2013 International Conference on Intelligent User Interfaces},
series = {IUI '13},
year = {2013},
 isbn = {978-1-4503-1965-2},
 location = {Santa Monica, California, USA},
 pages = {129--136},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/2449396.2449415},
 doi = {10.1145/2449396.2449415},
 acmid = {2449415},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {eeg, event detection, expert video analysis, eye tracking},
 }

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2524.php}
@INPROCEEDINGS{6681548,
author={Heger, D. and Mutter, R. and Herff, C. and Putze, F. and Schultz, T.},
booktitle={Affective Computing and Intelligent Interaction (ACII), 2013 Humaine Association Conference on},
title={Continuous Recognition of Affective States by Functional Near Infrared Spectroscopy Signals},
year={2013},
pages={832-837},
abstract={Functional near infrared spectroscopy (fNIRS) is becoming more and more popular as an innovative imaging modality for brain computer interfaces. A continuous (i.e. asynchronous) affective state monitoring system using fNIRS signals would be highly relevant for numerous disciplines, including adaptive user interfaces, entertainment, biofeedback, and medical applications. However, only stimulus-locked emotion recognition systems have been proposed by now. fNRIS signals of eight subjects at eight prefrontal locations have been recorded in response to three different classes of affect induction by emotional audio-visual stimuli and a neutral class. Our system evaluates short windows of five seconds length to continuously recognize affective states. We analyze hemodynamic responses, present a careful evaluation of binary classification tasks and investigate classification accuracies over the time.},
keywords={audio-visual systems;haemodynamics;infrared spectra;pattern classification;physiology;psychology;signal classification;adaptive user interfaces;affect induction;asynchronous affective state monitoring system;binary classification task accuracies;biofeedback application;brain computer interface;continuous affective state recognition;emotional audio-visual stimuli;entertainment application;fNRIS signal recording;functional near infrared spectroscopy signals;hemodynamic response analysis;imaging modality;medical application;neutral class;prefrontal locations;short-window evaluation;stimulus-locked emotion recognition systems;Accuracy;Detectors;Emotion recognition;Feature extraction;Hemodynamics;Monitoring;Training data;affective states;asynchronous;continuous recognition;emotion recognition;fNIRS;functional Near Infrared Spectroscopy},
url={https://www.csl.uni-bremen.de/cms/images/documents/publications/acii13_paper.pdf},
doi={10.1109/ACII.2013.156},
ISSN={2156-8103},
month={Sept},}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2510.php}
@inproceedings{nallasamy2012active,
  year={2012},
  title={Active Learning for Accent Adaptation in Automatic Speech Recognition},
  note={SLT 2012},
  booktitle={The Fourth IEEE Workshop on Spoken Language Technology},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SLT2012_UdhayNallasamy.pdf},
  author={Nallasamy, Udhyakumar and Metze, Florian and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2504.php}
@inproceedings{amma2013compressed,
  note={UbiComp 2013},
  year={2013},
  title={Compressed Signal Representation for Inertial Sensor Signals},
  booktitle={2013 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
  author={Amma, Christoph and Volk, Hannes and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2498.php}
@inproceedings{adel2013combination,
  title={Combination of Recurrent Neural Networks and Factored Language Models for Code-Switching Language Modeling},
  year={2013},
  note={ACL 2013},
  booktitle={The 51st Annual Meeting of the Association for Computational Linguistics, Sofia, Bulgaria},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Adel_Vu_ACL_2013.pdf},
  author={Adel, Heike and Vu, Ngoc Thang and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2496.php}
@inproceedings{premkumar2013experiments,
  note={Interspeech 2013},
  year={2013},
  title={Experiments towards a better LVCSR System for Tamil},
  booktitle={14th Annual Conference of the International Speech Communication Association, Lyon, France},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/tamil_interspeech2013.pdf},
  author={Premkumar, Melvin Jose Johnson and Vu, Ngoc Thang and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2487.php}
@inproceedings{vu2013an,
  title={An Investigation of Code-Switching Attitude Dependent Language Modeling},
  year={2013},
  note={SLSP 2013},
  booktitle={The 1st International Conference on Statistical Language and Speech Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/vu_adel_slsp2013.pdf},
  author={Vu, Ngoc Thang and Adel, Heike and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2485.php}
@inproceedings{vu2013multilingual,
  note={Interspeech 2013},
  title={Multilingual Multilayer Perceptron For Rapid Language Adaptation Between and Across Language Families},
  year={2013},
  booktitle={14th Annual Conference of the International Speech Communication Association, Lyon, France},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/vu_mlp_interspeech2013.pdf},
  author={Vu, Ngoc Thang and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2423.php}
@inproceedings{schlippe2013unsupervised,
  note={Interspeech 2013},
  title={Unsupervised Language Model Adaptation for Automatic Speech Recognition of Broadcast News Using Web 2.0},
  year={2013},
  booktitle={14th Annual Conference of the International Speech Communication Association, Lyon, France},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Interspeech2013-Schlippe_LMAdaptationWeb2.0.pdf},
  author={Schlippe, Tim and Gren, Lukasz and Vu, Ngoc Thang and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2371.php}
@inproceedings{telaar2013accent,
  title={Accent- and Speaker-Specific Polyphone Decision Trees for Non-Native Speech Recognition},
  year={2013},
  booktitle={14th Annual Conference of the International Speech Communication Association, Lyon, France},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/telaarInterspeech2013.pdf},
  author={Telaar, Dominic and Fuhs, Mark C.}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2285.php}
@inproceedings{wand2013artifact,
  year={2013},
  title={Artifact Removal Algorithm for an EMG-based Silent Speech Interface},
  note={EMBC 2013},
  booktitle={International Conference of the IEEE Engineering in Medicine and Biology Society, Osaka, Japan},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/WandSchultz_EMBC2013.pdf},
  abstract={An electromygraphic (EMG) Silent Speech Interface is a system which recognizes speech by capturing the electric potentials of the human articulatory muscles, thus enabling the user to communicate silently. This study deals with improving the EMG signal quality by removing artifacts: The EMG signals are captured by electrode arrays with multiple measuring points. On the resulting high-dimensional signal, Independent Component Analysis is performed, and artifact components are automatically detected and removed. This method reduces the Word Error Rate of the silent speech recognizer by 9.9% relative on a development corpus, and by 13.9% relative on an evaluation corpus.},
  author={Wand, Michael and Himmelsbach, Adam and Heistermann, Till and Janke, Matthias and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2287.php}
@INPROCEEDINGS{6610823,
author={Heger, D. and Putze, F. and Herff, C. and Schultz, T.},
booktitle={Engineering in Medicine and Biology Society (EMBC), 2013 35th Annual International Conference of the IEEE},
title={Subject-to-subject transfer for CSP based BCIs: Feature space transformation and decision-level fusion},
year={2013},
pages={5614-5617},
abstract={Modern Brain Computer Interfaces (BCIs) usually require a calibration session to train a machine learning system before each usage. In general, such trained systems are highly specialized to the subject's characteristic activation patterns and cannot be used for other sessions or subjects. This paper presents a feature space transformation that transforms features generated using subject-specific spatial filters into a subject-independent feature space. The transformation can be estimated from little adaptation data of the subject. Furthermore, we combine three different Common Spatial Pattern based feature extraction approaches using decision-level fusion, which enables BCI use when little calibration data is available, but also outperformed the subject-dependent reference approaches for larger amounts of training data.},
keywords={brain-computer interfaces;calibration;feature extraction;learning (artificial intelligence);sensor fusion;spatial filters;brain computer interfaces;calibration;common spatial patterns;decision-level fusion;feature extraction;feature space transformation;machine learning system;subject-independent feature space;subject-specific spatial filters;subject-to-subject transfer;Brain-computer interfaces;Calibration;Electroencephalography;Feature extraction;Testing;Training;Transforms},
url={https://www.csl.uni-bremen.de/cms/images/documents/publications/EMBC13_2191_FI.pdf},
doi={10.1109/EMBC.2013.6610823},
ISSN={1557-170X},
month={July},}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2283.php}
@INPROCEEDINGS{6609962,
author={Herff, C. and Heger, D. and Putze, F. and Hennrich, J. and Fortmann, O. and Schultz, T.},
booktitle={Engineering in Medicine and Biology Society (EMBC), 2013 35th Annual International Conference of the IEEE},
title={Classification of mental tasks in the prefrontal cortex using fNIRS},
year={2013},
pages={2160-2163},
abstract={Functional near infrared spectroscopy (fNIRS) is rapidly gaining interest in both the Neuroscience, as well as the Brain-Computer-Interface (BCI) community. Despite these efforts, most single-trial analysis of fNIRS data is focused on motor-imagery, or mental arithmetics. In this study, we investigate the suitability of different mental tasks, namely mental arithmetics, word generation and mental rotation for fNIRS based BCIs. We provide the first systematic comparison of classification accuracies achieved in a sample study. Data was collected from 10 subjects performing these three tasks. An optode template with 8 channels was chosen which covers the prefrontal cortex and only requires less than 3 minutes for setup. Two-class accuracies of up to 71% average across all subjects for mental arithmetics, 70% for word generation and 62% for mental rotation were achieved discriminating these tasks from a relax state. We thus lay the foundation for fNIRS based BCI using additional mental strategies than motor imagery and mental arithmetics. The tasks were chosen in a way that they might be used for user state monitoring, as well.},
keywords={arithmetic;biomedical equipment;brain-computer interfaces;cognition;feature extraction;fibre optic sensors;infrared spectroscopy;medical signal processing;neurophysiology;patient monitoring;signal classification;brain-computer interface;classification accuracy;fNIRS based BCI;fNIRS data single-trial analysis;functional near infrared spectroscopy;mental arithmetics;mental rotation;mental strategy;mental task classification;motor imagery;motor-imagery;neuroscience;optode template channel;prefrontal cortex;relax state;user state monitoring;word generation;Accuracy;Electroencephalography;Feature extraction;Hemodynamics;Neuroscience;Spectroscopy;Systematics},
url={https://www.csl.uni-bremen.de/cms/images/documents/publications/HerffSchultz_EMBC2013.pdf},
doi={10.1109/EMBC.2013.6609962},
ISSN={1557-170X},
month={July},}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2280.php}
@inproceedings{heger2013towards,
  title={Towards Biometric Person Identification using fNIRS},
  year={2013},
  booktitle={International BCI Meeting 2013, Asilomar, USA},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/heger_towards_biometric_BCI-meeting_2013_USletter.pdf},
  author={Heger, Dominic and Herff, Christian and Putze, Felix and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2278.php}
@inproceedings{herff2013self,
  title={Self-paced BCI with NIRS based on speech activity},
  year={2013},
  booktitle={International BCI Meeting 2013, Asilomar, USA},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/HerffSchultz_BCIMEETING2013.pdf},
  author={Herff, Christian and Heger, Dominic and Putze, Felix and Guan, Cuntai and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2275.php}
@inproceedings{stahlberg2013pronunciation,
  note={SLSP 2013},
  title={Pronunciation Extraction from Phoneme Sequences through Cross-Lingual Word-to-Phoneme Alignment},
  year={2013},
  booktitle={The 1st International Conference on Statistical Language and Speech Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SLSP2013-StahlbergSchlippe_PronunciationExtraction.pdf},
  author={Stahlberg, Felix and Schlippe, Tim and Vogel, Stephan and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2274.php}
@inproceedings{schlippe2013rapid,
  note={ICASSP 2013},
  title={Rapid Bootstrapping of a Ukrainian Large Vocabulary Continuous Speech Recognition System},
  year={2013},
  booktitle={The 38th International Conference on Acoustics, Speech, and Signal Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/ICASSP2013-Schlippe_UkrainianLVCSR.pdf},
  author={Schlippe, Tim and Volovyk, Mykola and Yurchenko, Kateryna and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2273.php}
@inproceedings{schultz2013globalphone,
  note={ICASSP 2013},
  title={GlobalPhone: A Multilingual Text & Speech Database in 20 Languages},
  year={2013},
  booktitle={The 38th International Conference on Acoustics, Speech, and Signal Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/ICASSP2013-Schultz_GlobalPhone.pdf},
  author={Schultz, Tanja and Vu, Ngoc Thang and Schlippe, Tim}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2272.php}
@inproceedings{adel2013recurrent,
  year={2013},
  title={Recurrent Neural Network Language Modeling for Code Switching Conversational Speech},
  note={ICASSP 2013},
  booktitle={The 38th International Conference on Acoustics, Speech, and Signal Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/ICASSP2013-Adel_NNLM4CS.pdf},
  author={Adel, Heike and Vu, Ngoc Thang and Kraus, Franziska and Schlippe, Tim and Li, Haizhou and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2271.php}
@inproceedings{schlippe2013statistical,
  year={2013},
  title={Statistical Machine Translation based Text Normalization with Crowdsourcing},
  note={ICASSP 2013},
  booktitle={The 38th International Conference on Acoustics, Speech, and Signal Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/ICASSP2013-Schlippe_SMTTextNormalization.pdf},
  author={Schlippe, Tim and Zhu, Chenfei and Lemcke, Daniel and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2262.php}
@inproceedings{stahlberg2012word,
  title={Word Segmentation through Cross-Lingual Word-to-Phoneme Alignment},
  year={2012},
  note={SLT 2012},
  booktitle={The Fourth IEEE Workshop on Spoken Language Technology},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SLT2012-StahlbergSchlippe_Model3P.pdf},
  author={Stahlberg, Felix and Schlippe, Tim and Vogel, Stephan and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2200.php}
@inproceedings{rebelo2013activity,
  title={Activity Recognition for an Intelligent Knee Orthosis},
  year={2013},
  note={BIOSIGNALS 2013},
  booktitle={6th International Conference on Bio-inspired Systems and Signal Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/RebeloAmmaGamboaSchultz_Biosignals2013.pdf},
  author={Rebelo, Diliana and Amma, Christoph and Gamboa, Hugo and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2190.php}
@inproceedings{wand2013array,
  note={BIOSIGNALS 2013},
  title={Array-based Electromyographic Silent Speech Interface},
  year={2013},
  booktitle={6th International Conference on Bio-inspired Systems and Signal Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/BS13_WandSchulteJankeSchultz_ArrayBasedEMGSSI.pdf},
  abstract={An electromygraphic (EMG) Silent Speech Interface is a system which recognizes speech by capturing the electric potentials of the human articulatory muscles, thus enabling the user to communicate silently. This study is concerned with introducing an EMG recording system based on multi-channel electrode arrays. We first present our new system and introduce a method to deal with undertraining effects which emerge due to the high dimensionality of our EMG features. Second, we show that Independent Component Analysis improves the classification accuracy of the EMG array-based recognizer by up to 22.9% relative, which is a first example of an EMG signal processing method which is specifically enabled by our new array-based system. We evaluate our system on recordings of audible speech; achieving an optimal average word error rate of 10.9% with a training set of less than 10 minutes on a vocabulary of 108 words.},
  author={Wand, Michael and Schulte, Christopher and Janke, Matthias and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2163.php}
@inproceedings{amma2010emotionserkennung,
  title={Emotionserkennung auf der Basis von Gangmustern},
  year={2010},
  booktitle={Sportinformatik trifft Sporttechnologie, Tagung der dvs-Sektion Sportinformatik in Kooperation mit der Deutschen Interdisziplinären Vereinigung für Sporttechnologie},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Sportinformatik2010_Beitrag_Emotionserkennung_Christoph_Amma_et_al.pdf},
  author={Amma, Christoph and Fischer, Andreas and Stein, Thorsten and Schwameder, Hermann and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2162.php}
@inproceedings{schick2012vision,
  note={ICMI'14},
  year={2012},
  title={Vision-Based Handwriting Recognition for Unrestricted Text Input in Mid-Air},
  booktitle={14th ACM International Conference on Multimodal Interaction},
  author={Schick, Alexander and Morlock, Daniel and Amma, Christoph and Schultz, Tanja and Stiefelhagen, Rainer}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2128.php}
@inproceedings{j2012initial,
  title={Initial Experiments with Tamil LVCSR},
  year={2012},
  note={IALP},
  booktitle={The International Conference on Asian Language Processing, Hanoi, Vietnam},
  author={J, Melvin Jose and Vu, Ngoc Thang and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2125.php}
@inproceedings{povey2012generating,
  note={ICASSP},
  title={Generating Exact Lattices in the WFST Framework},
  year={2012},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/povey_lattice.pdf},
  author={Povey, Daniel and Hannemann, Mirko and Boulianne, Gilles and Burget, Lukas and Ghoshal, Arnab and Janda, Milos and Karafiat, Martin and Kombrink, Stefan and Motlicek, Petr and Qian, Yanmin and Riedhammer, Korbinian and Vesely, Karel and Vu, Ngoc Thang}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2107.php}
@inproceedings{weiner2012integration,
  title={Integration Of Language Identification Into A Recognition System For Spoken Conversations Containing Code-Switches},
  year={2012},
  note={SLTU'12},
  booktitle={The third International Workshop on Spoken Languages Technologies for Under-resourced Languages},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/weiner_vu_sltu2012.pdf},
  author={Weiner, Jochen and Vu, Ngoc Thang and Telaar, Dominic and Metze, Florian and Schultz, Tanja and Lyu, Dau-Cheng and Li, Eng-Siong Chng and Haizhou},
  abstract={This paper describes the integration of language identification (LID) into a multilingual automatic speech recognition (ASR) system  for  spoken  conversations  containing  code-switches between Mandarin and English.  We apply a multistream approach to combine at frame level the acoustic model score and the language information, where the latter is provided by an LID component.  Furthermore, we advance this multistream approach by a new method called “Language Lookahead”, in which the language information of subsequent frames is used to improve accuracy.  Both methods are evaluated using a set of controlled LID results with varying frame accuracies. Our results show that both approaches improve the ASR performance by at least 4% relative if the LID achieves a minimum frame accuracy of 85%.},
}

@inproceedings{amma2015advancing,
  author = {Amma, Christoph and Krings, Thomas and B\"{o}er, Jonas and Schultz, Tanja},
  title = {Advancing Muscle-Computer Interfaces with High-Density Electromyography},
  booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
  series = {CHI '15},
  year = {2015},
  isbn = {978-1-4503-3145-6},
  location = {Seoul, Republic of Korea},
  pages = {929--938},
  numpages = {10},
  url = {http://doi.acm.org/10.1145/2702123.2702501},
  doi = {10.1145/2702123.2702501},
  acmid = {2702501},
  publisher = {ACM},
  address = {New York, NY, USA},
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2108.php}
@inproceedings{schlippe2012hausa,
  title={Hausa Large Vocabulary Continuous Speech Recognition},
  year={2012},
  note={SLTU'12},
  booktitle={The third International Workshop on Spoken Languages Technologies for Under-resourced Languages, Cape Town, South Africa},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SLTU2012-Schlippe_Hausa.pdf},
  author={Schlippe, Tim and Djomgang, Edy Guevara Komgang and Vu, Ngoc Thang and Schultz, Sebastian Ochs and Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2105.php}
@inproceedings{vu2012multilingual,
  title={Multilingual Bottleneck Features and Its Application for Under-resourced Languages},
  year={2012},
  note={SLTU'12},
  booktitle={The third International Workshop on Spoken Languages Technologies for Under-resourced Languages, Cape Town, South Africa},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/vu_sltu2012.pdf},
  author={Vu, Ngoc Thang and Schultz, Florian Metze and Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2094.php}
@inproceedings{vu2012initialization,
  note={Interspeech 2012},
  year={2012},
  title={Initialization Schemes for Multilayer Perceptron Training and Their Impact on ASR Performance using Multilingual Data},
  booktitle={13th Annual Conference of the International Speech Communication Association, Portland, Oregon},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/vu_mlp_interspeech2012.pdf},
  author={Vu, Ngoc Thang and Breiter, Wojtek and Metze, Florian and Schultz, and Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2079.php}
@inproceedings{putze2010utterance,
  year={2010},
  title={Utterance Selection for Speech Acts in a Cognitive Tourguide Scenario},
  note={Interspeech 2010},
  booktitle={11th Annual Conference of the International Speech Communication Association, Makuhari, Japan},
  author={Putze, Felix and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2074.php}
@inproceedings{janke2010impact,
  year={2010},
  title={Impact of Lack of Acoustic Feedback in EMG-based Silent Speech Recognition},
  note={Interspeech 2010},
  booktitle={11th Annual Conference of the International Speech Communication Association, Makuhari, Japan},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/JankeWandSchultz_IS10.pdf},
  abstract={This paper presents our recent advances in speech recognition based on surface electromyography (EMG). This technology allows for Silent Speech Interfaces since EMG captures the electrical potentials of the human articulatory muscles rather than the acoustic speech signal. Our earlier experiments have shown that the EMG signal is greatly impacted by the mode of speaking. In this study we extend this line of research by comparing EMG signals from audible, whispered, and silent speaking mode. We distinguish between phonetic features like consonants and vowels and show that the lack of acoustic feedback in silent speech implies an increased focus on somatosensoric feedback, which is visible in the EMG signal. Based on this analysis we develop a spectral mapping method to compensate for these differences. Finally, we apply the spectral mapping to the front-end of our speech recognition system and show that recognition rates on silent speech improve by up to 11.59% relative.},
  keywords={EMG, EMG-based speech recognition, Silent Speech Interfaces, somatosensoric feedback},
  author={Janke, Matthias and Wand, Michael and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2060.php}
@inproceedings{
year={2012},
isbn={978-3-642-34480-0},
booktitle={Neural Information Processing},
volume={7664},
series={Lecture Notes in Computer Science},
editor={Huang, Tingwen and Zeng, Zhigang and Li, Chuandong and Leung, ChiSing},
doi={10.1007/978-3-642-34481-7_51},
title={Cross-Subject Classification of Speaking Modes Using fNIRS},
url={https://www.csl.uni-bremen.de/cms/images/documents/publications/HerffSchultz_ICONIP2012.pdf},
publisher={Springer Berlin Heidelberg},
keywords={fNIRS; BCI; speech imagery; cross-subject; session-transfer},
author={Herff, Christian and Heger, Dominic and Putze, Felix and Guan, Cuntai and Schultz, Tanja},
pages={417-424},
language={English}
 }

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2037.php}
@inproceedings{schlippe2012automatic,
  title={Automatic Error Recovery for Pronunciation Dictionaries},
  year={2012},
  note={Interspeech 2012},
  booktitle={13th Annual Conference of the International Speech Communication Association, Portland, Oregon},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Interspeech2012-Schlippe_DictFilter.pdf},
  author={Schlippe, Tim and Ochs, Sebastian and Vu, Ngoc Thang and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2035.php}
@inproceedings{schlippe2012grapheme,
  year={2012},
  title={Grapheme-to-Phoneme Model Generation for Indo-European Languages},
  note={ICASSP 2012},
  booktitle={37th International Conference on Acoustics, Speech, and Signal Processing, Kyoto, Japan},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/ICASSP2012-Schlippe_G2PModelGenerationIndoEuropean.pdf},
  author={Schlippe, Tim and Ochs, Sebastian and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2034.php}
@inproceedings{vu2012a,
  title={A First Speech Recognition System For Mandarin-English Code-Switch Conversational Speech},
  year={2012},
  note={ICASSP 2012},
  booktitle={37th International Conference on Acoustics, Speech, and Signal Processing, Kyoto, Japan},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/ICASSP2012-Vu_CodeSwitch.pdf},
  author={Vu, Ngoc Thang and Lyu, Dau-Cheng and Weiner, Jochen and Telaar, Dominic and Schlippe, Tim and Blaicher, Fabian and Chng, Eng-Siong and Schultz, Tanja and Li, Haizhou},
  abstract={This  paper  presents  first  steps  toward  a  large  vocabulary continuous speech recognition system (LVCSR) for conversational Mandarin-English code-switching (CS) speech. We applied state-of-the-art techniques such as speaker adaptive and discriminative  training  to  build  the  first  baseline  system  on the SEAME corpus [1] (South East Asia Mandarin-English). For acoustic modeling,  we applied different phone merging approaches  based  on  the  International  Phonetic  Alphabet (IPA)  and  Bhattacharyya  distance  in  combination  with  discriminative training to improve accuracy. On language model level, we investigated statistical machine translation (SMT) - based text generation approaches for building code-switching language models.   Furthermore,  we integrated the provided information from a language identification system (LID) into the decoding process by using a multi-stream approach.  Our best  2-pass  system  achieves  a  Mixed  Error  Rate  (MER)  of 36.6% on the SEAME development set.},
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2033.php}
@inproceedings{lamel2011speech,
  title={Speech Recognition for Machine Translation in Quaero},
  year={2011},
  note={IWSLT 2011},
  booktitle={The International Workshop on Spoken Language Translation, San Francisco, USA},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/IWSLT2011-Schlippe_SpeechRecognitionQuaero.pdf},
  author={Lamel, Lori and Courcinous, Sandrine and Despres, Julien and Gauvain, Jean-Luc and Josse, Yvan and Kilgour, Kevin and Kraft, Florian and Bac, Le Viet and Ney, Hermann and Nußbaum-Thom, Markus and Oparin, Ilya and Schlippe, Tim and Schlüter, Ralf and Schultz, Tanja and Silva, Thiago Fraga Da and Stüker, Sebastian and Sundermeyer, Martin and Vieru, Bianca and Vu, Ngoc Thang and Waibel, Alexander and Woehrling, Cécile}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2032.php}
@inproceedings{schlippe2010text,
  title={Text Normalization based on Statistical Machine Translation and Internet User Support},
  year={2010},
  note={Interspeech 2010},
  booktitle={11th Annual Conference of the International Speech Communication Association, Makuhari, Japan},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Interspeech2010-Schlippe_SMTNormalization.pdf},
  author={Schlippe, Tim and Zhu, Chenfei and Gebhardt, Jan and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2011.php}
@INPROCEEDINGS{6346279,
author={Herff, C. and Putze, F. and Heger, D. and Cuntai Guan and Schultz, T.},
booktitle={Engineering in Medicine and Biology Society (EMBC), 2012 Annual International Conference of the IEEE},
title={Speaking mode recognition from functional Near Infrared Spectroscopy},
year={2012},
pages={1715-1718},
abstract={Speech is our most natural form of communication and even though functional Near Infrared Spectroscopy (fNIRS) is an increasingly popular modality for Brain Computer Interfaces (BCIs), there are, to the best of our knowledge, no previous studies on speech related tasks in fNIRS-based BCI. We conducted experiments on 5 subjects producing audible, silently uttered and imagined speech or do not produce any speech. For each of these speaking modes, we recorded fNIRS signals from the subjects performing these tasks and distinguish segments containing speech from those not containing speech, solely based on the fNIRS signals. Accuracies between 69% and 88% were achieved using support vector machines and a Mutual Information based Best Individual Feature approach. We are also able to discriminate the three speaking modes with 61% classification accuracy. We thereby demonstrate that speech is a very promising paradigm for fNIRS based BCI, as classification accuracies compare very favorably to those achieved in motor imagery BCIs with fNIRS.},
keywords={brain-computer interfaces;infrared spectra;speech recognition;support vector machines;audible speech;best individual feature approach;brain computer interface;functional near infrared spectroscopy;imagined speech;mutual information;silently uttered speech;speaking mode recognition;support vector machine;Accuracy;Brain;Feature extraction;Hemodynamics;Mutual information;Spectroscopy;Speech;Adult;Corpus Callosum;Electrodes;Hemodynamics;Humans;Male;Motor Cortex;Spectroscopy, Near-Infrared;Speech},
url={https://www.csl.uni-bremen.de/cms/images/documents/publications/HerffSchultzEMBC_2012.pdf},
doi={10.1109/EMBC.2012.6346279},
ISSN={1557-170X},
month={Aug},}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_2009.php}
@inproceedings{heger2012filling,
  note={EMBC'12},
  title={Filling a Glass of Water: Continuously Decoding the Speed of 3D Hand Movements from EEG Signals},
  year={2012},
  booktitle={International Conference of the IEEE Engineering in Medicine and Biology Society, San Diego, USA},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/embc2012_fillingAGlass.pdf},
  author={Heger, Dominic and Jäkel, Rainer and Putze, Felix and Lösch, Martin and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1960.php}
@inproceedings{wand2012decision,
  year={2012},
  title={Decision-tree based Analysis of Speaking Mode Discrepancies in EMG-based Speech Recognition},
  note={BIOSIGNALS 2012},
  booktitle={International Conference on Bio-inspired Systems and Signal Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/WandJankeSchultz_BS2012_DecisionTreeAnalysis.pdf},
  abstract={This study is concerned with the impact of speaking mode variabilities on speech recognition by surface electromyography (EMG). In EMG-based speech recognition, we capture the electric potentials of the human articulatory muscles by surface electrodes, so that the resulting signal can be used for speech processing. This enables the user to communicate silently, without uttering any sound. Previous studies have shown that the processing of silent speech creates a new challenge, namely that EMG signals of audible and silent speech are quite distinct. In this study we consider EMG signals of three speaking modes: audibly spoken speech, whispered speech, and silently mouthed speech. We present an approach to quantify the differences between these speaking modes by means of phonetic decision trees and show that this measure correlates highly with differences in the performance of a recognizer on the different speaking modes. We furthermore reinvestigate the spectral mapping algorithm, which reduces the discrepancy between different speaking modes, and give an evaluation of its effectiveness.},
  author={Wand, Michael and Janke, Matthias and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1965.php}
@inproceedings{johner2012inferring,
  title={Inferring Prosody from Facial Cues for EMG-based Synthesis of Silent Speech},
  year={2012},
  booktitle={4th International Conference on Applied Human Factors and Ergonomics},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/johner_christian_ahfe_paper.pdf},
  abstract={In this paper we introduce a system which is able to detect prosodic elements in a spoken utterance based on signals from the facial muscles. The proposed system can augment our surface electromyography (EMG) based Silent Speech Interface in order to make synthesized speech more natural. Having shown in (Nakamura, Janke, Wand, & Schultz, 2011) that it is possible to produce understandable synthesized speech from EMG signals, our current interest is to improve the quality and expressivity of the synthesis. We show that a standard phonetically balanced German speech corpus with only a few additional utterances is sufficient to train a system that can discriminate yes/no questions from normal speech and also distinguish between normal and emphasized words in an utterance. For the detection of prosodic information in facial muscle movement we extend our EMG based speech synthesis system with two additional EMG channels, recording the movements of the facial muscles musculus corrugator and musculus frontalis. Our classification method uses a frame-based SVM classification, followed by a majority vote to classify a whole word. Our system achieves F-scores of up to 0.68 for the recognition of emphasized words and 1.0 for the classification between questions and normal utterances although the results show large variations depending on the feature combination used for training.},
  keywords={EMG, synthesis, prosody, speech recognition},
  author={Johner, Christian and Janke, Matthias and Wand, Michael and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1962.php}
@inproceedings{janke2012further,
  year={2012},
  title={Further Investigations on EMG-to-Speech Conversion},
  note={ICASSP},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Janke_FurtherInvestigationsEMG2F0.pdf},
  abstract={Our study deals with a Silent Speech Interface based onmapping surface electromyographic (EMG) signals to speech waveforms.  Electromyographic signals recorded from the facial muscles capture the activity of the human articulatory apparatus and therefore allow to retrace speech, even when no audible signal is produced. The mapping of EMG signals to speech is done via a Gaussian mixture model (GMM)-based conversion technique. In this paper, we follow the lead of EMG-based speech-to-text systems and apply two major recent technological advances to our system, namely, we consider session- independent systems, which are robust against electrode repositioning, and we show that mapping the EMG signal to whispered speech creates a better speech signal than a mapping to normally spoken speech. We objectively evaluate the performance of our systems u sing a spectral distortion measure.},
  keywords={Silent Speech, Electromyography,Speech Synthesis, Voice Conversion},
  author={Janke, Matthias and Wand, Michael and Nakamura, Keigo and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1077.php}
@inproceedings{amma2010airwriting,
  year={2010},
  title={Airwriting Recognition using Wearable Motion Sensors},
  booktitle={First Augmented Human International Conference},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/1405.php},
  author={Amma, Christoph and Gehrig, Dirk and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1936.php}
@inproceedings{kuehne2012on,
  note={VISAPP 2012},
  year={2012},
  title={On-line Action Recognition from sparse Feature Flow},
  booktitle={International Conference on Computer Vision Theory and Applications 2012},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/paper_visapp2012.pdf},
  author={Kuehne, Hildegard and Gehrig, Dirk and Schultz, Tanja and Stiefelhagen, Rainer}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1914.php}
@inproceedings{amma2012airwriting,
  title={Airwriting: Hands-free Mobile Text Input by Spotting and Continuous Recognition of 3d-Space Handwriting with Inertial Sensors},
  year={2012},
  note={ISWC '12},
  booktitle={16th International Symposium on Wearable Computers},
  author={Amma, Christoph and Georgi, Marcus and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1911.php}
@inproceedings{amma2012airwriting,
  note={IUI '12},
  year={2012},
  title={Airwriting: demonstrating mobile text input by 3D-space handwriting},
  booktitle={International Conference on Intelligent User Interfaces},
  author={Amma, Christoph and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1059.php}
@inproceedings{nakamura2011estimation,
  year={2011},
  title={Estimation of Fundamental Frequency from Surface Electromyographic Data},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/NakamuraSchultz_ICASSP2011.pdf},
  abstract={In this paper, we present our recent studies of $F_0$ estimation from the surface electromyographic (EMG) data using a Gaussian mixture model (GMM)-based voice conversion (VC) technique, referred to as EMG-to-$F_0$. In our approach, a support vector machine recognizes individual frames as unvoiced and voiced (U/V), and voiced $F_0$ contours are discriminated by the trained GMM based on the manner of minimum mean-square error. EMG-to-$F_0$ is experimentally evaluated using three data sets of different speakers. Each data set includes almost 500 utterances.  Objective experiments demonstrate that we achieve a correlation coefficient of up to 0.49 between estimated and target $F_0$ contours with more than 84% U/V decision accuracy, although the results have large variations.},
  keywords={Electromyography, Voice conversion, Fundamental frequency, Feature estimation},
  author={Nakamura, Keigo and Janke, Matthias and Wand, Michael and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1054.php}
@inproceedings{nallasamy2011analysis,
  title={Analysis of Dialectal Influence in Pan-Arabic ASR},
  year={2011},
  note={Interspeech 2011},
  booktitle={12th Annual Conference of the International Speech Communication Association},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/NallasamySchultz_Interspeech2011.pdf},
  author={Nallasamy, Udhay and Garbus, Michael and Metze, Florian and Jin, Qin and Schaaf, Thomas and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1053.php}
@inproceedings{hsiao2011generalized,
  year={2011},
  title={Generalized Baum-Welch Algorithm and Its Implication to a New Extended Baum-Welch Algorithm},
  note={Interspeech 2011},
  booktitle={12th Annual Conference of the International Speech Communication Association},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/HsiaoSchultz_Interspeech2011.pdf},
  author={Hsiao, Roger and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1055.php}
@inproceedings{yang2011investigation,
  title={Investigation of Cross-show Speaker Diarization},
  year={2011},
  note={Interspeech 2011},
  booktitle={12th Annual Conference of the International Speech Communication Association},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/YangJinSchultz_Interspeech2011.pdf},
  author={Yang, Qian and Jin, Qin and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1052.php}
@inproceedings{vu2011rapid,
  year={2011},
  title={Rapid building of an ASR system for Under-Resourced Languages based on Multilingual Unsupervised Training},
  note={Interspeech 2011},
  booktitle={12th Annual Conference of the International Speech Communication Association},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/VuKrausSchultz_Interspeech2011.pdf},
  author={Vu, Ngoc Thang and Kraus, Franziska and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1056.php}
@inproceedings{janke2011investigations,
  title={Investigations on Speaking Mode Discrepancies in EMG-based Speech Recognition},
  year={2011},
  note={Interspeech 2011},
  booktitle={12th Annual Conference of the International Speech Communication Association},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/WandJankeSchultz_Interspeech2011.pdf},
  abstract={In this paper we present our recent study on the impact of speaking mode variabilities on speech recognition by surface electromyography (EMG). Surface electromyography captures the electric potentials of the human articulatory muscles, which enables a user to communicate naturally without making any audible sound. Our previous experiments have shown that the EMG signal varies greatly between different speaking modes, like audibly uttered speech and silently articulated speech. In this study we extend our previous research and quantify the impact of different speaking modes by investigating the amount of mode-specific leaves in phonetic decision trees. We show that this measure correlates highly with discrepancies in the spectral energy of the EMG signal, as well as with differences in the performance of a recognizer on different speaking modes. We furthermore present how EMG signal adaptation by spectral mapping decreases the effect of the speaking mode.},
  keywords={EMG, EMG-based speech recognition, Silent
Speech Interfaces, phonetic decision tree},
  author={Janke, Matthias and Wand, Michael and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1051.php}
@inproceedings{herff2011impact,
  year={2011},
  title={Impact of Different Feedback Mechanisms in EMG-based Speech Recognition},
  note={Interspeech 2011},
  booktitle={12th Annual Conference of the International Speech Communication Association},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/HerffSchultz_Interspeech2011.pdf},
  abstract={This paper reports on our recent research in the feedback effects of Silent Speech. Our technology is based on surface electromyography (EMG) which captures the electrical potentials of the human articulatory muscles rather than the acoustic speech signal. While recognition results are good for loudly articulated speech and when experienced users speak silently, novice users usually achieve far worse results when speaking silently. Since there is no acoustic feedback when speaking silently, we investigate different kinds of feedback modes: no additional feedback except the natural somatosensory feedback (like the touching of the lips), visual feedback using a mirror and indirect acoustic feedback by speaking simultaneously to a previously recorded audio signal. In addition we examine recorded EMG data when the subject speaks audibly and silently in a loud environment to see if the Lombard effect can be observed in Silent Speech, too.},
  keywords={Silent speech, Elecromyography, Lack of acoustic feedback, EMG-based speech recognition, Lombard effect},
  author={Herff, Christian and Janke, Matthias and Wand, Michael and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1047.php}
@inproceedings{jarvis2011multimodal,
  year={2011},
  title={Multimodal Person Independent Recognition of Workload Related Biosignal Patterns},
  booktitle={International Conference on Multimodal Interaction, ICMI 2011},
  author={Jarvis, Jan-Philip and Putze, Felix and Heger, Dominic and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1061.php}
@inproceedings{wand2011session,
  title={Session-Independent EMG-based Speech Recognition},
  year={2011},
  booktitle={International Conference on Bio-inspired Systems and Signal Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/WandSchultz_Biosignals2011.pdf},
  author={Wand, Michael and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1049.php}
@inproceedings{gehrig2011combined,
  year={2011},
  title={Combined Intention, Activity, and Motion Recognition for a Humanoid Household Robot},
  booktitle={IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS 2011},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Gehrig_IROS2011.pdf},
  author={Gehrig, Dirk and Krauthausen, Peter and Rybok, Lukas and Kuehne, Hildegard and Hanebeck, Uwe D. and Schultz, Tanja and Stiefelhagen, Rainer}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1058.php}
@inproceedings{vu2011cross,
  title={Cross-language bootstrapping based on completely unsupervised training using multilingual A-stabil},
  year={2011},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/VuKrausSchultz_ICASSP2011.pdf},
  author={Vu, Ngoc Thang and Kraus, Franziska and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1060.php}
@inproceedings{wand2011analysis,
  title={Analysis of Phone Confusion in EMG-based Speech Recognition},
  year={2011},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/WandSchultz_ICASSP2011.pdf},
  author={Wand, Michael and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1048.php}
@inproceedings{heger2011online,
  year={2011},
  title={Online Recognition of Facial Actions for natural EEG-based BCI Applications},
  booktitle={Affective Computing and Intelligent Interaction 2011, ACII 2011},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/acii11_facialActions.pdf},
  author={Heger, Dominic and Putze, Felix and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1075.php}
@inproceedings{vu2010optimization,
  year={2010},
  title={Optimization On Vietnamese Large Vocabulary Speech Recognition},
  booktitle={2nd Workshop on Spoken Languages Technologies for Under-resourced Languages},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/vu_SLTU2010_VNASR2.pdf},
  author={Vu, Ngoc Thang and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1064.php}
@inproceedings{metze2010the,
  year={2010},
  title={The 2010 CMU GALE Speech-to-Text System},
  booktitle={Interspeech 2010},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/MetzeSchultz_IS10.pdf},
  author={Metze, Florian and Hsiao, Roger and Jin, Qin and Nallasamy, Udhay and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1074.php}
@inproceedings{gehrig2010erkennung,
  title={Erkennung von menschlichen Bewegungen mit Hidden Markov Modellen},
  year={2010},
  booktitle={Sportinformatik trifft Sporttechnologie, Tagung der dvs-Sektion Sportinformatik in Kooperation mit der deutschen interdisziplin},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Gehrig_DVS10_Bewegungserkennung_mit_HMMs.pdf},
  author={Gehrig, Dirk and Kühne, Hildegard and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1063.php}
@inproceedings{heger2010an,
  title={An Adaptive Information System for an Empathic Robot using EEG Data},
  year={2010},
  booktitle={International Conference on Social Robotics},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/HegerPutzeSchultz_ICSR10.pdf},
  author={Heger, Dominic and Putze, Felix and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1062.php}
@inproceedings{vu2010multilingual,
  year={2010},
  title={Multilingual A-stabil: A new confidence score for multilingual unsupervised training},
  booktitle={IEEE Workshop on Spoken Language Technology},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/vu_mut_slt2010.pdf},
  author={Vu, Ngoc Thang and Kraus, Franziska and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1078.php}
@inproceedings{janke2010spectral,
  note={Side event of Biosignals 2010 conference},
  year={2010},
  title={Spectral Energy Mapping for EMG-based Recognition of Silent Speech},
  booktitle={First International Workshop on Bio-inspired Human-Machine Interfaces and Healthcare Applications},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/WandSchultz_BInterface2010.pdf},
  abstract={This paper reports on our latest study on speech recognition based on surface electromyography (EMG). This technology allows for Silent Speech Interfaces since EMG captures the electrical potentials of the human articulatory muscles rather than the acoustic speech signal. Therefore, our technology enables speech recognition to be applied to silently mouthed speech. Earlier experiments indicate that the EMG signal is greatly impacted by the mode of speaking. In this study we analyze and compare EMG signals from audible, whispered, and silent speech. We quantify the differences and develop a spectral mapping method to compensate for these differences. Finally, we apply the spectral mapping to the front-end of our speech recognition system and show that recognition rates on silent speech improve by up to 12.3% relative.},
  author={Janke, Matthias and Wand, Michael and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1076.php}
@inproceedings{putze2010multimodal,
  title={Multimodal Recognition of Cognitive Workload for Multitasking in the Car},
  year={2010},
  booktitle={20th International Conference on Pattern Recognition},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/PutzeJarvisSchultz_ICPR10.pdf},
  author={Putze, Felix and Jarvis, Jan-Philip and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1071.php}
@inproceedings{heger2010online,
  title={Online Workload Recognition from EEG data during Cognitive Tests and Human-Computer Interaction},
  year={2010},
  booktitle={33rd Annual German Conference on Artificial Intelligence 2010},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/HegerPutzeSchultz_KI10.pdf},
  author={Heger, Dominic and Putze, Felix and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1073.php}
@inproceedings{gehrig2010towards,
  title={Towards Semantic Segmentation of Human Motion Sequences},
  year={2010},
  booktitle={33rd Annual German Conference on Artificial Intelligence 2010},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/gehrig_ki2010.pdf},
  author={Gehrig, Dirk and Stein, Thorsten and Fischer, Andreas and Schwameder, Hermann and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1072.php}
@inproceedings{heger2010biosignalsstudio,
  year={2010},
  title={BiosignalsStudio: A flexible Framework for Biosignal Capturing and Processing},
  booktitle={33rd Annual German Conference on Artificial Intelligence 2010},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/HegerPutzeAmmaSchultz_KI10.pdf},
  author={Heger, Dominic and Putze, Felix and Amma, Christoph and Wielatt, Thomas and Plotkin, Igor and Wand, Michael and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1068.php}
@inproceedings{schlippe2010wiktionary,
  note={Interspeech 2010},
  title={Wiktionary as a Source for Automatic Pronunciation Extraction},
  year={2010},
  booktitle={11th Annual Conference of the International Speech Communication Association, Makuhari, Japan},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SchlippeOchsSchultz_IS10.pdf},
  author={Schlippe, Tim and Ochs, Sebastian and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1065.php}
@inproceedings{hsiao2010improvements,
  year={2010},
  title={Improvements to Generalized Discriminative Feature Transformation for Speech Recognition},
  booktitle={11th Annual Conference of the International Speech Communication Association},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/MetzeSchultz_IS10.pdf},
  author={Hsiao, Roger and Metze, Florian and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1066.php}
@inproceedings{vu2010rapid,
  title={Rapid Bootstrapping of five Eastern European Languages using the Rapid Language Adaptation Toolkit},
  year={2010},
  note={Interspeech 2010},
  booktitle={11th Annual Conference of the International Speech Communication Association, Makuhari, Japan},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/VuSchultz_IS10.pdf},
  author={Vu, Ngoc Thang and Schlippe, Tim and Kraus, Franziska and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1103.php}
@inproceedings{wand2009towards,
  note={Biosignals 2009},
  year={2009},
  title={Towards Speaker-Adaptive Speech Recognition based on Surface Electromyography},
  booktitle={2nd International Conference on Bio-inspired Systems and Signal Processing, Porto, Portugal},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/WandSchultz_Biosignals2009.pdf},
  author={Wand, Michael and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1104.php}
@inproceedings{porbadnigk2009eeg,
  title={EEG-based Speech Recognition - Impact of Temporal Effects},
  year={2009},
  note={Biosignals 2009},
  booktitle={2nd International Conference on Bio-inspired Systems and Signal Processing, Porto, Portugal},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Biosignals_paper114.pdf},
  author={Porbadnigk, Anne and Wester, Marek and Callies, Jan Peter and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1096.php}
@inproceedings{tam2009incorporating,
  title={Incorporating Monolingual Corpora into Bilingual Latent Semantic Analysis for Crosslingual LM Adaptation},
  year={2009},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/TamSchultz-ICASSP2009.pdf},
  author={Tam, Yik-Cheung and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1094.php}
@inproceedings{jin2009voice,
  title={Voice Convergin: Speaker De-Identification by Voice Transformation},
  year={2009},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/JinSchultz-ICASSP2009.pdf},
  author={Jin, Qin and Toth, Arthur and Schultz, Tanja and Black, Alan W}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1097.php}
@inproceedings{fuhs2009detecting,
  year={2009},
  title={Detecting Bandlimited Audio in Broadcast Television Shows},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/FuhsSchultz-ICASSP2009.pdf},
  author={Fuhs, Mark and Jin, Qin and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1098.php}
@inproceedings{hsiao2009generalized,
  title={Generalized Baum-Welch Algorithm for Discriminative Training on Large Vocabulary},
  year={2009},
  booktitle={Continuous Speech Recognition Systems},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/HsiaoSchultz-ICASSP2009.pdf},
  author={Hsiao, Roger and Tam, Yik-Cheung and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1079.php}
@inproceedings{stoimenov2009a,
  year={2009},
  title={A Multiplatform Speech Recognition Decoder Based on Weighted Finite-State Transducers},
  booktitle={Automatic Speech Recognition and Understanding},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/StoimenovSchultz_ASRU2009.pdf},
  author={Stoimenov, Emilian and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1080.php}
@inproceedings{jin2009speaker,
  year={2009},
  title={Speaker De-Identification Via Voice Transformation},
  booktitle={Automatic Speech Recognition and Understanding},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/JinTothSchultzBlack-ASRU2009.pdf},
  author={Jin, Qin and Toth, Arthur and Black, Alan W and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1081.php}
@inproceedings{vu2009vietnamese,
  title={Vietnamese Large Vocabulary Continuous Speech Recognition},
  year={2009},
  booktitle={Automatic Speech Recognition and Understanding},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/VuSchultz_ASRU2009.pdf},
  author={Vu, Ngoc Thang and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1133.php}
@inproceedings{fischer2008bewegungserkennung,
  year={2008},
  title={Bewegungserkennung mit Hidden Markov Modellen},
  booktitle={Landessymposium},
  author={Fischer, Andreas and Stein, Thorsten and Gehrig, Dirk and Schultz, Tanja and Schwameder, Hermann}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1083.php}
@inproceedings{gehrig2009hmm,
  title={HMM-based Human Motion Recognition with Optical Flow Data},
  year={2009},
  booktitle={9th IEEE-RAS International Conference on Humanoid Robots, Workshop Imitation and Coaching in Humanoid Robots},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Humanoids2009_final.pdf},
  author={Gehrig, Dirk and Kühne, Hildegard and Wörner, Annika and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1101.php}
@inproceedings{fischer2009training,
  title={Training und Erkennung mit Hidden Markov Modellen bei unterschiedlichen Geh-/Laufgeschwindigkeiten},
  year={2009},
  booktitle={Biomechanik â Grundlagenforschung und Anwendung, Tagung der dvs-Sektion Biomechanik},
  author={Fischer, Andreas and Stein, Thorsten and Gehrig, Dirk and Schultz, Tanja and Schwameder, Hermann}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1091.php}
@inproceedings{putze2009cognitive,
  year={2009},
  title={Cognitive Dialog Systems for Dynamic Environments: Progress and Challenges},
  booktitle={4th Biennial Workshop on DSP for In-Vehicle Systems and Safety},
  author={Putze, Felix and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1090.php}
@inproceedings{schultz2009towards,
  title={Towards Emotion Recognition from Electroencephalographic Signals},
  year={2009},
  booktitle={2009 International Conference on Affective Computing & Intelligent Interaction},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/ACII09_Schaaff.pdf},
  author={Schultz, Tanja and Schaaff, Kristina}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1082.php}
@inproceedings{putze2009cognitive,
  year={2009},
  title={Cognitive Memory Modeling for Interactive Systems in Dynamic Environments},
  booktitle={1st International Workshop on Spoken Dialog Systems},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/PutzeSchultz_IWSDS09.pdf},
  author={Putze, Felix and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1084.php}
@inproceedings{schaaff2009towards,
  title={Towards an EEG-based Emotion Recognizer for Humanoid Robots},
  year={2009},
  booktitle={18th IEEE International Symposium on Robot and Human Interactive Communication},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/ROMAN09-Schaaff.pdf},
  author={Schaaff, Kristina and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1087.php}
@inproceedings{li2009improving,
  title={Improving Speaker Segmentation via Speaker Identification and Text Segmentation},
  year={2009},
  booktitle={10th Annual Conference of the International Speech Communication Association},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Interspeech09_Li.pdf},
  author={Li, Runxin and Jin, Qin and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1089.php}
@inproceedings{hsiao2009generalized,
  year={2009},
  title={Generalized Discriminative Feature Transformation for Speech Recognition},
  booktitle={10th Annual Conference of the International Speech Communication Association},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Interspeech09_Hsiao.pdf},
  author={Hsiao, Roger and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1086.php}
@inproceedings{wand2009impact,
  title={Impact of Different Speaking Modes on EMG-based Speech Recognition},
  year={2009},
  booktitle={10th Annual Conference of the International Speech Communication Association},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Interspeech09_Wand_01.pdf},
  author={Wand, Michael and Toth, Arthur and Jou, Szu-Chen (Stan) and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1088.php}
@inproceedings{wölfel2009speaker,
  title={Speaker Identification using Warped MVDR Cepstral Features},
  year={2009},
  booktitle={10th Annual Conference of the International Speech Communication Association},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Interspeech09_Woelfel.pdf},
  author={Wölfel, Matthias and Yang, Qian and Jin, Qin and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1085.php}
@inproceedings{toth2009synthesizing,
  year={2009},
  title={Synthesizing Speech from Electromyography using Voice Transformation Techniques},
  booktitle={10th Annual Conference of the International Speech Communication Association},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Interspeech09_Toth.pdf},
  author={Toth, Arthur and Wand, Michael and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1093.php}
@inproceedings{schaaff2009eeg,
  year={2009},
  title={EEG-based Emotion Recognition Using Support Vector Machines},
  booktitle={1. Fachtagung Biophysiologische Interfaces},
  author={Schaaff, Kristina and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1092.php}
@inproceedings{putze2009towards,
  title={Towards Cognitive Dialog Systems},
  year={2009},
  booktitle={1. Fachtagung Biophysiologische Interfaces},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/cognitive_dialog_systems_01.pdf},
  author={Putze, Felix and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1412.php}
@inproceedings{gibert2009enhancement,
  note={CHISIG},
  title={Enhancement of human computer interaction with facial electromyographic sensors},
  year={2009},
  booktitle={23nd conference of the computer-human interaction special interest group of Australia on Computer-human interaction: design (OZCHI 2009), Melbourne, Australia},
  author={Gibert, Guillaume and Pruzinec, Martin and Schultz, Tanja and Stevens, Catherine}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1102.php}
@inproceedings{fischer2009bewegungserkennung,
  note={},
  title={Bewegungserkennung mit Hidden Markov Modellen},
  year={2009},
  booktitle={Informations- und Kommunikationstechnologien in der Sportmotorik, 11. Tagung der dvs-Sektion Sportmotorik},
  author={Fischer, Andreas and Stein, Thorsten and Gehrig, Dirk and Schultz, Tanja and Schwameder, Hermann}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1132.php}
@inproceedings{jou2008ears,
  year={2008},
  title={EARS: Electromyographical Automatic Recognition of Speech},
  note={Biosignals 2008},
  booktitle={1st International Conference on Bio-inspired Systems and Signal Processing, Madeira, Portugal},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/JouSchultz_Biosignals2008.pdf},
  author={Jou, Szu-Chen (Stan) and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1106.php}
@inproceedings{charoenpornsawat2008improving,
  title={Improving Word Segmentation for Thai Speech Translation},
  year={2008},
  booktitle={IEEE Workshop on Spoken Language Technology},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SLT2008-CharoenpornsawatSchultz.pdf},
  author={Charoenpornsawat, Paisarn and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1127.php}
@inproceedings{schultz2008rapid,
  title={Rapid Language Adaptation Tools and Technologies for Multilingual Speech Processing},
  year={2008},
  booktitle={ICASSP},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/laskowskiICASSP2008_published.pdf},
  author={Schultz, Tanja and Black, Alan W}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1105.php}
@inproceedings{fung)2008rapid,
  year={2008},
  title={Rapid Language Adaptation Tools & Technologies for Multilingual Speech Processing Systems},
  booktitle={IEEE Workshop on Spoken Language Technology},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SLT2008-CharoenpornsawatSchultz.pdf},
  author={Fung), (Presented by Pascale and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1131.php}
@inproceedings{honal2008determine,
  year={2008},
  title={Determine Task Demand from Brain Activity},
  note={Biosignals 2008},
  booktitle={1st International Conference on Bio-inspired Systems and Signal Processing, Madeira, Portugal},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/HonalSchultz_Biosignals2008.pdf},
  author={Honal, Matthias and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1124.php}
@inproceedings{schultz2008multilingual,
  year={2008},
  title={Multilingual Speech Processing in the context of Under-resourced Languages},
  booktitle={SLTU: Workshop on Spoken Language Technologies for Under-Resourced Languages},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SLTU2008-TSchultz.pdf},
  author={Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1125.php}
@inproceedings{kominek2008synthesizer,
  title={Synthesizer Voice Quality of New Languages Calibrated with Mean Mel Cepstral Distortion},
  year={2008},
  booktitle={SLTU: Workshop on Spoken Language Technologies for Under-Resourced Languages},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/kominek_black.sltu_2008.pdf},
  author={Kominek, John and Schultz, Tanja and Black, Alan W}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1118.php}
@inproceedings{heldner2008prosodic,
  title={Prosodic Features in the Vicinity of Silences and Overlaps},
  year={2008},
  booktitle={Nordic Prosody X},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/HeldnerEdlundLaskowskiPelce_NP08_ProsodicFeatures.pdf},
  author={Heldner, Mattias and Edlund, Jens and Laskowski, Kornel and Pelcé, Antoine}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1108.php}
@inproceedings{tam2008correlated,
  year={2008},
  title={Correlated Bigram LSA for Unsupervised LM adaptation},
  booktitle={Neural Information Processing Systems},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/TamSchultz_NIPS08_CorrelatedBigramLSA.pdf},
  author={Tam, Yik-Cheung and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1121.php}
@inproceedings{jin2008compensation,
  title={Compensation Approaches for Far-field Speaker Identification},
  year={2008},
  booktitle={NIST SRE Workshop 2008},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/NIST-SRE-2008.pdf},
  author={Jin, Qin and Kumar, Kshitiz and Schultz, Tanja and Stern, Richard M}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1112.php}
@inproceedings{schlippe2008diacritization,
  title={Diacritization as a Translation Problem and as a Sequence Labeling Problem},
  year={2008},
  note={AMTA 2008},
  booktitle={Eighth Conference of the Association for Machine Translation in the Americas, Waikiki, Hawai'i},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/AMTA-2008-Schlippe.pdf},
  author={Schlippe, Tim and Nguyen, ThuyLinh and Vogel, Stephan}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1123.php}
@inproceedings{burger2008a,
  title={A Comparative Cross-Domain Study of the Occurrence of Laughter in Meeting and Seminar Corpora},
  year={2008},
  booktitle={6th International Conference on Language Resources and Evaluation},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/815_paper.pdf},
  author={Burger, Susanne and Laskowski, Kornel and Wölfel, Matthias}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1117.php}
@inproceedings{laskowski2008detection,
  title={Detection of Laughter-in-Interaction in Multichannel Close-Talk Microphone Recordings of Meetings},
  year={2008},
  booktitle={5th Joint Workshop on Multimodal Interaction and Related Machine Learning Algorithms},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/laskowskiMLMI2008.pdf},
  author={Laskowski, Kornel and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1126.php}
@inproceedings{laskowski2008learning,
  year={2008},
  title={Learning Prosodic Sequences Using the Fundamental Frequency Variation Spectrum},
  booktitle={4th International Conference on Speech Prosody},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/laskowskiPROSODY2008_A.pdf},
  author={Laskowski, Kornel and Edlund, Jens and Heldner, Mattias}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1122.php}
@inproceedings{laskowski2008the,
  title={The Fundamental Frequency Variation Spectrum},
  year={2008},
  booktitle={21st Swedish Phonetics Conference},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/laskowski_heldner_edlund_newer.pdf},
  author={Laskowski, Kornel and Heldner, Mattias and Edlund, Jens}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1107.php}
@inproceedings{gehrig2008selecting,
  year={2008},
  title={Selecting Relevant Features for Human Motion Recognition},
  booktitle={19th International Conference on Pattern Recognition},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/icpr2008_final.pdf},
  author={Gehrig, Dirk and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1119.php}
@inproceedings{laskowski2008computing,
  year={2008},
  title={Computing the Fundamental Frequency Variation Spectrum in Conversational Spoken Dialogue Systems},
  booktitle={155th Meeting of the Acoustical Society of America},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/003228.pdf},
  author={Laskowski, Kornel and Wölfel, Matthias and Heldner, Mattias and Edlund, Jens}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1113.php}
@inproceedings{hsiao2008the,
  year={2008},
  title={The CMU-InterACT 2008 Mandarin Transcription System},
  booktitle={9th Annual Conference of the International Speech Communication Association},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/HsiaoSchultz-IS2008.pdf},
  author={Hsiao, Roger and Fuhs, Mark and Tam, Wilson (Yik-Cheung) and Jin, Qin and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1116.php}
@inproceedings{jin2008robust,
  year={2008},
  title={Robust Far-Field Speaker Recognition under Mismatched Conditions},
  booktitle={9th Annual Conference of the International Speech Communication Association},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/JinSchultz-IS2008.pdf},
  author={Jin, Qin and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1114.php}
@inproceedings{laskowski2008recovering,
  year={2008},
  title={Recovering Participant Identities in Meetings from a Probabilistic Description of Vocal Interaction},
  booktitle={9th Annual Conference of the International Speech Communication Association},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/LaskowskiSchultz-IS2008.pdf},
  author={Laskowski, Kornel and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1115.php}
@inproceedings{kominek2008improving,
  title={Improving Speech Systems Built From Very Little Data},
  year={2008},
  booktitle={9th Annual Conference of the International Speech Communication Association},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/KominekSchultz-IS2008.pdf},
  author={Kominek, John and Badaskar, Sameer and Black, Alan W and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1109.php}
@inproceedings{gehrig2008online,
  title={Online Recognition of Daily-Life Movements},
  year={2008},
  booktitle={8th IEEE-RAS International Conference on Humanoid Robots, Workshop Imitation and Coaching in Humanoid Robots},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Humanoids2008a.pdf},
  author={Gehrig, Dirk and Fischer, Andreas and Kühne, Hildegard and Stein, Thorsten and Wörner, Annika and Schwameder, Hermann and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1130.php}
@inproceedings{jin2008is,
  title={Is Voice Transformation A Threat To Speaker Identification?},
  year={2008},
  booktitle={33rd IEEE International Conference on Acoustics, Speech, and Signal Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/JinSchultz-ICASSP2008.pdf},
  author={Jin, Qin and Toth, Arthur and Black, Alan W and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1120.php}
@inproceedings{laskowski2008modeling,
  title={Modeling Vocal Interaction for Text-Independent Participant Characterization in Multi-Party Conversation},
  year={2008},
  booktitle={9th SIGdial Workshop on Discourse and Dialogue},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SIGDIAL24.pdf},
  author={Laskowski, Kornel and Ostendorf, Mari and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1129.php}
@inproceedings{paulik2008sentence,
  title={Sentence Segmentation and Punctuation Recovery For Spoken Language Translation},
  year={2008},
  booktitle={33rd IEEE International Conference on Acoustics, Speech, and Signal Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/PaulikSchultz-ICASSP2008.pdf},
  author={Paulik, Matthias and Rao, Sharath and Lane, Ian and Vogel, Stephan and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1128.php}
@inproceedings{laskowski2008an,
  title={An Instantaneous Vector Representation of Delta Pitch for Speaker-Change Prediction in Conversational Dialogue Systems},
  year={2008},
  booktitle={33rd IEEE International Conference on Acoustics, Speech, and Signal Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/laskowskiICASSP2008_published.pdf},
  author={Laskowski, Kornel and Edlund, Jens and Heldner, Mattias}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1432.php}
@inproceedings{do2008transfer,
  title={Transfer of Human Movements to Humanoid Robots},
  year={2008},
  booktitle={8th IEEE-RAS International Conference on Humanoid Robots, Workshop Imitation and Coaching in Humanoid Robots},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Humanoids2008b.pdf},
  author={Do, Martin and Gehrig, Dirk and Kühne, Hildegard and Azad, Pedram and Pastor, Peter and Asfour, Tamim and Schultz, Tanja and Wörner, Annika and Dillmann, Rüdiger}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1148.php}
@inproceedings{laskowski2007modeling,
  note={MLMI},
  title={Modeling Vocal Interaction for Segmentation in Meeting Recognition},
  year={2007},
  booktitle={4th Joint Workshop on Machine Learning and Multimodal Interaction, Lecture Notes in Computer Science},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/LaskowskiSchultz_MLMI2007.pdf},
  author={Laskowski, Kornel and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1153.php}
@inproceedings{tam2007correlated,
  title={Correlated Latent Semantic Model for Unsupervised LM Adaptation},
  year={2007},
  booktitle={Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/TamSchultz_ICASSP2007.pdf},
  author={Tam, Yik-Cheung and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1152.php}
@inproceedings{jou2007continuous,
  title={Continuous Electromyographic Speech Recognition with a Multi-Stream Decoding Architecture},
  year={2007},
  booktitle={Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/JouSchultz_ICASSP2007.pdf},
  author={Jou, Szu-Chen (Stan) and Schultz, Tanja and Waibel, Alex}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1138.php}
@inproceedings{schultz2007spice,
  title={SPICE: Web-based Tools for Rapid Language Adaptation in Speech Processing Systems},
  year={2007},
  booktitle={Proceedings of Interspeech},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Schultz_Interspeech2007.pdf},
  author={Schultz, Tanja and Black, Alan W and Badaskar, Sameer and Hornyak, Matthew and Kominek, John}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1139.php}
@inproceedings{laskowski2007analysis,
  year={2007},
  title={Analysis of the Occurrence of Laughter in Meetings},
  booktitle={Proceedings of Interspeech},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/laskowskiINTERSPEECH2007_B.pdf},
  author={Laskowski, Kornel and Burger, Susanne}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1143.php}
@inproceedings{laskowski2007simultaneous,
  title={Simultaneous Multispeaker Segmentation for Automatic Meeting Recognition},
  year={2007},
  booktitle={15th European Signal Processing Conference},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/LASKOWSK_01.pdf},
  author={Laskowski, Kornel and Fügen, Christian and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1150.php}
@inproceedings{noamany2007advances,
  title={Advances in the CMU-InterACT Arabic Gale Transcription System},
  year={2007},
  booktitle={Proceedings of the HLT-NAACL 2007},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/NoamanySchultz_HLT2007.pdf},
  author={Noamany, Mohamed and Schaaf, Thomas and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1141.php}
@inproceedings{rao2007optimizing,
  year={2007},
  title={Optimizing Sentence Segmentation for Spoken Language Translation},
  booktitle={Proceedings of Interspeech},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/RaoSchultz_Interspeech2007.pdf},
  author={Rao, Sharath and Lane, Ian and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1142.php}
@inproceedings{bach2007handling,
  title={Handling OOV Words In Arabic ASR Via Flexible Morphological Constraints},
  year={2007},
  booktitle={Proceedings of Interspeech},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/BachSchultz_Interspeech2007.pdf},
  author={Bach, Nguyen and Noamany, Mohamed and Lane, Ian and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1137.php}
@inproceedings{wand2007wavelet,
  title={Wavelet-based Front-End for Electromyographic Speech Recognition},
  year={2007},
  booktitle={Proceedings of Interspeech},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/WandSchultz_Interspeech2007.pdf},
  author={Wand, Michael and Jou, Szu-Chen (Stan) and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1154.php}
@inproceedings{stein2007kinematische,
  year={2007},
  title={Kinematische Analyse menschlicher Alltagsbewegungen für die Mensch-Maschine-Interaktion},
  booktitle={diverse Workshops 2007},
  author={Stein, Thorsten and Fischer, Andreas and Boesnach, Ingo and Gehrig, Dirk and Köhler, Hildegard and Schwameder, Hermann}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1140.php}
@inproceedings{tam2007bilingual,
  year={2007},
  title={Bilingual LSA-based Translation Lexicon Adaptation for Spoken Language Translation},
  booktitle={Proceedings of Interspeech},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Tam_IS07_LSABasedTranslationLexicon.pdf},
  author={Tam, Yik-Cheung and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1136.php}
@inproceedings{schultz2007spice,
  year={2007},
  title={SPICE: Web-based Tools for Rapid Language},
  booktitle={Adaptation for Speech Processing Systems},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Schultz_Interspeech2007.pdf},
  author={Schultz, Tanja and Black, Alan W and Kominek, John and Badaskar, Sameer}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1144.php}
@inproceedings{laskowski2007modeling,
  title={Modeling Vocal Interaction for Text-Independent Classification of Conversation Type},
  year={2007},
  booktitle={In proceedings of the 8th ISCA/ACL SIGdial Workshop on Discourse and Dialogue},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/laskowskiSIGDIAL2007_B.pdf},
  author={Laskowski, Kornel and Ostendorf, Mari and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1151.php}
@inproceedings{laskowski2007a,
  year={2007},
  title={A Geometric Interpretation of Non-Target-Normalized Maximum Cross-channel Correlation for Vocal Activity Detection in Meetings},
  booktitle={Proceedings of the HLT-NAACL 2007},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/LaskowskiSchultz_HLT2007.pdf},
  author={Laskowski, Kornel and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1147.php}
@inproceedings{jin2007whispering,
  note={Multimedia Interaction Human Machine Interface},
  title={Whispering Speaker Identification},
  year={2007},
  booktitle={Proceedings of ICME},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/JinSchultz_ICME2007.pdf},
  author={Jin, Qin and Jou, Szu-Chen (Stan) and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1149.php}
@inproceedings{tam2007bilingual,
  year={2007},
  title={Bilingual-LSA Based LM Adaptation for Spoken Language Translation},
  booktitle={Proceedings of ACL},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/TamSchultz_ACL2007.pdf},
  author={Tam, Yik-Cheung and Lane, Ian and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1135.php}
@inproceedings{bach2007the,
  title={The CMU TransTac 2007 Eyes-free and Hands-free Two-way Speech-to-Speech Translation System},
  year={2007},
  booktitle={International Workshop on Spoken Langage Translation},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/CMU-Transtac-IWSLT2007-camera.pdf},
  author={Bach, Nguyen and Eck, Matthias and Charoenpornsawat, Paisarn and Köhler, Thilo and Stüker, Sebastian and Nguyen, ThuyLinh and Hsiao, Roger and Waibel, Alex and Vogel, Stephan and Schultz, Tanja and Black, Alan W}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1146.php}
@inproceedings{laskowski2007on,
  year={2007},
  title={On The Correlation Between Perceptual and Contextual Aspects of Laughter},
  booktitle={16th International Congress of Phonetic Sciences},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/laskowskiICPhS2007.pdf},
  author={Laskowski, Kornel and Burger, Susanne}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1176.php}
@inproceedings{black2006speaker,
  year={2006},
  title={Speaker Clustering for Multilingual Synthesis},
  booktitle={Proceedings of the ISCA Tutorial and Researc Workshop on Multilingual Speech and Language Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/BlackSchultz_MULTILING2006.pdf},
  author={Black, Alan W and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1170.php}
@inproceedings{le2006acoustic,
  title={Acoustic-Phonetic Unit Similarities for Context Dependent Acoustic Model Portability},
  year={2006},
  booktitle={Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/LeSchultz_ICASSP2006.pdf},
  author={Le, Viet-Bac and Besacier, Laurent and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1173.php}
@inproceedings{schultz2006challenges,
  title={Challenges with Rapid Adaptation of Speech Translation Systems to New Language Pairs},
  year={2006},
  booktitle={Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SchultzBlack_ICASSP2006.pdf},
  author={Schultz, Tanja and Black, Alan W}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1169.php}
@inproceedings{jou2006articulatory,
  year={2006},
  title={Articulatory Feature Classification using Surface Electromyography},
  booktitle={Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/JouSchultz_ICASSP2006.pdf},
  author={Jou, Szu-Chen (Stan) and Maier-Hein, Lena and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1171.php}
@inproceedings{jin2006far,
  title={Far-Field Speaker Recognition},
  year={2006},
  booktitle={Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/JinSchultz_ICASSP2006.pdf},
  author={Jin, Qin and Pan, Yue and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1172.php}
@inproceedings{laskowski2006unsupervised,
  year={2006},
  title={Unsupervised Learning of Overlap Speech Model Parameters for Multichannel Speech Activity Detection in Meetings},
  booktitle={Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/LaskowskiSchultz_ICASSP2006.pdf},
  author={Laskowski, Kornel and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1175.php}
@inproceedings{schultz2006rapid,
  title={Rapid Language Portability of Speech Processing Systems},
  year={2006},
  booktitle={Invited keynote talk at the ISCA Tutorial and Research Workshop on Multilingual Speech and Language Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/MULTILING2006-Schultz-Spice.pdf},
  author={Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1161.php}
@inproceedings{tam2006unsupervised,
  title={Unsupervised Language Model Adaptation Using Latent Semantic Marginals},
  year={2006},
  booktitle={In proceedings of the 9th ISCA International Conference on Spoken Language Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/TamSchultz_Interspeech2006.pdf},
  author={Tam, Yik-Cheung and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1164.php}
@inproceedings{jou2006towards,
  title={Towards Continuous Speech Recognition Using Surface Electromyography},
  year={2006},
  booktitle={In proceedings of the 9th ISCA International Conference on Spoken Language Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/JouSchultz_Interspeech2006.pdf},
  author={Jou, Szu-Chen (Stan) and Schultz, Tanja and Walliczek, Matthias and Kraft, Florian and Waibel, Alex}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1159.php}
@inproceedings{charoenpornsawat2006example,
  year={2006},
  title={Example-based Grapheme-to-Phoneme Conversion for Thai},
  booktitle={In proceedings of the 9th ISCA International Conference on Spoken Language Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/PaisarnSchultz_Interspeech2006.pdf},
  author={Charoenpornsawat, Paisarn and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1160.php}
@inproceedings{woszczyna2006spontaneous,
  year={2006},
  title={Spontaneous Thai Speech Recognition},
  booktitle={In proceedings of the 9th ISCA International Conference on Spoken Language Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/WoszczynaSchultz_Interspeech2006.pdf},
  author={Woszczyna, Monika and Charoenpornsawat, Paisarn and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1163.php}
@inproceedings{walliczek2006sub,
  title={Sub-Word Unit based Non-audible Speech Recognition using Surface Electromyography},
  year={2006},
  booktitle={In proceedings of the 9th ISCA International Conference on Spoken Language Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/WalliczekSchultz_Interspeech2006.pdf},
  author={Walliczek, Matthias and Kraft, Florian and Jou, Szu-Chen (Stan) and Schultz, Tanja and Waibel, Alex}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1156.php}
@inproceedings{gehrig2006a,
  year={2006},
  title={A Comparative Study of Gaussian Selection Methods in Large Vocabulary Continuous Speech Recognition},
  booktitle={In proceedings of the 9th ISCA International Conference on Spoken Language Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/A_Comparative_Study_of_Gaussian_Selection_Methods_in_Large_Vocabulary_ContinuousSpeech_Recognition.pdf},
  author={Gehrig, Dirk and Schaaf, Thomas}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1157.php}
@inproceedings{neiberg2006emotion,
  year={2006},
  title={Emotion Recognition in Spontaneous Speech Using GMMs},
  booktitle={In proceedings of the 9th ISCA International Conference on Spoken Language Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/is061581.pdf},
  author={Neiberg, Daniel and Elenius, Kjell and Laskowski, Kornel}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1158.php}
@inproceedings{fügen2006advances,
  title={Advances in Lecture Recognition: The ISL RT-06S Evaluation System},
  year={2006},
  booktitle={In proceedings of the 9th ISCA International Conference on Spoken Language Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/is061415.pdf},
  author={Fügen, Christian and Wölfel, Matthias and McDonough, John and Ikbal, Shajith and Kraft, Florian and Laskowski, Kornel and Ostendorf, Mari and Stüker, Sebastian}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1165.php}
@inproceedings{fügen2006open,
  year={2006},
  title={Open Domain Speech Translation: From Seminars and Speeches to Lectures},
  note={JEP},
  booktitle={Journies d'E'tude sur la Parole Invited paper and keynote talk},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/FuegenSchultz_JEP2006.pdf},
  author={Fügen, Christian and Kolss, Muntsin and Paulik, Matthias and Stüker, Sebastian and Schultz, Tanja and Waibel, Alex}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1155.php}
@inproceedings{batliner2006combining,
  year={2006},
  title={Combining Efforts for Improving Automatic Classification of Emotional User States},
  booktitle={In proceedings of the 5th Slovenian and 1st International Language Technologies Conference},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/45_Batliner_1of2.pdf},
  author={Batliner, Anton and Steidl, Stefan and Schuller, Björn and Seppi, Dino and Laskowski, Kornel and Vogt, Thurid and Devillers, Laurence and Vidrascu, Laurence and Amir, Noam and Kessous, Loic and Aharonson, Vered}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1168.php}
@inproceedings{laskowski2006annotation,
  title={Annotation and Analysis of Emotionally Relevant Behavior in the ISL Meeting Corpus},
  year={2006},
  booktitle={In proceedings of the 5th ELRA International Conference on Language Resources and Evaluation},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/LREC2006slides.pdf},
  author={Laskowski, Kornel and Burger, Susanne}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1174.php}
@inproceedings{fügen2006the,
  title={The ISL RT-06S Speech-to-Text System},
  year={2006},
  booktitle={Presented at the 3rd Joint Workshop on Multimodal Interaction and Related Machine Learning Algorithms},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/rt06s-system-description-v10.pdf},
  author={Fügen, Christian and Ikbal, Shajith and Kraft, Florian and Kumatani, kenichi and Laskowski, Kornel and McDonough, John and Ostendorf, Mari and Stüker, Sebastian and Wölfel, Matthias}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1166.php}
@inproceedings{neiberg2006emotion,
  title={Emotion Recognition in Spontaneous Speech},
  year={2006},
  booktitle={In proceedings of the 19th Swedish Phonetics Conference},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/neiberg_et_al_fon06.pdf},
  author={Neiberg, Daniel and Elenius, Kjell and Karlsson, Inger and Laskowski, Kornel}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1167.php}
@inproceedings{charoenpornsawat2006thai,
  year={2006},
  title={Thai Grapheme-Based Speech Recognition},
  booktitle={Human Language Technology Conference},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/CharoenpornsawatSchultz_HLT2006.pdf},
  author={Charoenpornsawat, Paisarn and Hewavitharana, Sanjika and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1177.php}
@inproceedings{stelzner2006a,
  title={A large-scale database of human movements to humanize robot motion},
  year={2006},
  booktitle={French-German Workshop on Humanoid and Legged Robots, HLR 2006},
  author={Stelzner, Günther and Simonids, Christian and Boesnach, Ingo and Köhler, Hildegard and Gehrig, Dirk and Stein, Thorsten and Fischer, Andreas}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1185.php}
@inproceedings{jou2005whispery,
  year={2005},
  title={Whispery Speech Recognition using Adapted Articulatory Features},
  booktitle={Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/JouSchultz_ICASSP05.pdf},
  author={Jou, Szu-Chen (Stan) and Schultz, Tanja and Waibel, Alex}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1184.php}
@inproceedings{suebvisai2005thai,
  title={Thai Automatic Speech Recognition},
  year={2005},
  booktitle={Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SuebvisaiSchultz_ICASSP05.pdf},
  author={Suebvisai, Sinaporn and Charoenpornsawat, Paisarn and Black, Alan W and Woszczyna, Monika and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1186.php}
@inproceedings{honal2005automatic,
  year={2005},
  title={Automatic Disfluency Removal on Recognized Spontaneous Speech - Rapid Adaptation to Speaker-Dependent Disfluencies},
  booktitle={Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/HonalSchultz_ICASSP05.pdf},
  author={Honal, Matthias and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1182.php}
@inproceedings{tam2005dynamic,
  year={2005},
  title={Dynamic Language Model Adaptation using Variational Bayes Inference},
  booktitle={Proceedings of the Eurospeech},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/TamSchultz_Eurospeech2005.pdf},
  author={Tam, Yik-Cheung and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1183.php}
@inproceedings{paulik2005document,
  title={Document Driven Machine Translation Enhanced Automatic Speech Recognition},
  year={2005},
  booktitle={Proceedings of the Eurospeech},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/PaulikSchultz_Eurospeech2005.pdf},
  author={Paulik, Matthias and Fügen, Christian and Schaaf, Thomas and Schultz, Tanja and Stüker, Sebastian and Waibel, Alex}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1498.php}
@inproceedings{maier-hein2005session,
  year={2005},
  title={Session Independent Non-Audible Speech Recognition Using Surface Electromyography},
  booktitle={Proceedings of the Automatic Speech Recognition and Understanding Workshop},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Maier-HeinSchultz_ASRU2005.pdf},
  author={Maier-Hein, Lena and Metze, Florian and Schultz, Tanja and Waibel, Alex}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1496.php}
@inproceedings{paulik2005speech,
  title={Speech Translation Enhanced Automatic Speech Recognition},
  year={2005},
  booktitle={Proceedings of the Automatic Speech Recognition and Understanding Workshop},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/PaulikSchultz_ASRU2005.pdf},
  author={Paulik, Matthias and Stüker, Sebastian and Fügen, Christian and Schultz, Tanja and Schaaf, Thomas and Waibel, Alex}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1181.php}
@inproceedings{honal2005identifying,
  year={2005},
  title={Identifying User State using Electroencephalographic Data},
  booktitle={Proceedings of the International Conference on Multimodal Input},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/HonalSchultz_ICMI2005.pdf},
  author={Honal, Matthias and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1180.php}
@inproceedings{engelbrecht2005rapid,
  title={Rapid Development of an Afrikaans-English Speech-to-Speech Translator},
  year={2005},
  booktitle={Proceedings of International Workshop of Spoken Language Translation},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/EngelbrechtSchultz_IWSLT2005.pdf},
  author={Engelbrecht, Herman and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1198.php}
@inproceedings{kirchhoff2004icassp,
  title={ICASSP 2004, Special Session on Multilinguality in Speech Processing},
  year={2004},
  booktitle={Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing},
  author={Kirchhoff, Katrin and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1192.php}
@inproceedings{jin2004speaker,
  year={2004},
  title={Speaker Segmentation and Clustering in Meetings},
  booktitle={International Conference of Spoken Language Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SchultzJin_icslp04.pdf},
  author={Jin, Qin and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1191.php}
@inproceedings{metze2004issues,
  year={2004},
  title={Issues in Meeting Transcription - The ISL Meeting Transcription System},
  booktitle={International Conference of Spoken Language Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SchultzMetze_icslp04.pdf},
  author={Metze, Florian and Jin, Qin and Fügen, Christian and Laskowski, Kornel and Pan, Yue and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1195.php}
@inproceedings{stüker2004a,
  title={A Grapheme based Speech Recognition System for Russian},
  year={2004},
  booktitle={SPECOM Speech and Computer},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SchultzStueker_SPECOM04.pdf},
  author={Stüker, Sebastian and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1187.php}
@inproceedings{schultz2004towards,
  title={Towards Rapid Language Portability of Speech Processing Systems},
  year={2004},
  booktitle={Conference on Speech and Language Systems for Human Communication},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Schultz_SPLASH04.pdf},
  author={Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1200.php}
@inproceedings{jin2004speaker,
  year={2004},
  title={Speaker Segmentation and Clustering in Meetings},
  booktitle={NIST Meeting Recognition Workshop},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SchultzJin_NIST04.pdf},
  author={Jin, Qin and Laskowski, Kornel and Schultz, Tanja and Waibel, Alex}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1188.php}
@inproceedings{yu2004the,
  year={2004},
  title={The ISL RT04 Mandarin Broadcast News Evaluation System},
  booktitle={EARS Rich Transcription Workshop},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SchultzYu_EARS04.pdf},
  author={Yu, Hua and Tam, Yik-Cheung and Schaaf, Thomas and Stüker, Sebastian and Jin, Qin and Noamany, Mohamed and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1197.php}
@inproceedings{waibel2004towards,
  title={Towards Language Portability in Statistical Machine Translation},
  year={2004},
  booktitle={Invited paper, Special Session on Multilinguality in Speech Processing, Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SchultzWaibel_icassp04.pdf},
  author={Waibel, Alex and Schultz, Tanja and Vogel, Stephan and Fügen, Christian and Honal, Matthias and Kolss, Muntsin and Reichert, Jürgen and Stüker, Sebastian}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1193.php}
@inproceedings{jou2004adaptation,
  title={Adaptation for Soft Whisper Recognition Using a Throat Microphone},
  year={2004},
  booktitle={International Conference of Spoken Language Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SchultzJou_icslp04.pdf},
  author={Jou, Szu-Chen (Stan) and Schultz, Tanja and Waibel, Alex}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1194.php}
@inproceedings{saleem2004using,
  title={Using Word Lattice Information for a Tighter Coupling in Speech Translation Systems},
  year={2004},
  booktitle={International Conference of Spoken Language Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SchultzSaleem_icslp04.pdf},
  author={Saleem, Shirin and Jou, Szu-Chen (Stan) and Vogel, Stephan and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1196.php}
@inproceedings{mimer2004graphembasierte,
  title={Graphembasierte Spracherkennung unter Verwendung flexibler Entscheidungsbäume},
  year={2004},
  booktitle={Elektronische Sprachsignalverarbeitung ESSV},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SchultzMimer_ESSV04.pdf},
  author={Mimer, Borislava and Stüker, Sebastian and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1199.php}
@inproceedings{metze2004issues,
  title={Issues in Meeting Transcription - The ISL Meeting Transcription System},
  year={2004},
  booktitle={NIST Meeting Recognition Workshop},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SchultzMetze_NIST04.pdf},
  author={Metze, Florian and Fügen, Christian and Pan, Yue and Schultz, Tanja and Yu, Hua}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1189.php}
@inproceedings{katzenmaier2004human,
  year={2004},
  title={Human-Human-Robot Interaction},
  booktitle={International Conference on Multimodal Interfaces},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SchultzKatzenmaier_icmi04.pdf},
  author={Katzenmaier, Michael and Schultz, Tanja and Stiefelhagen, Rainer}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1190.php}
@inproceedings{laskowski2004crosscorrelation,
  title={Crosscorrelation-based Multispeaker Speech Activity Detection},
  year={2004},
  booktitle={International Conference of Spoken Language Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/SchultzLaskowski_icslp04.pdf},
  author={Laskowski, Kornel and Jin, Qin and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1201.php}
@inproceedings{schultz2004a,
  year={2004},
  title={A Thai Speech Translation System For Medical Dialogs},
  booktitle={Proceedings of the Human Language Technologies},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/HLT04-Schultz.pdf},
  author={Schultz, Tanja and Alexander, Dorcas and Black, Alan W and Peterson, Kay and Suebvisai, Sinaporn and Waibel, Alex}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1208.php}
@inproceedings{stüker2003integrating,
  year={2003},
  title={Integrating Multilingual Articulatory Features into Speech Recognition},
  booktitle={Proceedings of the 8th European Conference on Speech Communication and Technology},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Euro03-StuekerSchultz.pdf},
  author={Stüker, Sebastian and Metze, Florian and Schultz, Tanja and Waibel, Alex}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1212.php}
@inproceedings{waibel2003smart,
  title={SMaRT: The Smart Meeting Room Task at ISL},
  year={2003},
  booktitle={Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/ICASSP03-schultz.pdf},
  author={Waibel, Alex and Schultz, Tanja and Bett, Michael and Malkin, Robert and Rogina, Ivica and Stiefelhagen, Rainer and Yang, Jie}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1204.php}
@inproceedings{wang2003non,
  title={Non-Native Spontaneous Speech Recognition through Polyphone Decisision Tress Specialization},
  year={2003},
  booktitle={Proceedings of the 8th European Conference on Speech Communication and Technology},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Euro03-WangSchultz.pdf},
  author={Wang, Zhirong and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1203.php}
@inproceedings{waibel2003speechalator,
  title={Speechalator: two-way speech-to-speech translation on a consumer PDA},
  year={2003},
  booktitle={Proceedings of the 8th European Conference on Speech Communication and Technology},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Euro03-BlackSchultz.pdf},
  author={Waibel, Alex and Badran, Ahmed and Black, Alan W and Frederking, Robert and Gates, Donna and Lavie, Alon and Levin, Lori and Lenzo, Kevin and Tomokiyo-Mayfield, Laura and Reichert, Jürgen and Schultz, Tanja and Wallace, Dorcas and Woszczyna, Monika and Zhang, Jing}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1205.php}
@inproceedings{yu2003enhanced,
  year={2003},
  title={Enhanced Tree Clustering with Single Pronunciation Dictionary for Conversational Speech Recognition},
  booktitle={Proceedings of the 8th European Conference on Speech Communication and Technology},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Euro03-YuSchultz.pdf},
  author={Yu, Hua and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1206.php}
@inproceedings{honal2003correction,
  year={2003},
  title={Correction of Disfluencies in Spontaneous Speech using a Noisy-Channel Approach},
  booktitle={Proceedings of the 8th European Conference on Speech Communication and Technology},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Euro03-HonalSchultz.pdf},
  author={Honal, Matthias and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1213.php}
@inproceedings{wang2003comparison,
  title={Comparison of Acoustic Model Adaptation Techniques},
  year={2003},
  booktitle={Non-native Speech},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/ICASSP03-wang.pdf},
  author={Wang, Zhirong and Schultz, Tanja and Waibel, Alex}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1210.php}
@inproceedings{yu2003implicit,
  title={Implicit Trajectory Modeling through Gaussian Transition Models},
  year={2003},
  booktitle={Human Language Technology & North American Chapter of the Association for Computational Linguistics},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/HLT03-YuSchultz.pdf},
  author={Yu, Hua and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1207.php}
@inproceedings{killer2003grapheme,
  year={2003},
  title={Grapheme based Speech Recognition},
  booktitle={Proceedings of the 8th European Conference on Speech Communication and Technology},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Euro03-KillerSchultz.pdf},
  author={Killer, Mirjam and Stüker, Sebastian and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1211.php}
@inproceedings{stüker2003multilingual,
  year={2003},
  title={Multilingual Articulatory Features},
  booktitle={Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/ICASSP03-stueker.pdf},
  author={Stüker, Sebastian and Schultz, Tanja and Metze, Florian and Waibel, Alex}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1209.php}
@inproceedings{waibel2003speechalator,
  year={2003},
  title={Speechalator: Two-way Speech-to-Speech Translation in your Hand},
  booktitle={Human Language Technology & North American Chapter of the Association for Computational Linguistics},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/HLT03-WaibelSchultz.pdf},
  author={Waibel, Alex and Badran, Ahmed and Black, Alan W and Frederking, Robert and Gates, Donna and Lavie, Alon and Levin, Lori and Lenzo, Kevin and Tomokiyo-Mayfield, Laura and Reichert, Jürgen and Schultz, Tanja and Wallace, Dorcas and Woszczyna, Monika and Zhang, Jing}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1202.php}
@inproceedings{fügen2003efficient,
  year={2003},
  title={Efficient Handling of Multilingual Language Models},
  booktitle={Proceedings of the Workshop of Automatic Speech Recognition Understanding},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Asru03-FuegenSchultz.pdf},
  author={Fügen, Christian and Stüker, Sebastian and Soltau, Hagen and Metze, Florian and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1219.php}
@inproceedings{schultz2002improvements,
  year={2002},
  title={Improvements in Non-verbal Cue Identification using Multilingual Phone Strings},
  booktitle={Proceedings of the Speech-to-Speech Translation Workshop on the 40th Anniversary Meeting of the Association for Computational Linguistics},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/schultz_ACL2002.pdf},
  author={Schultz, Tanja and Jin, Qin and Laskowski, Kornel and Tribble, Alicia and Waibel, Alex}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1218.php}
@inproceedings{lavie2002a,
  title={A Multi-Perspective Evaluation of the NESPOLE! Speech-to-Speech Translation System},
  year={2002},
  booktitle={Proceedings of the Speech-to-Speech Translation Workshop on the 40th Anniversary Meeting of the Association for Computational Linguistics},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/s2s013.pdf},
  author={Lavie, Alon and Metze, Florian and Cattoni, Roldano and Constantini, Erica}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1216.php}
@inproceedings{schultz2002globalphone,
  title={GlobalPhone: A Multilingual Speech and Text Database developed at Karlsruhe University},
  year={2002},
  booktitle={Proceedings of the International Conference of Spoken Language Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/schultz_icslp02.pdf},
  author={Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1224.php}
@inproceedings{schultz2002speaker,
  year={2002},
  title={Speaker, Accent, and Language Identification using Multilingual Phone Strings},
  booktitle={Proceedings of the Human Language Technology Meeting},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/schultz_hlt2002.pdf},
  author={Schultz, Tanja and Jin, Qin and Waibel, Alex}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1220.php}
@inproceedings{zhao2002towards,
  year={2002},
  title={Towards Robust Parametric Segmental Trajectory Model for Vowel Recognition},
  booktitle={Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/ICASSP02-bzhao.pdf},
  author={Zhao, Bing and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1223.php}
@inproceedings{metze2002the,
  title={The NESPOLE! Speech-to-Speech Translation System},
  year={2002},
  booktitle={Proceedings of the Human Language Technology Meeting},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/lavie-hlt02demo.pdf},
  author={Metze, Florian and McDonough, John and Soltau, Hagen and Langley, Chad and Lavie, Alon and Schultz, Tanja and Waibel, Alex and Cattoni, Roldano and Lazzari, Gianni and Pianesi, Fabio}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1222.php}
@inproceedings{metze2002enhancing,
  title={Enhancing the Usability and Performance of NESPOLE!: a Real-World Speech-to-Speech Translation System},
  year={2002},
  booktitle={Proceedings of the Human Language Technology Meeting},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/lavie-hlt02poster.pdf},
  author={Metze, Florian and McDonough, John and Soltau, Hagen and Lavie, Alon and Levin, Lori and Langley, Chad and Schultz, Tanja and Waibel, Alex and Cattoni, Roldano and Lazzari, Gianni and Mana, Nadia and Pianesi, Fabio and Pianta, Emanuelle}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1215.php}
@inproceedings{wang2002towards,
  year={2002},
  title={Towards Universal Speech Recognition},
  booktitle={Proceedings of the International Conference on Multimodal Interfaces},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/ICMI02-Wang.pdf},
  author={Wang, Zhirong and Topkara, Umut and Schultz, Tanja and Waibel, Alex}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1217.php}
@inproceedings{jin2002phonetic,
  title={Phonetic Speaker Identification},
  year={2002},
  booktitle={Proceedings of the International Conference of Spoken Language Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/ICSLP02-qjin.pdf},
  author={Jin, Qin and Schultz, Tanja and Waibel, Alex}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1231.php}
@inproceedings{fügen2001lingwear,
  year={2001},
  title={LingWear: A Mobil Tourist Information System},
  booktitle={Proceedings of the Human Language Technology Meeting},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/fuegen_hlt01-final.pdf},
  author={Fügen, Christian and Westphal, Martin and Schneider, Mike and Schultz, Tanja and Waibel, Alex}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1229.php}
@inproceedings{lavie2001domain,
  year={2001},
  title={Domain Portability in Speech-to-Speech Translation},
  booktitle={Proceedings of the Human Language Technology Meeting},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/levin_hlt01-final.pdf},
  author={Lavie, Alon and Levin, Lori and Schultz, Tanja and Waibel, Alex}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1230.php}
@inproceedings{waibel2001advances,
  year={2001},
  title={Advances in Meeting Recognition},
  booktitle={Proceedings of the Human Language Technology Meeting},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/schultz_hlt01-notebook.pdf},
  author={Waibel, Alex and Yu, Hua and Soltau, Hagen and Schultz, Tanja and Schaaf, Thomas and Pan, Yue and Metze, Florian and Bett, Michael}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1228.php}
@inproceedings{schultz2001the,
  year={2001},
  title={The ISL Meeting Room System},
  booktitle={Proceedings of the Workshop on Hands-Free Speech Communication},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/schultz_hsc01.ps.gz},
  author={Schultz, Tanja and Waibel, Alex and Bett, Michael and Metze, Florian and Pan, Yue and Ries, Klaus and Schaaf, Thomas and Soltau, Hagen and Yu, Hua and Zechner, Klaus}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1227.php}
@inproceedings{waibel2001advances,
  year={2001},
  title={Advances in Automatic Meeting Record Creation and Access},
  booktitle={Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/schultz_icassp01.pdf},
  author={Waibel, Alex and Bett, Michael and Ries, Klaus and Schaaf, Thomas and Schultz, Tanja and Soltau, Hagen and Yu, Hua and Zechner, Klaus}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1226.php}
@inproceedings{schultz2001experiments,
  year={2001},
  title={Experiments on Cross-language Acoustic Modeling},
  booktitle={Proceedings of the 7th European Conference on Speech Communication and Technology},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/schultz_euro01.pdf},
  author={Schultz, Tanja and Waibel, Alex}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1225.php}
@inproceedings{kunzmann2001portability,
  title={Portability of Automatic Speech Recognition Technology to New Languages: Multilinguality Issues and Speech/Text Resources},
  year={2001},
  booktitle={Panel Session on Automatic Speech Recognition and Understanding},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/asru2001.ppt},
  author={Kunzmann, Jimmy and Choukri, Khalid and Jahnke, Eric and Kiessling, Andreas and Knill, Kate and Lamel, Lori and Schultz, Tanja and Yamamoto, Seiichi}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1236.php}
@inproceedings{schultz2000polyphone,
  title={Polyphone Decision Tree Specialization for Language Adaptation},
  year={2000},
  booktitle={Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/schultz_icassp00-multi.pdf},
  author={Schultz, Tanja and Waibel, Alex}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1234.php}
@inproceedings{Çarki2000turkish,
  title={Turkish LVCSR: Towards better Speech Recognition for Agglutinative Languages},
  year={2000},
  booktitle={Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/schultz_icassp00-tu.pdf},
  author={Çarki, Kenan and Geutner, Petra and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1235.php}
@inproceedings{metze2000confidence,
  title={Confidence Measure based Language Identification},
  year={2000},
  booktitle={Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/schultz_icassp00-lid.pdf},
  author={Metze, Florian and Kemp, Thomas and Schaaf, Thomas and Schultz, Tanja and Soltau, Hagen}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1232.php}
@inproceedings{kurematsu2000verbmobil,
  title={Verbmobil Dialogues: Multifaced Analysis},
  year={2000},
  booktitle={Proceedings of the International Conference of Spoken Language Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/kurematsu_icslp2000.pdf},
  author={Kurematsu, Akira and Akegami, Youichi and Burger, Susanne and Jekat, Susanne and Lause, Brigitte and MacLaren, Victoria and Oppermann, Daniela and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1095.php}
@inproceedings{li2000the,
  year={2000},
  title={The I4U System in NIST 2008 Speaker Recognition Evaluation},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/LiSchultz-ICASSP2009.pdf},
  author={Li, Haizhou and Ma, Bin and Lee, K-A. and Sun, Hanwu and Zhu, Donglai and Sim, Khe Chai and You, Changhuai and Tong, Rong and Karkkainen, Ismo and Huang, Chien-Lin and Pervouchine, Vladimir and Guo, Wu and Li, Yijie and Dai, Lirong and Nosratighods, M. and Tharmarajah, T. and Epps, Julien and Ambikairajah, E. and Chng, E.-S. and Jin, Qin and Schultz, Tanja}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1233.php}
@inproceedings{schultz2000language,
  title={Language Portability in Acoustic Modeling},
  year={2000},
  pages={59-64},
  booktitle={Proceedings of the Workshop on Multilingual Speech Communication},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/schultz_msc00.pdf},
  author={Schultz, Tanja and Waibel, Alex}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1237.php}
@inproceedings{schultz1999language,
  title={Language adaptive LVCSR through Polyphone Decision Tree Specialization},
  pages={85-90},
  year={1999},
  booktitle={Workshop on Multi-lingual Interoperability in Speech Technology},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/schultz_mist99.pdf.zip},
  author={Schultz, Tanja and Waibel, Alex}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1238.php}
@inproceedings{reichert1999mandarin,
  pages={815-818},
  year={1999},
  title={Mandarin Large Vocabulary Speech Recognition using the GlobalPhone Database},
  booktitle={Proceedings of the 6th European Conference on Speech Communication and Technology},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/EUROSPEECH99-reichert.pdf},
  author={Reichert, Jürgen and Schultz, Tanja and Waibel, Alex}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1240.php}
@inproceedings{kurematsu1999development,
  year={1999},
  title={Development of Data Collection and Transliteration of Japanese Spontaneous Database in the Travel Arrangement Task Domain},
  booktitle={International Workshop on East-Asien Language Resources and Evaluation},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/kurematsu_cocosda99.pdf},
  author={Kurematsu, Akira and Akegami, Youichi and Schultz, Tanja and Burger, Susanne}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1241.php}
@inproceedings{schultz1999experiments,
  title={Experiments towards a Multi-language LVCSR Interface},
  year={1999},
  booktitle={2nd International Conference on Multi-modal Interfaces},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/schultz_icmi99.ps.gz},
  author={Schultz, Tanja and Waibel, Alex}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1239.php}
@inproceedings{kiecza1999data,
  title={Data-Driven Determination of Appropriate Dictionary Units for Korean LVCSR},
  pages={323-327},
  year={1999},
  booktitle={1999 Proceedings of the International Conference on Speech Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/schultz_icsp99.pdf.zip},
  author={Kiecza, Daniel and Schultz, Tanja and Waibel, Alex}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1243.php}
@inproceedings{schultz1998language,
  title={Language Independent and Language Adaptive Large Vocabulary Speech Recognition},
  pages={1819--1822},
  year={1998},
  booktitle={Proceedings of the International Conference of Spoken Language Processing , Vol. 5},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/schultz_icslp98.pdf.zip},
  author={Schultz, Tanja and Waibel, Alex}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1242.php}
@inproceedings{westphal1998linear,
  title={Linear Discriminant - A New Criterion for Speaker Normalization},
  year={1998},
  pages={1819--1822},
  booktitle={Proceedings of the International Conference of Spoken Language Processing , Vol. 5},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/ICSLP98-west.pdf.zip},
  author={Westphal, Martin and Schultz, Tanja and Waibel, Alex}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1245.php}
@inproceedings{schultz1998adaptation,
  pages={207-210},
  year={1998},
  title={Adaptation of Pronunciation Dictionaries for Recognition of Unseen Languages},
  booktitle={Workshop on Speech and Communication},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/schultz_specom98.pdf.zip},
  author={Schultz, Tanja and Waibel, Alex}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1248.php}
@inproceedings{soltau1998recognition,
  year={1998},
  title={Recognition of Music Types},
  booktitle={Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/ICASSP98-hagen.pdf.zip},
  author={Soltau, Hagen and Schultz, Tanja and Westphal, Martin and Waibel, Alex}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1249.php}
@inproceedings{schultz1998multilingual,
  pages={259-262},
  year={1998},
  title={Multilingual and Crosslingual Speech Recognition},
  booktitle={Proceedings of the DARPA Broadcast News Transcription and Understanding},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/schultz_darpa98.pdf.zip},
  author={Schultz, Tanja and Waibel, Alex}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1247.php}
@inproceedings{schultz1998development,
  title={Development of Multilingual Acoustic Models in the GlobalPhone Project},
  pages={311-316},
  year={1998},
  booktitle={Proceedings of the 1st Workshop on Text, Speech, and Dialogue, ; TSD},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/schultz_tsd98.pdf.zip},
  author={Schultz, Tanja and Waibel, Alex}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1246.php}
@inproceedings{schultz1998das,
  year={1998},
  title={Das Projekt GlobalPhone: Multilinguale Spracherkennung},
  booktitle={Computers, Linguistics, and Phonetics between Language and Speech. Proceedings of the 4th Conference on NLP},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/schultz_konvens98.pdf.zip},
  author={Schultz, Tanja and Waibel, Alex}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1250.php}
@inproceedings{schultz1997japanese,
  year={1997},
  pages={371--373},
  title={Japanese LVCSR on the Spontaneous Scheduling Task with JANUS-3},
  booktitle={Proceedings of the 5th European Conference on Speech Communication and Technology, Vol. 1},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/schultz_euro97_jsst.pdf.zip},
  author={Schultz, Tanja and Koll, Detlef and Waibel, Alex}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1251.php}
@inproceedings{schultz1997fast,
  pages={371--373},
  year={1997},
  title={Fast Bootstrapping of LVCSR Systems with Multilingual Phoneme Sets},
  booktitle={Proceedings of the 5th European Conference on Speech Communication and Technology, Vol. 1},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/schultz_euro97_gp.pdf.zip},
  author={Schultz, Tanja and Waibel, Alex}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1252.php}
@inproceedings{schultz1997the,
  title={The GlobalPhone Project: Multilingual LVCSR with JANUS-3},
  year={1997},
  pages={20--27},
  booktitle={Multilingual Information Retrieval Dialogs: 2nd SQEL Workshop},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/schultz_sqel97.pdf.zip},
  author={Schultz, Tanja and Westphal, Martin and Waibel, Alex}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1254.php}
@inproceedings{schultz1996lvcsr,
  title={LVCSR-based Language Identification},
  pages={781-784},
  year={1996},
  booktitle={Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/schultz_icassp96.pdf.zip},
  author={Schultz, Tanja and Rogina, Ivica and Waibel, Alex}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1253.php}
@inproceedings{schultz1996automatische,
  title={Automatische Identifizierung spontan gesprochener Sprachen mit neuronalen Netzen},
  year={1996},
  pages={102--110},
  booktitle={Proceedings of the 3rd Conference on Natural Language Processing and Speech Technology},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/schultz_konvens96.pdf.zip},
  author={Schultz, Tanja and Soltau, Hagen}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1256.php}
@inproceedings{schultz1995experiments,
  year={1995},
  pages={89--94},
  title={Experiments with LVCSR based Language Identification},
  booktitle={Proceedings of the Speech Research Symposium SRS XV},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/schultz_srs95.pdf.zip},
  author={Schultz, Tanja and Rogina, Ivica and Waibel, Alex}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1257.php}
@inproceedings{schultz1995acoustic,
  title={Acoustic and Language Modeling of Human and Nonhuman Noises for Human-to-Human Spontaneous Speech Recognition},
  pages={293--296},
  year={1995},
  booktitle={Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, Vol. 1},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/schultz_icassp95.pdf.zip},
  author={Schultz, Tanja and Rogina, Ivica}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1255.php}
@inproceedings{suhm1995janus,
  title={JANUS: Towards Multilingual Spoken Language Translation},
  pages={185-189},
  year={1995},
  booktitle={ARPA Workshop on Speech and Natural Language Technology},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/suhm_slt95.pdf},
  author={Suhm, B and Geutner, Petra and Kemp, Thomas and Lavie, Alon and Tomokiyo-Mayfield, Laura and McNair, A.E and Rogina, Ivica and Schultz, Tanja and Sloboda, T and Ward, W and Woszczyna, Monika and Waibel, Alex}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/konferenzen_1258.php}
@inproceedings{woszczyna1994towards,
  pages={345--348},
  year={1994},
  title={Towards Spontaneous Speech Translation},
  booktitle={Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, Vol. 1},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/ICASSP94.janus.pdf},
  author={Woszczyna, Monika and Aoki-Waibel, N and Buø, F.D and Coccaro, N and Horiguchi, K and Kemp, Thomas and Lavie, Alon and McNair, A.E and Polzin, T and Rogina, Ivica and Rose, C.P and Schultz, Tanja and Suhm, B and Tomita, M and Waibel, Alex}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/1853_2897.php}
@bachelorsthesis{selvanayagam2014modellierung,
  school={Karlsruher Institut für Technologie},
  title={Modellierung der Dauer von HMM Zuständen für multilinguale Spracherkennung},
  year={2014},
  supervisor={Telaar, Dominic and Schultz, Tanja},
  author={Selvanayagam, Kopiga}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/1853_2896.php}
@bachelorsthesis{deßloch2014spoken,
  school={Karlsruher Institut für Technologie},
  title={Spoken Term Detection using Deep Neural Networks},
  year={2014},
  supervisor={Telaar, Dominic and Vu, Thang and Schultz, Tanja},
  author={Deßloch, Florian}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/1853_2863.php}
@bachelorsthesis{dinh2014fundamental,
  school={Karlsruher Institut für Technologie},
  title={Fundamental Frequency Analysis and Generation for Whispered to Audible Speech Conversion},
  year={2014},
  supervisor={Janke, Matthias and Schultz, Tanja},
  author={Dinh, Martin}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/1853_2837.php}
@bachelorsthesis{onogur2014hierarchische,
  school={Karlsruher Institut für Technologie},
  year={2014},
  title={Hierarchische Diskriminierung von visuellem und auditivem Aufmerksamkeitsfokus durch Ereigniskorrelierte Potentiale},
  supervisor={Heger, Dominik},
  author={Onogur, Sinan}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/1853_2786.php}
@bachelorsthesis{becker2014adaption,
  school={Karlsruher Institut für Technologie},
  title={Adaption of a Cognitive Decision-Making Model through the Application of Workload Recognition},
  year={2014},
  supervisor={Putze, Felix},
  author={Becker, Vincent}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/1853_2727.php}
@bachelorsthesis{leidig2014single,
  school={Karlsruher Institut für Technologie},
  year={2014},
  title={Single and Combined Features for the Detection of Anglicisms in German and Afrikaans},
  supervisor={Schlippe, Tim and Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/BA_SebastianLeidig.pdf},
  author={Leidig, Sebastian}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/1853_2826.php}
@bachelorsthesis{röhrs2013kalman,
  school={Karlsruher Institut für Technologie},
  title={Kalman Filter zur Bestimmung der Blickrichtung durch EOG},
  year={2013},
  supervisor={Herff, Christian},
  author={Röhrs, Eike Simon}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/1853_2802.php}
@bachelorsthesis{sazinger2013entwicklung,
  school={Karlsruher Institut für Technologie},
  year={2013},
  title={Entwicklung und Evaluation von Benutzerschnittstellen zur Unterstützung bei einer komplexen Aufgabe unter verschiedenen Workload-Bedingungen},
  supervisor={Putze, Felix and Schultz, Tanja},
  author={Sazinger, Matthias}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/1853_2801.php}
@bachelorsthesis{klinowski2013designing,
  school={Karlsruher Institut für Technologie},
  year={2013},
  title={Designing a workload adaptive dialog system with flexible initiative},
  supervisor={Putze, Felix and Schultz, Tanja},
  author={Klinowski, Patrick}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/1853_2800.php}
@bachelorsthesis{axtmann2013online,
  school={Karlsruher Institut für Technologie},
  year={2013},
  title={Online detection of error related potentials using electroencephalography and spatial filtering},
  supervisor={Putze, Felix and Schultz, Tanja},
  author={Axtmann, Michael}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/1853_2798.php}
@bachelorsthesis{stefano2013classification,
  school={Karlsruher Institut für Technologie},
  title={Classification of perceptual modality and processing code in multimodal cognition processes using EEG},
  year={2013},
  supervisor={Putze, Felix and Schultz, Tanja},
  author={Stefano, Antonino Simone Di}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/1853_2799.php}
@bachelorsthesis{katev2013comparison,
  school={Karlsruher Institut für Technologie},
  title={Comparison of individualized Reinforcement Learning models with real-life subjects for a complex learning task},
  year={2013},
  supervisor={Putze, Felix and Schultz, Tanja},
  author={Katev, Kalin}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/1853_2784.php}
@bachelorsthesis{adigüzel2013signalinterpolation,
  school={Karlsruher Institut für Technologie},
  title={Signalinterpolation für Elektrodenarrays in der EMG-basierten Spracherkennung},
  year={2013},
  supervisor={Wand, Michael and Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/BA-Adiguezel.pdf},
  author={Adigüzel, Davud}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/1853_2459.php}
@bachelorsthesis{vogel2013kontextsensitive,
  school={Karlsruher Institut für Technologie},
  year={2013},
  title={Kontextsensitive Konvertierung von geflüsterter auf hörbare Sprache: Implementierung und Evaluation},
  supervisor={Wand, Michael and Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/BA_MaximilianVogel.pdf},
  author={Vogel, Maximilian}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/1853_2427.php}
@bachelorsthesis{yurchenko2013cross,
  school={Karlsruher Institut für Technologie},
  title={Cross-Lingual Pronunciation Dictionary Production},
  year={2013},
  supervisor={Schlippe, Tim and Schultz, Tanja},
  author={Yurchenko, Kateryna}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/1853_2289.php}
@bachelorsthesis{himmelsbach2013rauschunterdr,
  school={Karlsruher Institut für Technologie},
  title={Rauschunterdrückung durch Quellenseparation in der EMG-basierten Spracherkennung},
  year={2013},
  supervisor={Wand, Michael and Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/BA_Adam_Himmelsbach.pdf},
  author={Himmelsbach, Adam}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/1853_2193.php}
@bachelorsthesis{heistermann2013decomposition,
  school={Karlsruher Institut für Technologie},
  title={Decomposition of Multichannel Electromyographic Signals for a Silent Speech Interface},
  year={2013},
  supervisor={Janke, Matthias and Wand, Michael and Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/BA_Till_Heistermann.pdf},
  author={Heistermann, Till}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/1853_2815.php}
@bachelorsthesis{ernst2012bootstrapping,
  school={Karlsruher Institut für Technologie},
  title={Bootstrapping Pronunciation Dictionaries with Multilingual Phoneme Recognition},
  year={2012},
  supervisor={Schlippe, Tim and Vu, Ngoc Thang and Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/BA-DarioErnst.pdf},
  author={Ernst, Dario}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/1853_2805.php}
@bachelorsthesis{meyer2012kognitive,
  school={Karlsruher Institut für Technologie},
  year={2012},
  title={Kognitive Modellierung komplexer strategischer Entscheidungsprozesse mittels EEG und Reinforcement Learning},
  supervisor={Putze, Felix and Schultz, Tanja},
  author={Meyer, Johannes and Borné, Joscha}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/1853_2804.php}
@bachelorsthesis{bechberger2012modeling,
  school={Karlsruher Institut für Technologie},
  year={2012},
  title={Modeling human memory performance under influence of cognitive workload},
  supervisor={Putze, Felix and Schultz, Tanja},
  author={Bechberger, Lucas}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/1853_2803.php}
@bachelorsthesis{siem2012transfer,
  school={Karlsruher Institut für Technologie},
  year={2012},
  title={Transfer entropy for extracranial EEG analysis with TRENTOOL in a visual cued motor task},
  supervisor={Putze, Felix and Schultz, Tanja},
  author={Siem, Sebastian Mendez}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/1853_2355.php}
@bachelorsthesis{erhardt2012error,
  school={Karlsruher Institut für Technologie},
  year={2012},
  title={Error Blaming based on Decoding Output},
  supervisor={Telaar, Dominic and Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/ba_mark_erhardt.pdf},
  author={Erhardt, Mark}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/1853_2115.php}
@bachelorsthesis{weiner2012integrating,
  school={Karlsruher Institut für Technologie},
  year={2012},
  title={Integrating Language ID into Code-Switch Speech Recognition},
  supervisor={Vu, Ngoc Thang and Telaar, Dominic and Metze, Florian and Schultz, Tanja},
  author={Weiner, Jochen}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/1853_1974.php}
@bachelorsthesis{alexandrov2012f,
  school={Karlsruher Institut für Technologie},
  year={2012},
  title={F0-Erkennung bei elektromyographischer Sprachsynthese mit Elektrodenarrays},
  supervisor={Janke, Matthias and Wand, Michael and Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/BA_Luben_Alexandrov.pdf},
  author={Alexandrov, Luben}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/1853_2806.php}
@bachelorsthesis{colling2011appraisal,
  school={Karlsruher Institut für Technologie},
  year={2011},
  title={Appraisal-basierte Modellierung von Emotionen in der Interaktion mit einem virtuellen Beifahrer},
  supervisor={Putze, Felix and Schultz, Tanja},
  author={Colling, Steven}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/1853_2369.php}
@bachelorsthesis{kirzner2011analyse,
  school={Karlsruher Institut für Technologie},
  year={2011},
  title={Analyse und Klassifikation von EEG und EMG bei lauter und lautloser Sprache},
  supervisor={Heger, Dominic and Wand, Michael and Schultz, Tanja},
  author={Kirzner, Evgheni}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/1853_2044.php}
@bachelorsthesis{stahlberg2011discovering,
  school={Karlsruher Institut für Technologie},
  title={Discovering Vocabulary of a Language through Cross-Lingual Alignment},
  year={2011},
  supervisor={Schlippe, Tim and Vogel, Stephan and Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/BA_FelixStahlberg_Ausarbeitung.pdf},
  author={Stahlberg, Felix}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/1853_1643.php}
@bachelorsthesis{schulte2011aufbau,
  school={Karlsruher Institut für Technologie},
  title={Aufbau eines EMG-basierten Spracherkennungssystems unter Verwendung von Elektrodenarrays},
  year={2011},
  supervisor={Wand, Michael and Janke, Matthias and Schultz, Tanja},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/BA-Schulte.pdf},
  author={Schulte, Christopher}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/1853_1954.php}
@bachelorsthesis{werfel2011integration,
  school={Karlsruher Institut für Technologie},
  title={Integration von Objektwissen in die automatische Erkennung menschlicher Bewegungen},
  year={2011},
  supervisor={Schultz, Tanja and Gehrig, Dirk},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/BachelorarbeitWerfel.pdf},
  author={Werfel, Sergej}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/1853_2061.php}
@bachelorsthesis{jabbar2010erfassung,
  school={Karlsruher Institut für Technologie},
  year={2010},
  title={Erfassung und Analyse von Bewegungssequenzen mittels Inertialsensorik},
  supervisor={Schultz, Tanja},
  author={Jabbar, Jalil Amir}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/theses_2759.php}
@phdthesis{wand2014advancing,
  school={Karlsruher Institut für Technologie},
  title={Advancing Electromyographic Continuous Speech Recognition: Signal Preprocessing and Modeling},
  year={2014},
  supervisor={Schultz, Tanja and Green, Philip},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Diss_Wand_Michael.pdf},
  author={Wand, Michael}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/theses_1994.php}
@phdthesis{hsiao2012generalized,
  school={Carnegie Mellon University},
  title={Generalized Discriminative Training for Speech Recognition},
  year={2012},
  supervisor={Schultz, Tanja and Black, Alan and Metze, Florian and Saon, George},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/PhD-Hsiao.pdf},
  author={Hsiao, Roger}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/theses_1989.php}
@phdthesis{prahallad2010automatic,
  school={Carnegie Mellon University},
  title={Automatic Building of Synthetic Voices from Audio Books},
  year={2010},
  supervisor={Black, Alan W and Ravishankar, Mosur and Schultz, Tanja and Tokuda, Keiichi},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/PhD-Prahallad.pdf},
  author={Prahallad, Kishore}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/theses_1999.php}
@phdthesis{tam2009rapid,
  school={Carnegie Mellon University},
  year={2009},
  title={Rapid Unsupervised Topic Adaptation - a Latent Semantic Approach},
  supervisor={Schultz, Tanja and Waibel, Alex and Vogel, Stephan and Khudanpur, Sanjeev P.},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/PhD-Tam.pdf},
  author={Tam, Yik-Cheung}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/theses_1261.php}
@phdthesis{jou2008automatic,
  school={Carnegie Mellon University},
  title={Automatic Speech Recognition on Vibrocervigraphic and Electromyographic Signals},
  year={2008},
  supervisor={Schultz, Tanja and Waibel, Alex},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/PhD-Jou.pdf},
  author={Jou, Szu-Chen (Stan)}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/theses_1262.php}
@phdthesis{laskowski2006vocal,
  school={Carnegie Mellon University},
  year={2006},
  title={Vocal Interaction in Multiparty Conversation},
  author={Laskowski, Kornel}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/theses_1263.php}
@phdthesis{tomokiyo2001recognizing,
  school={Carnegie Mellon University},
  year={2001},
  title={Recognizing non-native speech: Characterizing and adapting to non-native usage in speech recognition},
  author={Tomokiyo-Mayfield, Laura},
  supervisor={Waibel, Alex and Bernstein, Jared and Eskenazi, Maxine and Schulz, Tanja and Ward, Wayne}
}

@comment{Old page: http://csl.anthropomatik.kit.edu/theses_1264.php}
@phdthesis{schultz2000multilinguale,
  school={Universit\"at Karlsruhe},
  title={Multilinguale Spracherkennung - Kombination akustischer Modelle zur Portierung auf neue Sprachen},
  year={2000},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/schultz_Diss.pdf},
  author={Schultz, Tanja}
}

@inproceedings{weiner2016towards,
  title={{Towards Automatic Transcription of ILSE -- an Interdisciplinary Longitudinal Study of Adult Development and Aging}},
  author={Jochen Weiner and Claudia Frankenberg and Dominic Telaar and Britta Wendelstein and Johannes Schr\"oder and Tanja Schultz},
  booktitle={Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC'16)},
  year={2016},
  abstract={The Interdisciplinary Longitudinal Study on Adult Development and Aging (ILSE) was created to facilitate the study of challenges posed by rapidly aging societies in developed countries such as Germany. ILSE contains over 8,000 hours of biographic interviews recorded from more than 1,000 participants over the course of 20 years. Investigations on various aspects of aging, such as cognitive decline, often rely on the analysis of linguistic features which can be derived from spoken content like these interviews. However, transcribing speech is a time and cost consuming manual process and so far only 380 hours of ILSE interviews have been transcribed. Thus, it is the aim of our work to establish technical systems to fully automatically transcribe the ILSE interview data. The joint occurrence of poor recording quality, long audio segments, erroneous transcriptions, varying speaking styles & crosstalk, and emotional & dialectal speech in these interviews presents challenges for automatic speech recognition (ASR). We describe our ongoing work towards the fully automatic transcription of all ILSE interviews and the steps we implemented in preparing the transcriptions to meet the interviews' challenges. Using a recursive long audio alignment procedure 96 hours of the transcribed data have been made accessible for ASR training.},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/LREC2016_WeinerEtAl.pdf},
  poster={http://www.csl.uni-bremen.de/cms/images/documents/publications/LREC2016_WeinerEtAl_poster.pdf}
}

@inproceedings{weiner2016speechbased,
  title={{Speech-Based Detection of Alzheimer's Disease in Conversational German}},
  author={Jochen Weiner and Christian Herff and Tanja Schultz},
  booktitle={{INTERSPEECH} 2016 -- 17th Annual Conference of the International Speech Communication Association},
  year={2016},
  abstract={The worldwide population is aging. With a larger population of elderly people, the numbers of people affected by cognitive impairment such as Alzheimer’s disease are growing. Unfortunately, there is no known cure for Alzheimer’s disease. The only way to alleviate it’s serious effects is to start therapy very early before the disease has wrought too much irreversible damage. Current diagnostic procedures are neither cost nor time efficient and therefore do not meet the demands for frequent mass screening required to mitigate the consequences of cognitive impairments on the global scale.
We present an experiment to detect Alzheimer’s disease using spontaneous conversational speech. The speech data was recorded during biographic interviews in the Interdisciplinary Longitudinal Study on Adult Development and Aging (ILSE), a large data resource on healthy and satisfying aging in middle adulthood and later life in Germany. From these recordings we extract ten speech-based features using voice activity detection and transcriptions. In an experimental setup with 98 data samples we train a linear discriminant analysis classifier to distinguish subjects with Alzheimer’s disease from the control group. This setup results in an F-score of 0.8 for the detection of Alzheimer’s disease, clearly showing our approach detects dementia well.},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Interspeech2016_WeinerEtAl.pdf},
  poster={http://www.csl.uni-bremen.de/cms/images/documents/publications/Interspeech2016_WeinerEtAl_poster.pdf},
  doi={10.21437/Interspeech.2016-100}
}

@inproceedings{weiner2016detection,
  title={{Detection of Intra-Personal Development of Cognitive Impairment From Conversational Speech}},
  author={Jochen Weiner and Tanja Schultz},
  booktitle={12th ITG Conference on Speech Communication},
  year={2016},
  abstract={As the population in developed countries is aging, cognitive impairment such as Alzheimer’s disease becomes an urging challenge for these societies. In order to mitigate the consequences, diagnosing cognitive impairment early is crucial. We present automatic detection of an intra-personal development of cognitive impairment from speech. Using conversational speech data from the ILSE corpus we detect subjects which were considered cognitively healthy at one examination and were diagnosed with a cognitive impairment at a later examination.
  From the speech recordings we extract 14 speech-based features using voice activity detection and transcriptions. With these features we train a linear discriminant analysis classifier that distinguishes subjects who developed a cognitive impairment from subjects who did not. The classifier achieves an accuracy of 80.4\%, classifying half the cognitively impaired subjects correctly and assigning that label to hardly any cognitively health subjects. This shows our approach is well suited for longitudinal cognitive status monitoring.},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/ITGSpeech2016_WeinerEtAl.pdf}
}

@phdthesis{schlippe2014rapid,
  school={Karlsruher Institut für Technologie},
  title={{Rapid Generation of Pronunciation Dictionaries for New Domains and Languages}},
  year={2014},
  supervisor={Schultz, Tanja and Davel, Marelie},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/PhD-Schlippe.pdf},
  author={Schlippe, Tim}
}

@phdthesis{vu2014automatic,
  school={Karlsruher Institut für Technologie},
  title={{Automatic Speech Recognition for Low-resource Languages and Accents Using Multilingual and Crosslingual Information}},
  year={2014},
  supervisor={Schultz, Tanja and Barnard, Etienne},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/PhD-Vu.pdf},
  author={Vu, Thang}
}


@phdthesis{telaar2015error,
  school={Karlsruher Institut für Technologie},
  title={{Error Correction based on Error Signatures applied to automatic speech recognition}},
  year={2015},
  supervisor={Schultz, Tanja and Tichy, Walter F.},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/PhD-Telaar.pdf},
  author={Telaar, Dominic}
}

@phdthesis{putze2014adaptive,
  school={Karlsruher Institut für Technologie},
  title={{Adaptive Cognitive Interaction Systems}},
  year={2014},
  supervisor={Schultz, Tanja and Funke, Joachim},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/PhD-Putze.pdf},
  author={Putze, Felix}
}

@phdthesis{heger2015advancing,
  school={Karlsruher Institut für Technologie},
  title={{Advancing Pattern Recognition Techniques for Brain-Computer Interfaces: Optimizing Discriminability, Compactness, and Robustness}},
  year={2015},
  supervisor={Schultz, Tanja and Stiefelhagen, Reiner},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/PhD-Heger.pdf},
  author={Heger, Dominic}
}

@phdthesis{amma2015modellierung,
  school={Karlsruher Institut für Technologie},
  title={{Modellierung und Erkennung dreidimensionaler Handschrift mittels Inertialsensorik}},
  year={2015},
  supervisor={Schultz, Tanja and Asfour, Tamim},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/PhD-Amma.pdf},
  author={Amma, Christoph}
}

@phdthesis{gehrig2015automatic,
  school={Karlsruher Institut für Technologie},
  title={{Automatic Recognition of Concurrent and Coupled Human Motion Sequences}},
  year={2015},
  supervisor={Schultz, Tanja and Dillmann, Rüdiger},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/PhD-Gehrig.pdf},
  author={Gehrig, Dirk}
}

@inproceedings{telaar2016error,
  title={{Error Signatures to identify Errors in ASR in an unsupervised fashion}},
  author={Dominic Telaar and Jochen Weiner and Tanja Schultz},
  year={2015},
  booktitle={Proceedings of the Errare Workshop (ERRARE 2015)},
  abstract={Large scale ASR systems are trained on thousands of hours of speech. Usually, many of these training data were automatically transcribed by another ASR system due to a lack of manual transcriptions and a lack of resources to transcribe them. Systems trained in such a fashion are biased towards the transcription system. In the past, confidence models have been investigated to exclude data from training. We propose to investigate areas of low confidence by extending our previous work. For this purpose we aggregate potential errors of ASR systems by ascribing a list of attributes to each potential error and find a set of attributes which best describe the errors encountered on an automatically transcribed set. We call these characteristic sets of attributes Error Signatures. Examples of attributes are word identity, phonemes, acoustic models, word context, speaker id, and language id. For each Error Signatures, an error ratio is computed, giving the probability that the signature properly describes the error. Error ratios and occurrence frequencies are used to sort the signatures and present them to an expert to fix the Error Signatures underlying shortcomings of the ASR system.},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/TelaarEtAl_Errare2015.pdf}
}

@mastersthesis{palyafari2015,
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/palyafari2015.pdf},
  school={Karlsruher Institut für Technologie},
  title={{Continuous Activity Recognition for an Intelligent Knee Orthosis; An Out-of-Lab Study}},
  year={2015},
  supervisor={Amma, Christoph and Georgi, Marcus and Schultz, Tanja},
  author={Palyaf\'{a}ri, Ren\'{a}ta},
}

@bachelorsthesis{dittrich2015speaker,
  school={Karlsruher Institut für Technologie},
  title={{Speaker Diarization for ILSE-Interviews}},
  year={2015},
  supervisor={Weiner, Jochen and Schultz, Tanja},
  author={Dittrich, Florian},
}

@studentresearchproject{strentzsch2015deanonymization,
  school={Karlsruher Institut für Technologie},
  title={{Deanonymization of anonymized transcripts}},
  year={2015},
  supervisor={Weiner, Jochen and Schultz, Tanja},
  author={Strentzsch, Gunnar},
}

@bachelorsthesis{grimm2015modellierung,
  school={Karlsruher Institut für Technologie},
  title={{Modellierung von Satzenden für automatische Spracherkennung}},
  year={2015},
  supervisor={Weiner, Jochen and Schultz, Tanja},
  author={Grimm, Daniela},
}

@mastersthesis{costa2015noise,
  school={Karlsruher Institut für Technologie / Universitat Polit\`{e}cnica de Catalunya},
  title={{Noise Reduction for ILSE Interviews}},
  year={2015},
  supervisor={Weiner, Jochen and Schultz, Tanja and Moreno Bilbao, Asunci\'{o}n},
  author={Pastrana Costa, Asunci\'{o}n},
}


@inproceedings{putze_starring_2016,
	address = {Gothenborg, Sweden},
	title = {Starring into the void? {Classifying} {Internal} vs. {External} {Attention} from {EEG}},
	booktitle = {Proceedings of  9th {Nordic} {Conference} on {Human}-{Computer} {Interaction} ({NordiCHI})},
	author = {Putze, Felix and Scherer, Maximilian and Schultz, Tanja},
	year = {2016}
}

@inproceedings{putze_model-driven_2016,
	address = {Bremen, Germany},
	title = {Model-driven interaction strategies of	a dialog system	for navigation and information},
	booktitle = {Proceedings of 13th {Biannual} {Conference} of the {German} {Cognitive} {Science} {Society}},
	author = {Putze, Felix and Bordolo, Elias and Schultz, Tanja},
	year = {2016}
}

@inproceedings{schultz_i-care:_2016,
	address = {Bremen, Germany},
	title = {I-{CARE}:	{Individual} activation	of people with dementia},
	booktitle = {Proceedings of 13th {Biannual} {Conference} of the {German} {Cognitive} {Science} {Society}},
	author = {Schultz, Tanja and Putze, Felix and Schulze, Timo and Mikut, Ralf and Doneit, Wolfgang and Kruse, Andreas and Depner, Anamaria and Franz, Ingo and Engels, Marc Aurel and Gaerte, Philipp and Bothe, Dietmar and Ziegler, Christof and Maucher, Irene and Ricken, Michael and Dimitrov, Todor and Herzig, Joachim and Bernardin, Keni and Gehrig, Tobias and Lohse, Jana and Adam, Marion and Fischer, Monika and Volpe, Massimo and Simon, Clarissa},
	year = {2016},
	url={https://www.csl.uni-bremen.de/cms/images/documents/publications/icarekogwis16schultz.pdf}
}

@article{ehret_technikbasiertes_2016,
	title = {Technikbasiertes {Spiel} von {Tagespflegebesuchern} mit und ohne {Demenz}},
	issn = {0948-6704, 1435-1269},
	language = {de},
	urldate = {2016-09-29},
	journal = {Zeitschrift für Gerontologie und Geriatrie},
	author = {Ehret, S. and Putze, F. and Miller-Teynor, H. and Kruse, A. and Schultz, T.},
	month = jul,
	year = {2016},
	pages = {1--10},
}

@inproceedings{putze_intervention-free_2016,
	address = {Tokyo, Japan},
	title = {Intervention-{Free} {Selection} using {EEG} and {Eye} {Tracking}},
	booktitle = {Proceedings of 18th {ACM} {International} {Conference} on {Multimodal} {Interaction}},
	author = {Putze, Felix and Hild, Jutta and Popp, Johannes and Beyerer, Jürgen and Schultz, Tanja},
	year = {2016}
}

@incollection{stiefelhagen_aktiv_2016,
	address = {Stuttgart, Germany},
	title = {{AKTIV} mit {Demenz} - technischen {Aktivierungssystemen} sei {Dank}},
	booktitle = {100! {Was} die {Wissenschaft} vom {Altern} weiß},
	publisher = {Hirzel, S., Verlag},
	author = {Stiefelhagen, Rainer and Schultz, Tanja and Putze, Felix and Kruse, Andreas and Metz, Brigitte},
	year = {2016},
	pages = {127--136}
}


@inproceedings{weiner2017manual,
  title={{Manual and Automatic Transcription in Dementia Detection from Speech}},
  author={Jochen Weiner and Mathis Engelbart and Tanja Schultz},
  booktitle={{INTERSPEECH} 2017 -- 18\textsuperscript{th} Annual Conference of the International Speech Communication Association},
  year={2017},
  abstract={As the population in developed countries is aging, larger numbers of people are at risk of developing dementia. In the near future there will be a need for time- and cost-efficient screening methods. Speech can be recorded and analyzed in this manner, and as speech and language are affected early on in the course of dementia, automatic speech processing can provide valuable support for such screening methods.
We present two pipelines of feature extraction for dementia detection: the manual pipeline uses manual transcriptions while the fully automatic pipeline uses transcriptions created by automatic speech recognition (ASR). The acoustic and linguistic features that we extract need no language specific tools other than the ASR system. Using these two different feature extraction pipelines we automatically detect dementia. Our results show that the ASR system’s transcription quality is a good single feature and that the features extracted from automatic transcriptions perform similar or slightly better than the features extracted from the manual transcriptions.},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Interspeech2017_WeinerEtAl.pdf},
  poster={http://www.csl.uni-bremen.de/cms/images/documents/publications/Interspeech2017_WeinerEtAl_poster.pdf},
}

@InProceedings{Weiner2017,
	author="Weiner, Jochen and Diener, Lorenz and Stelter, Simon and Externest, Eike and K{\"u}hl, Sebastian and Herff, Christian and Putze, Felix and Schulze, Timo and Salous, Mazen and Liu, Hui and K{\"u}ster, Dennis and Schultz, Tanja",
	editor="Kern-Isberner, Gabriele
		and F{\"u}rnkranz, Johannes
		and Thimm, Matthias",
	title="Bremen Big Data Challenge 2017: Predicting University Cafeteria Load",
	booktitle="KI 2017: Advances in Artificial Intelligence: 40th Annual German Conference on AI, Dortmund, Germany, September 25--29, 2017, Proceedings",
	year="2017",
	publisher="Springer International Publishing",
	address="Cham",
	pages="380--386",
	abstract="Big data is a hot topic in research and industry. The availability of data has never been as high as it is now. Making good use of the data is a challenging research topic in all aspects of industry and society. The Bremen Big Data Challenge invites students to dig deep into big data. In this yearly event students are challenged to use the month of March to analyze a big dataset and use the knowledge they gained to answer a question. In this year's Bremen Big Data Challenge students were challenged to predict the load of the university cafeteria from the load of past years. The best of 24 teams predicted the load with a root mean squared error of 8.6 receipts issued in five minutes, with a fusion system based on the top 5 entries achieving an even better result of 8.28.",
	isbn="978-3-319-67190-1",
	doi="10.1007/978-3-319-67190-1_35",
	url={https://www.csl.uni-bremen.de/cms/images/documents/publications/KI2017_DienerEtAl.pdf},
}

@article{janke2017emg,
  title={EMG-to-Speech: Direct Generation of Speech From Facial Electromyographic Signals},
  volume={25},
  number={12},
  pages={2375--2385},
  year={2017},
  month={nov},
  day={23},
  doi={10.1109/TASLP.2017.2738568},
  journal={IEEE/ACM Transactions on Audio, Speech and Language Processing},
  author={Janke, Matthias and Diener, Lorenz},
  abstract={Silent speech interfaces are systems that enable speech communication even when an acoustic signal is unavailable. Over the last years, public interest in such interfaces has intensified. They provide solutions for some of the challenges faced by today's speech-driven technologies, such as robustness to noise and usability for people with speech impediments. In this paper, we provide an overview over our silent speech interface. It is based on facial surface electromyography (EMG), which we use to record the electrical signals that control muscle contraction during speech production. These signals are then converted directly to an audible speech waveform, retaining important paralinguistic speech cues for information such as speaker identity and mood. This paper gives an overview over our state-of-the-art direct EMG-to-speech transformation system. This paper describes the characteristics of the speech EMG signal, introduces techniques for extracting relevant features, presents different EMG-to-speech mapping methods, and finally, presents an evaluation of the different methods for real-time capability and conversion quality.},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/TASLP-2017-direct-generation.pdf},  
}

@article{schultz2017biosignal,
  title={Biosignal-based Spoken Communication: A Survey},
  volume={25},
  number={12},
  pages={2257--2271},
  year={2017},
  month={nov},
  day={23},
  doi={10.1109/TASLP.2017.2752365},
  journal={IEEE/ACM Transactions on Audio, Speech and Language Processing},
  author={Schultz, Tanja and Wand, Michael and Hueber, Thomas and Krusienski Dean J. and Herff, Christian and Brumberg, Jonathan S.},
  abstract={Speech is a complex process involving a wide range of biosignals, including but not limited to acoustics. These biosignals—stemming from the articulators, the articulator muscle activities, the neural pathways, and the brain itself — can be used to circumvent limitations of conventional speech processing in particular, and to gain insights into the process of speech production in general. Research on biosignal-based speech processing is a wide and very active field at the intersection of various disciplines, ranging from engineering, computer science, electronics and machine learning to medicine, neuroscience, physiology, and psychology. Consequently, a variety of methods and approaches have been used to investigate the common goal of creating biosignal-based speech processing devices for communication applications in everyday situations and for speech rehabilitation, as well as gaining a deeper understanding of spoken communication. This paper gives an overview of the various modalities, research approaches, and objectives for biosignal-based spoken communication.},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/TASLP-2017-biosignal-based-spoken.pdf},
}

@inproceedings{putze_salous_2018iui,
  author={Putze, Felix and Salous, Mazen and Schultz, Tanja},
  title={Detecting Memory-Based Interaction Obstacles with a Recurrent Neural Model of User Behavior},
  booktitle={Proceedings of the 2018 International Conference on Intelligent User Interfaces},
  series = {IUI '18},
  year = {2018},
  isbn = {978-1-4503-4945-1/18/03},
  location = {National Center of Sciences Building, Tokyo, Japan},
  pages = {205--209},
  numpages = {5},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/putze_salous_2018iui.pdf},
  doi = {10.1145/3172944.3173006},
  publisher = {ACM},
  address = {Tokyo, Japan},
  keywords = {Classification of user behavior, memory, interaction obstacles, LSTMs},
  abstract={A memory-based interaction obstacle is a condition which impedes human memory during Human-Computer Interaction, for example a memory-loading secondary task. In this paper, we present an approach to detect the presence of such memory-based interaction obstacles from logged user behavior during system use. For this purpose, we use a recurrent neural network which models the resulting temporal sequences. To acquire a sufficient number of training episodes, we employ a cognitive user simulation. We evaluate the approach with data from a user test and on which we outperform a non-sequential baseline by up to 42% relative.}
}

@diplomathesis{janke2016emg,
  school={Karlsruher Institut für Technologie},
  title={EMG-to-Speech: Direct Generation of Speech from Facial Electromyographic Signals},
  year={2016},
  supervisor={Schultz, Tanja},
  author={Janke, Matthias},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/janke_thesis.pdf},
}

@inproceedings{salous_putze_2018esann,
  author={Salous, Mazen and Putze, Felix},
  title={Behaviour-Based Working Memory Capacity Classification Using Recurrent Neural Networks},
  booktitle={{ESANN} 2018 -- 26th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning},
  isbn = {978-2-87587-047-6},
  pages = {159--164},
  numpages = {6},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/salous_putze_2018esann.pdf},
  address = {Brugge, Belgium},
  year={2018},
  abstract={A user's working memory capacity is a crucial factor for successful Human Computer Interaction (HCI). While reliable tests for working memory capacity are available, they are time-consuming, stressful, and not well-integrated into HCI applications. This paper presents a classifier based on Long Short Term Memory networks to exploit sparse temporal dependencies in behavioural data, collected in a complex, memory-intense interaction task, to classify working memory capacity. A cognitive user simulation is introduced to generate additional training data episodes that follow the behaviour of existing real data. We show that the classifier outperforms a linear baseline especially for short segments of data.},
}

@inproceedings{angrick_2018esann,
  author={Angrick, Miguel and Herff, Christian and Johnson, Garett and Shih, Jerry and Krusienski, Dean and Schultz, Tanja},
  title={{Interpretation of Convolutional Neural Networks for Speech Regression from Electrocorticography}},
  booktitle={{ESANN} 2018 -- 26th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning},
  isbn = {978-2-87587-047-6},
  pages = {7--12},
  numpages = {6},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/angrick_2018esann.pdf},
  address = {Brugge, Belgium},
  year={2018},
  abstract={The direct synthesis of continuously spoken speech from neural activity is envisioned to enable fast and intuitive Brain-Computer Interfaces. Earlier results indicate that intracranial recordings reveal very suitable signal characteristics for direct synthesis. To map the complex dynamics of neural activity to spectral representations of speech, Convolutional Neural Networks (CNNs) can be trained. However, the resulting networks are hard to interpret and thus provide little opportunity to gain insights on neural processes underlying speech. Here, we show that CNNs are useful to reconstruct speech from intracranial recordings of brain activity and propose an approach to interpret the trained CNNs.},
}


@inproceedings{weiner2018investigating,
  title={{Investigating the Effect of Audio Duration on Dementia Detection using Acoustic Features}},
  author={Jochen Weiner and Miguel Angrick and Srinivasan Umesh and Tanja Schultz},
  booktitle={{INTERSPEECH} 2018 -- 19th Annual Conference of the International Speech Communication Association},
  year={2018},
  abstract={This paper presents recent progress toward our goal to enable area-wide pre-screening methods for the early detection of dementia based on automatically processing conversational speech of a representative group of more than 200 subjects. We focus on conversational speech since it is the natural form of communication that can be recorded unobtrusively, without adding stress to subjects, and without the need of controlled clinical settings. We describe our unsupervised process chain consisting of voice activity detection and speaker diarization followed by extraction of features and detection of early signs of dementia. The unsupervised system achieves up to 0.645 unweighted average recall (UAR) and compares favorably to a system that was carefully designed on manually annotated data. To further lower the burden for subjects, we investigate UAR over speech duration, and find that about 12 minutes of interview are sufficient to achieve the best UAR.},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Interspeech2018_WeinerEtAl.pdf},
}

@inproceedings{weiner2018selecting,
  title={{Selecting Features for Automatic Screening for Dementia based on Speech}},
  author={Jochen Weiner and Tanja Schultz},
  booktitle={Speech and Computer},
  year={2018},
  publisher="Springer International Publishing",
  pages="747--756",
  doi={10.1007/978-3-319-99579-3_76},
  abstract={As the population in developed countries ages, larger numbers of people are at risk of developing dementia. In the near future large-scale time- and cost-efficient screening methods will be needed. Speech can be recorded and analyzed in this manner, and as speech and language are affected early on in the course of dementia, automatic speech processing can provide valuable support for such screening methods.
  We have developed acoustic and linguistic features for dementia screening and established that a combination of acoustic and linguistic features provides the best results. However, our full set of 429 fine-grained features from 15 feature types is too large to train a robust model on limited training data. We therefore need to select features to use for dementia screening. We employ forward feature selection nested in a cross-validation and identify the most commonly selected features. Both acoustic and linguistic features from seven different feature types are selected. Using sets of these features we obtain a 0.819 unweighted average recall which is a strong improvement over previous results.},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Specom2018_WeinerEtAl.pdf},
}

@inproceedings{weiner2018automatic,
  title={{Automatic Screening for Transition into Dementia using Speech}},
  author={Jochen Weiner and Tanja Schultz},
  booktitle={13th ITG Conference on Speech Communication},
  year={2018},
  abstract={Diagnosing dementia early is crucial in mitigating the consequences of the disease for patients, their care-givers and relatives. We present automatic screening for personal transition into dementia from speech using information from more than one point in time. Using conversational speech data from the ILSE corpus we screen subjects if they transition from a cognitively healthy state to a state of dementia.
  We use both acoustic and linguistic features from two pipelines of feature extraction: the manual pipeline uses manual transcriptions while the fully automatic pipeline uses transcriptions created by automatic speech recognition (ASR). Using these two different feature extraction pipelines we automatically screen for dementia transition, where the fully automatic pipeline performs the whole screening process fully automatically. Our results show the features extracted from automatic transcriptions outperform the features extracted from the manual transcriptions.},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/ITG2018_WeinerEtAl.pdf}
}

@inproceedings{diener2018investigating,
  title={{Investigating Objective Intelligibility in Real-Time EMG-to-Speech Conversion}},
  author={Lorenz Diener and Tanja Schultz},
  booktitle={{INTERSPEECH} 2018 -- 19th Annual Conference of the International Speech Communication Association},
  year={2018},
  abstract={This paper presents an analysis of the influence of various system parameters on the output quality of our neural network based real-time EMG-to-Speech conversion system. This EMG-to-Speech system allows for the direct conversion of facial surface electromyographic signals into audible speech in real time, allowing for a closed-loop setup where users get direct audio feedback. Such a setup opens new avenues for research and applications through co-adaptation approaches. In this paper, we evaluate the influence of several parameters on the output quality, such as time context, EMG-Audio delay, network-, training data- and Mel spectrogram size. The resulting output quality is evaluated based on the objective output quality measure STOI.},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/IS2018_EMG_Realtime.pdf},
}

@inproceedings{diener2018session,
  title={{Session-Independent Array-Based EMG-to-Speech Conversion using Convolutional Neural Networks}},
  author={Lorenz Diener and Gerrit Felsch and Miguel Angrick and Tanja Schultz},
  booktitle={13th ITG Conference on Speech Communication},
  year={2018},
  abstract={This paper presents an evaluation of the performance of EMG-to-Speech conversion based on convolutional neural networks. We present an analysis of two different architectures and network design considerations and evaluate CNN-based systems for their within-session and cross-session performance. We find that they are able to perform on par with feedforward neural networks when trained and evaluated on a single session and outperform them in cross session evaluations.},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/ITG2018_EMG_ConvNets.pdf}
}

@inproceedings{diener2018comparison,
  title={{A comparison of EMG-to-Speech Conversion for Isolated and Continuous Speech}},
  author={Lorenz Diener and Sebastian Bredehöft and Tanja Schultz},
  booktitle={13th ITG Conference on Speech Communication},
  year={2018},
  abstract={This paper presents initial results of performing EMG-to-Speech conversion within our new EMG-to-Speech corpus. This new corpus consists of parallel facial array sEMG and read audible speech signals recorded from multiple speakers. It contains different styles of utterances - continuous sentences, isolated words, and isolated consonant-vowel combinations - which allows us to evaluate the performance of EMG-to-Speech conversion when trying to convert these different styles of utterance as well as the effect of training systems on one style to convert another. We find that our system deals with isolated-word/consonant-vowel utterances better than with continuous speech. We also find that it is possible to use a model trained on one style to convert utterances from another - however, performance suffers compared to training within that style, especially when going from isolated to continuous speech.},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/ITG2018_EMG_NewCorpus.pdf}
}

@inproceedings{liu2018ask,
  title={ASK: A Framework for Data Acquisition and Activity Recognition.},
  author={Liu, Hui and Schultz, Tanja},
  booktitle={Proceedings of the 11th International Joint Conference on Biomedical Engineering Systems and Technologies - Volume 3: BIOSIGNALS,},
  pages={262--268},
  year={2018},
  isbn={978-989-758-279-0},
  doi={10.5220/0006732902620268},
  abstract={This work puts forward a framework for the acquisition and processing of biosignals to indicate strain on the knee inflicted by human everyday activities. Such a framework involves the appropriate equipment in devices and sensors to capture factors that inflict strain on the knee, the long-term recording and archiving of corresponding multi-sensory biosignal data, the semi-automatic annotation and segmentation of these data, and the person-dependent or person-adaptive automatic recognition of strain. In this paper we present first steps toward our goal, i.e. person-dependent recognition of a small set of human everyday activities. The focus here is on the fully automatic end-to-end processing from signal input to recognition output. The framework was applied to collect and process a small pilot dataset from one person for a proof-of-concept validation and achieved 97\% accuracy in recognizing instances of seven daily activities.},
   url={https://www.csl.uni-bremen.de/cms/images/documents/publications/ASK_A_Framework_for_Data_Acquisition_and_Activity_Recognition_Biosignal_2018.pdf}
}

@inproceedings{liu2019har,
  title={A Wearable Real-time Human Activity Recognition System using Biosensors Integrated into a Knee Bandage.},
  author={Liu, Hui and Schultz, Tanja},
  booktitle={Proceedings of the 12th International Joint Conference on Biomedical Engineering Systems and Technologies - Volume 1: BIODEVICES,},
  pages={47--55},
  year={2019},
  isbn={978-989-758-353-7},
  doi={10.5220/0007398800470055},
  abstract={This work introduces an innovative wearable real-time Human Activity Recognition (HAR) system. The system processes and decodes various biosignals that are captured from biosensors integrated into a knee bandage. The presented work includes (1) the selection of an appropriate equipment in terms of devices and sensors to capture human activity-related biosignals in real time, (2) the experimental tuning of system parameters which balances recognition accuracy with real-time performance, (3) the intuitive visualization of biosignals as well as n-best recognition results in the graphical user interfaces, and (4) the on-the-air extensions for rapid prototyping of applications. The presented system recognizes seven daily activities: sit, stand, stand up, sit down, walk, turn left and turn right. The amount of activity classes to be recognized can be easily extended by the "plug-and-play" function. To the best of our knowledge, this is the first work which demonstrates a real-time HAR system using biosensors integrated into a knee bandage.},
   url={https://www.csl.uni-bremen.de/cms/images/documents/publications/A_Wearable_Real-time_Human_Activity_Recognition_System_using_Biosensors_Integrated_into_a_Knee_Bandage.pdf}
}


@inproceedings{salous_putze_2018icmi_mcpmd,
  author={Salous, Mazen and Putze, Felix and Schultz, Tanja and Hild Jutta and Beyerer, J\"{u}rgen},
  title={Investigating Static and Sequential Models for Intervention-Free Selection Using Multimodal Data of EEG and Eye Tracking},
  booktitle={{ICMI} 2018 -- ICMI 2018 Workshop on Modeling Cognitive Processes from Multimodal Data},
  isbn = {978-1-4503-5692-3},
  numpages = {6},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/salous_putze_2018icmi_mcpmd.pdf},
  address = {Boulder, Colorado, USA},
  year={2018},
  abstract={Multimodal data is increasingly used in cognitive prediction models to better analyze and predict different user cognitive processes. Classifiers based on such data, however, have different performance characteristics. We discuss in this paper an intervention-free selection task using multimodal data of EEG and eye tracking in three different models. We show that a sequential model, LSTM, is more sensitive but less precise than a static model SVM. Moreover, we introduce a confidence-based Competition-Fusion model using both SVM and LSTM. The fusion model further improves the recall compared to either SVM or LSTM alone, without decreasing precision compared to LSTM. According to the results, we recommend SVM for interactive applications which require minimal false positives (high precision), and recommend LSTM and highly recommend Competition-Fusion Model for applications which handle intervention-free selection requests in an additional post-processing step, requiring higher recall than precision.},
}


@article{garcia_dynamics_2016,
	title = {The dynamics of emotions in online interaction},
	volume = {3},
	issn = {2054-5703},
	doi = {10.1098/rsos.160059},
	pages = {160059},
	number = {8},
	journal = {Royal Society Open Science},
	author = {Garcia, David and Kappas, Arvid and Küster, Dennis and Schweitzer, Frank},
	urldate = {2018-08-17},
	year = {2016},
	langid = {english},
	abstract = {We study the changes in emotional states induced by reading and participating in online discussions, empirically testing a computational model of online emotional interaction. Using principles of dynamical systems, we quantify changes in valence and arousal through subjective reports, as recorded in three independent studies including 207 participants (110 female). In the context of online discussions, the dynamics of valence and arousal are composed of two forces: an internal relaxation towards baseline values independent of the emotional charge of the discussion, and a driving force of emotional states that depends on the content of the discussion. The dynamics of valence show the existence of positive and negative tendencies, while arousal increases when reading emotional content regardless of its polarity. The tendency of participants to take part in the discussion increases with positive arousal. When participating in an online discussion, the content of participants' expression depends on their valence, and their arousal significantly decreases afterwards as a regulation mechanism. We illustrate how these results allow the design of agent-based models to reproduce and analyze emotions in online communities. Our work empirically validates the microdynamics of a model of online collective emotions, bridging online data analysis with research in the laboratory.},
	url = {https://www.csl.uni-bremen.de/cms/images/documents/publications/Garcia et al. - 2016 - The dynamics of emotions in online interaction.pdf:C\:\\Users\\Dennis Küster\\Zotero\\storage\\L5EQHBNB\\Garcia et al. - 2016 - The dynamics of emotions in online interaction.pdf:application/pdf}
}

@article{swiderska_avatars_2018,
	title = {Avatars in Pain: Visible Harm Enhances Mind Perception in Humans and Robots},
	issn = {0301-0066, 1468-4233},
	doi = {10.1177/0301006618809919},
	shorttitle = {Avatars in Pain},
	abstract = {Previous research has shown that when people read vignettes about the infliction of harm upon an entity appearing to have no more than a liminal mind, their attributions of mind to that entity increased. Currently, we investigated if the presence of a facial wound enhanced the perception of mental capacities (experience and agency) in response to images of robotic and human-like avatars, compared with unharmed avatars. The results revealed that harmed versions of both robotic and human-like avatars were imbued with mind to a higher degree, irrespective of the baseline level of mind attributed to their unharmed counterparts. Perceptions of capacity for pain mediated attributions of experience, while both pain and empathy mediated attributions of abilities linked to agency. The findings suggest that harm, even when it appears to have been inflicted unintentionally, may augment mind perception for robotic as well as for nearly human entities, at least as long as it is perceived to elicit pain.},
	pages = {030100661880991},
	journal = {Perception},
	author = {Swiderska, Aleksandra and Küster, Dennis},
	urldate = {2018-12-03},
	year = {2018},
	langid = {english},
	url = {https://www.csl.uni-bremen.de/cms/images/documents/publications/Swiderska and Küster - 2018 - Avatars in Pain Visible Harm Enhances Mind Percep.pdf}
}

@article{kuster_social_2018,
	title = {Social Effects of Tears and Small Pupils Are Mediated by Felt Sadness: An Evolutionary View},
	volume = {16},
	issn = {1474-7049, 1474-7049},
	doi = {10.1177/1474704918761104},
	shorttitle = {Social Effects of Tears and Small Pupils Are Mediated by Felt Sadness},
	abstract = {Small pupils elicit empathic socioemotional responses comparable to those found for emotional tears. This might be understood in an evolutionary context. Intense emotional tearing increases tear film volume and disturbs tear layer uniformity, resulting in blurry vision. A constriction of the pupils may help to mitigate this handicap, which in turn may have resulted in a perceptual association of both signals. However, direct empirical evidence for a role of pupil size in tearful emotional crying is still lacking. The present study examined socioemotional responses to different pupil sizes, combined with the presence (absence) of digitally added tears superimposed upon expressively neutral faces. Data from 50 subjects showed significant effects of observing digitally added tears in avatars, replicating previous findings for increased perceived sadness elicited by tearful photographs. No significant interactions were found between tears and pupil size. However, small pupils likewise elicited a significantly greater wish to help in observers. Further analysis showed a significant serial mediation of the effects of tears on perceived wish to help via perceived and then felt sadness. For pupil size, only felt sadness emerged as a significant mediator of the wish to help. These findings support the notion that pupil constriction in the context of intense sadness may function to counteract blurry vision. Pupil size, like emotional tears, appears to have acquired value as a social signal in this context.},
	pages = {147470491876110},
	number = {1},
	journal = {Evolutionary Psychology},
	author = {Küster, Dennis},
	urldate = {2019-01-07},
	year = {2018},
	langid = {english},
	url = {https://www.csl.uni-bremen.de/cms/images/documents/publications/Küster - 2018 - Social Effects of Tears and Small Pupils Are Media.pdf}
}

@article{obaid_endowing_2018,
	title = {Endowing a Robotic Tutor with Empathic Qualities: Design and Pilot Evaluation},
	pages = {32},
	author = {Obaid, Mohammad and Aylett, Ruth and Barendregt, Wolmet and Basedow, Christina and Corrigan, Lee J and Hall, Lynne and Jones, Aidan and Kappas, Arvid and Küster, Dennis and Paiva, Ana and Papadopoulos, Fotis and Serholt, Soﬁa and Castellano, Ginevra},
	year = {2018},
	langid = {english},
	abstract = {As increasingly more research efforts are geared towards creating robots that can teach and interact with children in educational contexts, it has been speculated that endowing robots with artificial empathy may facilitate learning. In this paper, we provide a background to the concept of empathy, and how it factors into learning. We then present our approach to equipping a robotic tutor with several empathic qualities, describing the technical architecture and its components, a map-reading learning scenario developed for an interactive multitouch table, as well as the pedagogical and empathic strategies devised for the robot. We also describe the results of a pilot study comparing the robotic tutor with these empathic qualities against a version of the tutor without them. The pilot study was performed with 26 school children aged 10-11 at their school. Results revealed that children in the test condition indeed rated the robot as more empathic than children in the control condition. Moreover, we explored several related measures, such as relational status and learning effect, yet no other significant differences were found. We further discuss these results and provide insights into future directions.},
	url = {https://www.csl.uni-bremen.de/cms/images/documents/publications/Obaid et al. - 2018 - Endowing a Robotic Tutor with Empathic Qualities .pdf}
}

@article{papadopoulos_relative_2016,
	title = {Do relative positions and proxemics affect the engagement in a human-robot collaborative scenario?},
	volume = {17},
	issn = {1572-0373, 1572-0381},
	doi = {10.1075/is.17.3.01pap},
	abstract = {This paper investigates the effects of relative position and proxemics in the engagement process involved in Human-Robot collaboration. We evaluate the differences between two experimental placement conditions (frontal vs. lateral) for an autonomous robot in a collaborative task with a user across two different types of robot behaviours (helpful vs. neutral). The study evaluated placement and behaviour types around a touch table with 85 participants by measuring gaze, smiling behaviour, distance from the task, and finally electrodermal activity. Results suggest an overall user preference and higher engagement rates with the helpful robot in the frontal position. We discuss how behaviours and position of the robot relative to a user may affect user engagement and collaboration, in particular when the robot aims to provide help via socio-emotional bonding.},
	pages = {321--347},
	number = {3},
	journal = {Interaction Studies},
	author = {Papadopoulos, Fotios and Küster, Dennis and Corrigan, Lee J. and Kappas, Arvid and Castellano, Ginevra},
	urldate = {2019-01-07},
	year = {2016},
	langid = {english},
	url = {https://www.csl.uni-bremen.de/cms/images/documents/publications/Papadopoulos et al. - 2016 - Do relative positions and proxemics affect the eng.pdf}
}

@article{kuster_you_2018,
	title = {You are What You Wear: Unless You Moved—Effects of Attire and Posture on Person Perception},
	issn = {0191-5886, 1573-3653},
	doi = {10.1007/s10919-018-0286-3},
	shorttitle = {You are What You Wear},
	abstract = {While first impressions are often based on appearance cues, little is known about how these interact with information from other channels. The present research aimed to investigate the impact of occupational stereotypes, evoked by attire, as well as posture on person per‑ception. For this, computer animation was used to create avatars with different types of attire (nurse, military, casual) and posture (open, closed). In Study 1 (N = 164), participants attributed significantly more empathy to avatars wearing a nurse versus a military uniform or casual outfit. When adding posture as an additional cue, Study 2 (N = 312) showed that ratings of empathy and dominance were affected by both attire and posture. This effect was replicated in Study 3 (N = 163) for female avatars, in the sense that open postures in nurses increased empathy ratings and decreased dominance ratings, which both in turn led to greater perceived competence. By contrast, for male avatars, posture did not affect attri‑butions of competence directly. Rather, attire predicted perceived dominance directly, as well as through perceived empathy. The present findings suggest that both posture, and occupational information evoked by attire, are used to infer personal characteristics. How‑ever, the strength of each cue may vary with the gender of the target.},
	journal = {Journal of Nonverbal Behavior},
	author = {Küster, Dennis and Krumhuber, Eva G. and Hess, Ursula},
	urldate = {2019-01-07},
	year = {2018},
	langid = {english},
	url = {https://www.csl.uni-bremen.de/cms/images/documents/publications/Küster et al. - 2018 - You are What You Wear Unless You Moved—Effects of.pdf}
}

@article{krumhuber_review_2017,
	title = {A {Review} of {Dynamic} {Datasets} for {Facial} {Expression} {Research}},
	volume = {9},
	issn = {1754-0739, 1754-0747},
	url = {http://journals.sagepub.com/doi/10.1177/1754073916670022},
	doi = {10.1177/1754073916670022},
	abstract = {Temporal dynamics have been increasingly recognized as an important component of facial expressions. With the need for appropriate stimuli in research and application, a range of databases of dynamic facial stimuli has been developed. The present article reviews the existing corpora and describes the key dimensions and properties of the available sets. This includes a discussion of conceptual features in terms of thematic issues in dataset construction as well as practical features which are of applied interest to stimulus usage. To identify the most influential sets, we further examine their citation rates and usage frequencies in existing studies. General limitations and implications for emotion research are noted and future directions for stimulus generation are outlined.},
	language = {en},
	number = {3},
	urldate = {2019-01-08},
	journal = {Emotion Review},
	author = {Krumhuber, Eva G. and Skora, Lina and Küster, Dennis and Fou, Linyun},
	month = jul,
	year = {2017},
	pages = {280--292},
}

@article{choloniewski_temporal_2016,
	title = {Temporal {Taylor}’s scaling of facial electromyography and electrodermal activity in the course of emotional stimulation},
	volume = {90},
	issn = {09600779},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0960077916301564},
	doi = {10.1016/j.chaos.2016.04.023},
	abstract = {High frequency psychophysiological data create a challenge for quantitative modeling based on Big Data tools since they reﬂect the complexity of processes taking place in human body and its responses to external events. Here we present studies of ﬂuctuations in facial electromyography (fEMG) and electrodermal activity (EDA) massive time series and changes of such signals in the course of emotional stimulation. Zygomaticus major (ZYG; “smiling” muscle) activity, corrugator supercilii (COR; “frowning” muscle) activity, and phasic skin conductance (PHSC; sweating) levels of 65 participants were recorded during experiments that involved exposure to emotional stimuli (i.e., IAPS images, reading and writing messages on an artiﬁcial online discussion board). Temporal Taylor’s ﬂuctuations scaling were found when signals for various participants and during various types of emotional events were compared. Values of scaling exponents were close to one, suggesting an external origin of system dynamics and/or strong interactions between system’s basic elements (e.g., muscle ﬁbres). Our statistical analysis shows that the scaling exponents enable identiﬁcation of high valence and arousal levels in ZYG and COR signals.},
	language = {en},
	urldate = {2019-01-08},
	journal = {Chaos, Solitons \& Fractals},
	author = {Chołoniewski, Jan and Chmiel, Anna and Sienkiewicz, Julian and Hołyst, Janusz A. and Küster, Dennis and Kappas, Arvid},
	month = sep,
	year = {2016},
	pages = {91--100},
}

@article{skowron_applying_2014,
	title = {Applying a {Text}-{Based} {Affective} {Dialogue} {System} in {Psychological} {Research}: {Case} {Studies} on the {Effects} of {System} {Behaviour}, {Interaction} {Context} and {Social} {Exclusion}},
	volume = {6},
	issn = {1866-9956, 1866-9964},
	shorttitle = {Applying a {Text}-{Based} {Affective} {Dialogue} {System} in {Psychological} {Research}},
	url = {http://link.springer.com/10.1007/s12559-014-9271-2},
	doi = {10.1007/s12559-014-9271-2},
	language = {en},
	number = {4},
	urldate = {2019-01-08},
	journal = {Cognitive Computation},
	author = {Skowron, Marcin and Rank, Stefan and Świderska, Aleksandra and Küster, Dennis and Kappas, Arvid},
	month = dec,
	year = {2014},
	pages = {872--891},
}

@article{sofia_students_2016,
	title = {Students' {Normative} {Perspectives} on {Classroom} {Robots}},
	copyright = {©2016 \&copy; The authors and IOS Press. All rights reserved.},
	issn = {0922-6389},
	url = {http://www.medra.org/servlet/aliasResolver?alias=iospressISBN&isbn=978-1-61499-707-8&spage=240&doi=10.3233/978-1-61499-708-5-240},
	doi = {10.3233/978-1-61499-708-5-240},
	abstract = {As robots are becoming increasingly common in society and education, it is expected that autonomous and socially adaptive classroom robots may eventually be given responsible roles in primary education. In this paper, we present the results of a questionnaire study carried out with students enrolled in compulsory education in three European countries. The study aimed to explore students’ normative perspectives on classroom robots pertaining to roles and responsibilities, student-robot relationships, and perceptive and emotional capabilities in robots. The results suggest that, although students are generally positive toward the existence of classroom robots, certain aspects are deemed more acceptable than others.},
	language = {en},
	urldate = {2019-01-08},
	journal = {Frontiers in Artificial Intelligence and Applications},
	author = {Sofia, Serholt and Wolmet, Barendregt and Dennis, K\&uuml;ster and Aidan, Jones and Patr\&iacute;cia, Alves-Oliveira and Ana, Paiva},
	year = {2016},
	pages = {240--251},
}

@incollection{kuster_measuring_2017,
	address = {Cham},
	title = {Measuring {Emotions} {Online}: {Expression} and {Physiology}},
	isbn = {978-3-319-43639-5},
	url = {https://doi.org/10.1007/978-3-319-43639-5_5},
	abstract = {Cyberemotions refer to emotions in networks that are a complex function of emotional states in individuals. Thus, measuring cyberemotions frequently involves attempts to estimate emotional states in individuals. Yet, this is not easy, as emotions in individuals are characterized by limited cohesion of the components of response, such as expression in the face, voice, and body, central and peripheral physiological changes, changes in action readiness, as well as subjective experience. There is no gold standard that would identify any of these components by a single criterion. In consequence, modern experimental emotion research has focused on multi-modal assessment of emotions. Different components are targeted at identifying the valence of responses, or the intensity. We will describe paradigms that are particularly tailored for research in the context of cyberemotions and illustrate these with concrete examples of data recorded in our laboratory.},
	booktitle = {Cyberemotions: {Collective} {Emotions} in {Cyberspace}},
	publisher = {Springer International Publishing},
	author = {Küster, Dennis and Kappas, Arvid},
	editor = {Holyst, Janusz A.},
	year = {2017},
	doi = {10.1007/978-3-319-43639-5_5},
	pages = {71--93}
}

@inproceedings{schultz_i-care:_2018,
	address = {Oldenburg, Germany},
	title = {I-{CARE}: {Ein} {Mensch}-{Technik} {Interaktionssystem} zur {Individuellen} {Aktivierung} von {Menschen} mit {Demenz}},
	booktitle = {Tagungsband der 1. {Clusterkonferenz} {Zukunft} der {Pflege}},
	author = {Schultz, Tanja and Putze, Felix and Schulze, Timo and Steinert, Lars and Mikut, Ralf and Doneit, Wolfgang and Kruse, Andreas and Depner, Anamaria and Franz, Ingo and Engels, Marc Aurel and Gaerte, Philipp and Jünger, Sebastian and Linden, Rene and Ziegler, Christof and Ricken, Michael and Dimitrov, Todor and Herzig, Joachim and Maucher, Irene and Bernardin, Keni and Gehrig, Tobias and Lohse, Jana and Glesing, Kristina and Fischer, Monika and Simon, Clarissa},
	year = {2018}
}

@inproceedings{putze_dozing_2018,
	address = {Boulder, CO, USA},
	title = {Dozing off or {Thinking} {Hard}? {Classifying} {Multi}-dimensional {Attentional} {States} in the {Classroom} from {Video}},
	booktitle = {Proceedings of 20th {ACM} {International} {Conference} on {Multimodal} {Interfaces}},
	publisher = {ACM},
	author = {Putze, Felix and Annerer-Walcher, Sonja and Küster, Dennis and Benedek, Mathias},
	year = {2018}
}

@inproceedings{schulz2019role,
  title={The Role of Physical Props in VR Climbing Environments},
  author={Schulz, Peter and Alexandrovsky, Dmitry and Putze, Felix and Malaka, Rainer and Sch{\"o}ning, Johannes},
  booktitle={Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
  pages={183},
  year={2019},
  organization={ACM}
}

@incollection{putze2019methods,
  title={Methods and Tools for Using BCI with Augmented and Virtual Reality},
  author={Putze, Felix},
  booktitle={Brain Art},
  pages={433--446},
  year={2019},
  publisher={Springer}
}

@article{frankenberg_weiner_2019,
  author={Claudia Frankenberg and Jochen Weiner and Tanja Schultz and Maren Knebel and Christina Degen and Hans-W. Wahl and Johannes Schr\"oder},
  title={Perplexity - a new predictor of cognitive changes in spoken language?: - results of the Interdisciplinary Longitudinal Study on Adult Development and Aging (ILSE)},
  year={2019},
  month={06},
  day={22},
  journal={Linguistics Vanguard},
  volume={5},
  note={s2},
  issn={2199174X},
  doi={10.1515/lingvan-2018-0026},
  url={https://www.degruyter.com/view/j/lingvan.2019.5.issue-s2/lingvan-2018-0026/lingvan-2018-0026.xml},
  abstract={In addition to memory loss, progressive deterioration of speech and language skills is among the main symptoms at the onset of Alzheimer’s disease (AD) as well as in mild cognitive impairment (MCI). Detailed interview analyses demonstrated early symptoms years before the onset of AD/MCI. Automatic speech processing could be a promising approach to identifying underlying mechanisms in larger studies or even support diagnostics. Perplexity as a measure of predictability of text could be a sensitive indicator of cognitive deterioration. Therefore, voice recordings from the Interdisciplinary Longitudinal Study on Adult Development and Aging were analyzed with regard to neuropsychological parameters in participants that develop MCI/AD or remain cognitively healthy. Preliminary results indicate that perplexity predicts severity of cognitive deficits and information processing speed obtained 10–12 years later in participants who developed MCI/AD in contrast to those who stayed healthy. Findings support the heuristic value of research on the diagnostic potential of automatic speech processing.}
}

@inproceedings{meier_iros_2018,
  title = {Synchronized Multimodal Recording of a Table Setting Dataset},
  author = {Meier, Moritz and Mason, Celeste and Porzel, Robert and Putze, Felix and Schultz, Tanja},
  booktitle = {IROS 2018: Workshop on Latest Advances in Big Activity Data Sources for Robotics \& New Challenges},
  year = {2018},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/meier_iros_2018.pdf},
  address={Madrid, Spain},
  abstract={We present here a description of our initial efforts in developing a Biosignal Acquisition Space and Environment (BASE) to collect a large open access dataset of human everyday activities. The final  dataset  is  planned  to consist of synchronously recorded biosignals from 100 participants performing everyday activities  while  describing  their  task  through  use  of  think-aloud protocols. Biosignals encompass six different modalities, with one first person and seven third person cameras, a nine camera motion capture system, one near distance speech microphone and one far distance room microphone, four channel EMG, 16 channel EEG and an eye tracker. The data is collected in the context of the EASE collaborative research center and is intended to benefit the robotics community. This paper provides details regarding the sensors, devices and software used for the data recording as well as insights into the recorded biosignal data streams.}
}

@inproceedings{mason_iros_2018,
  title = {Human Activities Data Collection and Labeling using a Think-aloud Protocol in a Table Setting Scenario},
  author = {Mason, Celeste and Meier, Moritz and Ahrens, Florian and Fehr, Thorsten and Herrmann, Manfred and Putze, Felix and Schultz, Tanja},
  booktitle = {IROS 2018: Workshop on Latest Advances in Big Activity Data Sources for Robotics \& New Challenges},
  year={2018},
  address={Madrid, Spain},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/mason_iros_2018.pdf},
  abstract={We describe our efforts in developing a Biosignals Acquisition Space and Environment (BASE) to acquire a large database of human everyday activities along with a procedure to automatically structure and label these high-dimensional data into a valuable resource for research in cognitive robotics. The final dataset is planned to consist of synchronously recorded biosignals from about 100 participants performing everyday activities while describing their task through use of think-aloud protocols. Biosignals encompass multimodal sensor streams of near and far speech \& audio, video, marker-based motion tracking, eye-tracking, as well as muscle and brain readings of humans performing everyday activities. This paper provides details of our pilot recordings carried out in the well established and scalable "table setting scenario." Besides presenting initial insights, the paper describes concurrent and retrospective think-aloud protocols and compares their usefulness toward automatic data segmentation and structuring.}
}

@inproceedings{meier_interspeech_2019,
   note={Interspeech 2019},
   title={Comparative Analysis of Think-aloud Methods for Everyday Activities in the Context of Cognitive Robotics},
   year={2019},
   month={October},
   booktitle={20th Annual Conference of the International Speech Communication Association},
   address={Graz, Austria},
   author={Meier, Moritz and Mason, Celeste and Putze, Felix and Schultz, Tanja}, 
   url={https://www.csl.uni-bremen.de/cms/images/documents/publications/meier_interspeech_2019.pdf},
   abstract={We describe our efforts to compare data collection methods using two think-aloud protocols in preparation to be used as a basis for automatic structuring and labeling of a large database of high-dimensional human activities data into a valuable resource for research in cognitive robotics. The envisioned dataset, currently in development, will contain synchronously recorded multimodal data, including audio, video, and biosignals (eye-tracking, motion-tracking, muscle and brain activity) from about 100 participants performing everyday activities while describing their task through use of think-aloud protocols. This paper provides details of our pilot recordings in the well-established and scalable ``table setting scenario," describes the concurrent and retrospective think-aloud protocols used, the methods used to analyze them, and compares their potential impact on the data collected as well as the automatic data segmentation and structuring process.}
}

@inproceedings{putze_augmented_2019,
	address = {Bari, Italy},
	title = {Augmented {Reality} {Interface} for {Smart} {Home} {Control} using {SSVEP}-{BCI} and {Eye} {Gaze}},
	booktitle = {{IEEE} {International} {Conference} on {Systems}, {Man}, and {Cybernetics}},
	author = {Putze, Felix and Weiß, Dennis and Vortmann, Lisa-Marie and Schultz, Tanja},
	url={https://www.csl.uni-bremen.de/cms/images/documents/publications/putze_ssvep2019.pdf},
	year = {2019}
}

@inproceedings{salous_putze_smc_2019,
	address = {Bari, Italy},
	title = {Visual and Memory-based HCI Obstacles: Behaviour-based Detection and User Interface Adaptations Analysis},
	booktitle = {{IEEE} {International} {Conference} on {Systems}, {Man}, and {Cybernetics}},
	author = {Salous, Mazen and Putze, Felix and Ihrig, Markus and Schultz, Tanja},
	url={https://www.csl.uni-bremen.de/cms/images/documents/publications/salous_putze_SMC19.pdf},
	year = {2019},
	abstract={Human Computer Interaction (HCI) performance can be impaired by several HCI obstacles. Cognitive adaptive systems should dynamically detect such obstacles and compensate them with suitable User Interface (UI) adaptation. In this paper, we discuss the detection of two main HCI obstacles: memory-based and visual obstacles. A sequential model based on Long-Short Term Memory (LSTM) is suggested for such a detection of HCI obstacles. UI adaptations for both types of obstacles are discussed and analyzed. We investigate the classification performance on data from a user study with 17 participants. Furthermore, we also investigate the influence of different adaptation mechanisms on performance and subjective assessment. Results show advantages of the proposed sequential LSTM model: on the one hand, the LSTM outperforms the baseline random guess and also a baseline static model LDA in the detection of visual obstacles with 70.6\% as an average accuracy. On the other hand, the evaluation of HCI sessions impeded by obstacles but supported with different UI adaptations shows that LSTM results well match the subjective assessment as a plausible detector of behaviour changes.}
}

@article{Tanja_Interspeechkeynote_2019,
	address = {Graz, Austria},
	title = {Biosignal Processing for Human-Machine Interaction. In: Keynote presented at Interspeech 2019, September 2019 Graz, Austria},
    year={2019},
    month={09},
    day={16},
	author = {Schultz, Tanja},
	url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Interspeech2019-KeynoteTanjaSchultz.pdf},
	abstract={Tanja Schultz held a keynote on "Biosignal Processing for Human-Machine Interaction" at Interspeech 2019, the largest conference on the science and technology of spoken language processing, and flagship of ISCA. Talk on Youtube (https://www.youtube.com/watch?v=XzkQnzP7yPA) Slides for download}
}

@article{doi:10.1080/2326263X.2019.1697163,
author = {Jane E. Huggins and Christoph Guger and Erik Aarnoutse and Brendan Allison and Charles W. Anderson and Steven Bedrick and Walter Besio and Ricardo Chavarriaga and Jennifer L. Collinger and An H. Do and Christian Herff and Matthias Hohmann and Michelle Kinsella and Kyuhwa Lee and Fabien Lotte and Gernot Müller-Putz and Anton Nijholt and Elmar Pels and Betts Peters and Felix Putze and Rüdiger Rupp and Gerwin Schalk and Stephanie Scott and Michael Tangermann and Paul Tubig and Thorsten Zander},
title = {Workshops of the seventh international brain-computer interface meeting: not getting lost in translation},
journal = {Brain-Computer Interfaces},
volume = {0},
number = {0},
pages = {1-31},
year  = {2019},
publisher = {Taylor & Francis},
doi = {10.1080/2326263X.2019.1697163},
}

@inproceedings{,
title = {Towards Restoration of Articulatory Movements: Functional Electrical Stimulation of Orofacial Muscles},
year = {2019},
month = {07},
pages = {3111-3114},
doi = {10.1109/EMBC.2019.8857670}
}

@inproceedings{schultz_embc_2019,
author = {Schultz, Tanja and Angrick, Miguel and Diener, Lorenz and Küster, Dennis and Meier, Moritz and Krusienski, Dean and Herff, Christian and Brumberg, Jonathan},
booktitle={2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)},
title={Towards Restoration of Articulatory Movements: Functional Electrical Stimulation of Orofacial Muscles},
year={2019},
volume={},
number={},
pages={3111-3114},
keywords={brain;muscle;neuromuscular stimulation;speech coding;speech synthesis;decoding speech-related brain activity;physical speech production;decoded speech-related brain activity;eventual orofacial stimulation;functional electrical stimulation;synthesized speech generation;physical speech restoration;electrical stimulation;orofacial muscles stimulation;acoustic production;articulatory movement restoration;Muscles;Production;Electromyography;Spectrogram;Correlation;Electrodes;Brain},
doi={10.1109/EMBC.2019.8857670},
ISSN={1557-170X},
month={July},
abstract={Millions of individuals suffer from impairments that significantly disrupt or completely eliminate their ability to speak. An ideal intervention would restore one's natural ability to physically produce speech. Recent progress has been made in decoding speech-related brain activity to generate synthesized speech. Our vision is to extend these recent advances toward the goal of restoring physical speech production using decoded speech-related brain activity to modulate the electrical stimulation of the orofacial musculature involved in speech. In this pilot study we take a step toward this vision by investigating the feasibility of stimulating orofacial muscles during vocalization in order to alter acoustic production. The results of our study provide necessary foundation for eventual orofacial stimulation controlled directly from decoded speech-related brain activity.},
url={https://www.csl.uni-bremen.de/cms/images/documents/publications/schultz_fes_embc2019.pdf},
}

@inproceedings{weiner2019speech,
  title={Speech Reveals Future Risk of Developing Dementia: Predictive Dementia Screening from Biographic Interviews},
  year={2019},
  booktitle={Automatic Speech Recognition and Understanding},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/weiner2019speech.pdf},
  author={Weiner, Jochen and Frankenberg, Claudia and Schr\"oder, Johannes and Schultz, Tanja}
}

@inproceedings{diener2019improving,
  title={Improving Fundamental Frequency Generation in EMG-to-Speeech Conversion using a Quantization Approach},
  year={2019},
  booktitle={Automatic Speech Recognition and Understanding},
  author={Diener, Lorenz and Umesh, Tejas and and Schultz, Tanja},
  abstract={We present a novel approach to generating fundamental frequency (intonation and voicing) trajectories in an EMG-to-Speech conversion Silent Speech Interface, based on quantizing the EMG-to-F0 mappings target values and thus turning a regression problem into a recognition problem. We present this method and evaluate its performance with regard to the accuracy of the voicing information obtained as well as the performance in generating plausible intonation trajectories within voiced sections of the signal. To this end, we also present a new measure for overall F0 trajectory plausibility, the trajectory-label accuracy (TLAcc), and compare it with human evaluations. Our new F0 generation method achieves a significantly better performance than a baseline approach in terms of voicing accuracy, correlation of voiced sections, trajectory-label accuracy and, most importantly, human evaluations.},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/diener_asru_2019_f0_quant.pdf},
}

@inproceedings{putze_platform_2020,
	address = {Honolulu, USA},
	title = {Platform for {Studying} {Self}-{Repairing} {Auto}-{Corrections} in {Mobile} {Text} {Entry} based on {Brain} {Activity}, {Gaze}, and {Context}},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	author = {Putze, Felix and Ihrig, Tilman and Schultz, Tanja and Stuerzlinger, Wolfgang},
	year = {2020},
	address={Honolulu, USA},
	url={https://www.csl.uni-bremen.de/cms/images/documents/publications/autocorrect_2020.pdf},
}

@inproceedings{putze_breaking_2020,
	address = {Honolulu, USA},
	title = {Breaking {The} {Experience}: {Effects} of {Questionnaires} in {VR} {User} {Studies}},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	author = {Putze, Susanne and Alexandrovsky, Dmitry and Putze, Felix and Höffner, Sebastian and Smeddinck, Jan David and Malaka, Rainer},
	year = {2020},
	address={Honolulu, USA},
	url={https://www.csl.uni-bremen.de/cms/images/documents/publications/chi2020_bip_selfreports.pdf},
}

@inproceedings{vortmann_attention-aware_2020,
	address = {Honolulu, USA},
	title = {Attention-{Aware} {Brain} {Computer} {Interface} to avoid {Distractions} in {Augmented} {Reality}},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	author = {Vortmann, Lisa-Marie and Putze, Felix},
	year = {2020},
	address={Honolulu, USA},
	url={https://www.csl.uni-bremen.de/cms/images/documents/publications/vortmann2020attention_aware.pdf},
}

@inproceedings{Vortmann2019,
  abstract = {},
  author = {Vortmann, Lisa-Marie and Schult, Moritz and Benedek, Mathias and Walcher, Sonja and Putze, Felix},
  doi = { https://doi.org/10.1145/3351529.3360658 },
  journal = {Adjunct of the 2019 International Conference on Multimodal Interaction},
  title = {{Real-Time Multimodal Classification of Internal and External Attention}},
  year = {2019},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/vortmann2019LBW_ICMI.pdf}
}

@ARTICLE{Vortmann_frontiers2019,
  AUTHOR={Vortmann, Lisa-Marie and Kroll, Felix and Putze, Felix},    
  TITLE={EEG-Based Classification of Internally- and Externally-Directed Attention in an Augmented Reality Paradigm},      
  JOURNAL={Frontiers in Human Neuroscience},      
  VOLUME={13},     
  PAGES={348},     
  YEAR={2019},      
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/vortmann2019_frontiers.pdf},       
  DOI={10.3389/fnhum.2019.00348},      
  ISSN={1662-5161}, 
  ABSTRACT={One problem faced in the design of Augmented Reality (AR) applications is the interference of virtually displayed objects in the user's visual field, with the current attentional focus of the user. Newly generated content can disrupt internal thought processes. If we can detect such internally-directed attention periods, the interruption could either be avoided or even used intentionally. In this work, we designed a special alignment task in AR with two conditions: one with externally-directed attention and one with internally-directed attention. Apart from the direction of attention, the two tasks were identical. During the experiment, we performed a 16-channel EEG recording, which was then used for a binary classification task. Based on selected band power features, we trained a Linear Discriminant Analysis classifier to predict the label for a 13-s window of each trial. Parameter selection, as well as the training of the classifier, were done in a person-dependent manner in a 5-fold cross-validation on the training data. We achieved an average score of approximately 85.37\% accuracy on the test data (± 11.27\%, range = [66.7\%, 100\%], 6 participants > 90\%, 3 participants = 100\%). Our results show that it is possible to discriminate the two states with simple machine learning mechanisms. The analysis of additionally collected data dispels doubts that we classified the difference in movement speed or task load. We conclude that a real-time assessment of internal and external attention in an AR setting in general will be possible.}  
}

@inproceedings{VortmannDC,
 author = {Vortmann, Lisa-Marie},
 title = {Attention-driven Interaction Systems for Augmented Reality},
 booktitle = {2019 International Conference on Multimodal Interaction},
 series = {ICMI '19},
 year = {2019},
 isbn = {978-1-4503-6860-5},
 location = {Suzhou, China},
 pages = {482--486},
 numpages = {5},
 url={https://www.csl.uni-bremen.de/cms/images/documents/publications/vortmann2019DC_ICMI.pdf},
 doi = {10.1145/3340555.3356088},
 acmid = {3356088},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {adaptive systems, attention, augmented reality, classification, interaction, machine learning, user interface},
} 

@inproceedings{yale2020featurereduction,
  title={Feature Space Reduction for Multimodal Human Activity Recognition},
  author={Hartmann, Yale and Liu, Hui and Schultz, Tanja},
  booktitle={Proceedings of the 13th International Joint Conference on Biomedical Engineering Systems and Technologies - Volume 4: BIOSIGNALS,},
  pages={135--140},
  year={2020},
  isbn={978-989-758-398-8},
  doi={10.5220/0008851401350140},
  abstract={This work describes the implementation, optimization, and evaluation of a Human Activity Recognition (HAR) system using 21-channel biosignals. These biosignals capture multiple modalities, such as motion and muscle activity based on two 3D-inertial sensors, one 2D-goniometer, and four electromyographic sensors. We start with an early fusion, HMM-based recognition system which discriminates 18 human activities at 91% recognition accuracy. We then optimize preprocessing with a feature space reduction and feature vector stacking. For this purpose, a Linear Discriminant Analysis (LDA) was performed based on HMM state alignments. Our experimental results show that LDA feature space reduction improves recognition accuracy by four percentage points while stacking feature vectors currently does not show any positive effects. To the best of our knowledge, this is the first work on feature space reduction in a HAR system using various biosensors integrated into a knee bandage recognizing a dive rse set of activities.},
   url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Feature_Space_Reduction_for_Multimodal_Human_Activity_Recognition.pdf}
} 

@article{hui2020tsfel,
  title={TSFEL: Time Series Feature Extraction Library},
  author={Barandas, Mar{\'\i}lia and Folgado, Duarte and Fernandes, Let{\'\i}cia and Santos, Sara and Abreu, Mariana and Bota, Patr{\'\i}cia and Liu, Hui and Schultz, Tanja and Gamboa, Hugo},
  journal={SoftwareX},
  volume={11},
  pages={100456},
  year={2020},
  publisher={Elsevier},
  doi={10.1016/j.softx.2020.100456},
  abstract={Time series feature extraction is one of the preliminary steps of conventional machine learning pipelines. Quite often, this process ends being a time consuming and complex task as data scientists must consider a combination between a multitude of domain knowledge factors and coding implementation. We present in this paper a Python package entitled Time Series Feature Extraction Library (TSFEL), which computes over 60 different features extracted across temporal, statistical and spectral domains. User customisation is achieved using either an online interface or a conventional Python package for more flexibility and integration into real deployment scenarios. TSFEL is designed to support the process of fast exploratory data analysis and feature extraction on time series with computational cost evaluation.},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/TSFEL_Time_Series_Feature_Extraction_Library.pdf}
}

@inproceedings{abulimiti-schultz-2020-automatic,
    title = "Automatic Speech Recognition for {U}yghur through Multilingual Acoustic Modeling",
    author = "Abulimiti, Ayimunishagu  and
      Schultz, Tanja",
    booktitle = "Proceedings of The 12th Language Resources and Evaluation Conference",
    month = may,
    year = "2020",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    url = "https://www.csl.uni-bremen.de/cms/images/documents/publications/ay_LREC2020.pdf",
    pages = "6444--6449",
    abstract = "Low-resource languages suffer from lower performance of Automatic Speech Recognition (ASR) system due to the lack of data. As a common approach, multilingual training has been applied to achieve more context coverage and has shown better performance over the monolingual training (Heigold et al., 2013). However, the difference between the donor language and the target language may distort the acoustic model trained with multilingual data, especially when much larger amount of data from donor languages is used for training the models of low-resource language. This paper presents our effort towards improving the performance of ASR system for the under-resourced Uyghur language with multilingual acoustic training. For the developing of multilingual speech recognition system for Uyghur, we used Turkish as donor language, which we selected from GlobalPhone corpus as the most similar language to Uyghur. By generating subsets of Uyghur training data, we explored the performance of multilingual speech recognition systems trained with different sizes of Uyghur and Turkish data. The best speech recognition system for Uyghur is achieved by multilingual training using all Uyghur data (10hours) and 17 hours of Turkish data and the WER is 19.17{\%}, which corresponds to 4.95{\%} relative improvement over monolingual training.",
    language = "English",
    ISBN = "979-10-95546-34-4",
}

@inproceedings{abulimiti-schultz-2020-building,
    title = "Building Language Models for Morphological Rich Low-Resource Languages using Data from Related Donor Languages: the Case of {U}yghur",
    author = "Abulimiti, Ayimunishagu  and
      Schultz, Tanja",
    booktitle = "Proceedings of the 1st Joint Workshop on Spoken Language Technologies for Under-resourced languages (SLTU) and Collaboration and Computing for Under-Resourced Languages (CCURL)",
    month = may,
    year = "2020",
    address = "Marseille, France",
    publisher = "European Language Resources association",
    url = "https://www.csl.uni-bremen.de/cms/images/documents/publications/ay_SLTU2020.pdf",
    pages = "271--276",
    abstract = "Huge amounts of data are needed to build reliable statistical language models. Automatic speech processing tasks in low-resource languages typically suffer from lower performances due to weak or unreliable language models. Furthermore, language modeling for agglutinative languages is very challenging, as the morphological richness results in higher Out Of Vocabulary (OOV) rate. In this work, we show our effort to build word-based as well as morpheme-based language models for Uyghur, a language that combines both challenges, i.e. it is a low-resource and agglutinative language. Fortunately, there exists a closely-related rich-resource language, namely Turkish. Here, we present our work on leveraging Turkish text data to improve Uyghur language models. To maximize the overlap between Uyghur and Turkish words, the Turkish data is pre-processed on the word surface level, which results in 7.76{\%} OOV-rate reduction on the Uyghur development set. To investigate various levels of low-resource conditions, different subsets of Uyghur data are generated. Morpheme-based language models trained with bilingual data achieved up to 40.91{\%} relative perplexity reduction over the language models trained only with Uyghur data.",
    language = "English",
    ISBN = "979-10-95546-35-1",
}

@INPROCEEDINGS{9053144,
  author={M. Y. {Tachbelie} and A. {Abulimiti} and S. T. {Abate} and T. {Schultz}},
  booktitle={ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={DNN-Based Speech Recognition for Globalphone Languages}, 
  year={2020},
  volume={},
  number={},
  pages={8269-8273},
  abstract={This paper describes new reference benchmark results based on hybrid Hidden Markov Model and Deep Neural Networks (HMM-DNN) for the GlobalPhone (GP) multilingual text and speech database. GP is a multilingual database of high-quality read speech with corresponding transcriptions and pronunciation dictionaries in more than 20 languages. Moreover, we provide new results for five additional languages, namely, Amharic, Oromo, Tigrigna, Wolaytta, and Uyghur. Across the 22 languages considered, the hybrid HMM-DNN models outperform the HMM-GMM based models regardless of the size of the training speech used. Overall, we achieved relative improvements that range from 7.14% to 59.43%.},
  keywords={GlobalPhone;DNN;Ethiopian Languages},
  doi={10.1109/ICASSP40776.2020.9053144},
  ISSN={2379-190X},
  month={May},
  url = "https://www.csl.uni-bremen.de/cms/images/documents/publications/martha_ICASSP2020.pdf",  
}

@inproceedings{diener2020cslemgarray,
    title={{CSL-EMG\_Array: An Open Access Corpus for EMG-to-Speech Conversion}},
    author={Diener, Lorenz and  Roustay Vishkasougheh, Mehrdad and Schultz, Tanja},
    booktitle={{INTERSPEECH} 2020 - 21st Annual Conference of the International Speech Communication Association},
    year={2020 (to appear)},
    url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Diener_IS2020_CSLEMGArray.pdf},
    abstract={We present a new open access corpus for the training and evaluation of EMG-to-Speech conversion systems based on array electromyographic recordings. The corpus is recorded with a recording paradigm closely mirroring realistic EMG-to-Speech usage scenarios, and includes evaluation data recorded from both audible as well as silent speech. The corpus consists of 9.5 hours of data, split into 12 sessions recorded from 8 speakers. Based on this corpus, we present initial benchmark results with a realistic online EMG-to-Speech conversion use case, both for the audible and silent speech subsets. We also present a method for drastically improving EMG-to-Speech system stability and performance in the presence of time-related artifacts.},
}
  
@inproceedings{diener2020towards,
    title={Towards Silent Paralinguistics: Deriving Speaking Mode and Speaker ID from Electromyographic Signals},
    author={Diener, Lorenz and Amiriparian, Shahin and Botelho, Catarina and Scheck, Kevin and Küster, Dennis and Trancoso, Isabel Schuller, Björn W. and Schultz, Tanja},
    booktitle={{INTERSPEECH} 2020 - 21st Annual Conference of the International Speech Communication Association},
    year={2020 (to appear)},
    url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Diener_IS2020_SilentCompPara.pdf},
    abstract={Silent Computational Paralinguistics (SCP) - the assessment of speaker states and traits from non-audibly spoken communication - has rarely been targeted in the rich body of either Computational Paralinguistics or Silent Speech Processing. Here, we provide first steps towards this challenging but potentially highly rewarding endeavour: Paralinguistics can enrich spoken language interfaces, while Silent Speech Processing enables confidential and unobtrusive spoken communication for everybody, including mute speakers. We approach SCP by using speech-related biosignals stemming from facial muscle activities captured by surface electromyography (EMG). To demonstrate the feasibility of SCP, we select one speaker trait (speaker identity) and one speaker state (speaking mode). We introduce two promising strategies for SCP: (1) deriving paralinguistic speaker information directly from EMG of silently produced speech versus (2) first converting EMG into an audible speech signal followed by conventional computational paralinguistic methods. We compare traditional feature extraction and decision making approaches to more recent deep representation and transfer learning by convolutional and recurrent neural networks, using openly available EMG data. We find that paralinguistics can be assessed not only from acoustic speech but also from silent speech captured by EMG.},
}

@inproceedings{botelho2020towards,
    title={Toward Silent Paralinguistics: Speech-to-EMG - Retrieving Articulatory Muscle Activity from Speech},
    author={Botelho, Catarina and Diener, Lorenz and Küster, Dennis and Scheck, Kevin and Amiriparian, Shahin and Schuller, Björn W. and Schultz, Tanja and Abad, Alberto and Trancoso, Isabel},
    booktitle={{INTERSPEECH} 2020 - 21st Annual Conference of the International Speech Communication Association},
    year={2020 (to appear)},
    url={https://www.csl.uni-bremen.de/cms/images/documents/publications/Interspeech2020_emg_to_speech_revised.pdf},
    abstract={Electromyographic (EMG) signals recorded during speech production encode information on articulatory muscle activity and also on the facial expression of emotion, thus representing a speech-related biosignal with strong potential for paralinguistic applications. In this work, we estimate the electrical activity of the muscles responsible for speech articulation directly from the speech signal. To this end, we first perform a neural conversion of speech features into electromyographic time domain features, and then attempt to retrieve the original EMG signal from the time domain features. We propose a feed forward neural network to address the first step of the problem (speech features to EMG features) and a neural network composed of a convolutional block and a bidirectional long short-term memory block to address the second problem (true EMG features to EMG signal). We observe that four out of the five originally proposed time domain features can be estimated reasonably well from the speech signal. Further,  the five time domain features are able to predict the original speech-related EMG signal with a concordance correlation coefficient of 0.663. We further compare our results with the ones achieved on the inverse problem of generating acoustic speech features from EMG features.},
}

@inproceedings{mason_iros2020,
  title = {From Human to Robot Everyday Activity},
  author = {Mason, Celeste and Gadzicki, Konrad and Meier, Moritz and Ahrens, Florian and Kluss, Thorsten and Maldonado, Jaime and Putze, Felix and Fehr, Thorsten and Zetzsche, Christoph and Herrmann, Manfred and Schill, Kerstin and Schultz, Tanja},
  booktitle = {IROS 2020},
  year = {2020},
  url={ https://www.csl.uni-bremen.de/cms/images/documents/publications/mason_iros2020.pdf },
  address={Las Vegas, USA},
  abstract={The Everyday Activities Science and Engineering (EASE) Collaborative Research Consortium's mission to enhance the performance of cognition-enabled robots establishes its foundation in the EASE Human Activities Data Analysis Pipeline. Through collection of diverse human activity information resources, enrichment with contextually relevant annotations, and subsequent multimodal analysis of the combined data sources, the pipeline described will provide a rich resource for robot planning researchers, through incorporation in the OpenEASE cloud platform.}
}

@inproceedings{angrick2020speech,
  title={Speech Spectrogram Estimation from Intracranial Brain Activity using a Quantization Approach},
  author={Angrick, Miguel and Herff, Christian and Johnson, Garett and Shih, Jerry and Krusienski, Dean and Schultz, Tanja},
  note={Interspeech 2020},
  abstract={Direct synthesis from intracranial brain activity into acoustic speech might provide an intuitive and natural communication means for speech-impaired users. In previous studies we have used logarithmic Mel-scaled speech spectrograms (logMels) as an intermediate representation in the decoding from ElectroCorticoGraphic (ECoG) recordings to an audible waveform. Mel-scaled speech spectrograms have a long tradition in acoustic speech processing and speech synthesis applications. In the past, we relied on regression approaches to find a mapping from brain activity to logMel spectral coefficients, due to the continuous feature space. However, regression tasks are unbounded and thus neuronal fluctuations in brain activity may result in abnormally high amplitudes in a synthesized acoustic speech signal. To mitigate these issues, we propose two methods for quantization of power values to discretize the feature space of logarithmic Mel-scaled spectral coefficients by using the median and the logistic formula, respectively, to reduce the complexity and restricting the number of intervals. We evaluate the practicability in a proof-of-concept with one participant through a simple classification based on linear discriminant analysis and compare the resulting waveform with the original speech. Reconstructed spectrograms achieve Pearson correlation coefficients with a mean of r=0.5 ± 0.11 in a 5-fold cross validation.},
  url={https://www.csl.uni-bremen.de/cms/images/documents/publications/angrick2020speech.pdf},
  keywords={neural signals for spoken communication, speech synthesis, electrocorticography, BCI},
  year={2020}
}

@article{kuster_i_2020,
  title = {I saw it on {YouTube}! {How} online videos shape perceptions of mind, morality, and fears about robots},
  issn = {1461-4448, 1461-7315},
  url= {https://www.csl.uni-bremen.de/cms/images/documents/publications/Kuster_et_al_I_saw_it_on_YouTube.pdf},
  doi = {10.1177/1461444820954199},
  abstract = {Robots have the potential to transform our existing categorical distinctions between “property” and “persons.” Previous research has demonstrated that humans naturally anthropomorphize them, and this tendency may be amplified when a robot is subject to abuse. Simultaneously, robots give rise to hopes and fears about the future and our place in it. However, most available evidence on these mechanisms is either anecdotal, or based on a small number of laboratory studies with limited ecological validity. The present work aims to bridge this gap through examining responses of participants (N = 160) to four popular online videos of a leading robotics company (Boston Dynamics) and one more familiar vacuum cleaning robot (Roomba). Our results suggest that unexpectedly human-like abilities might provide more potent cues to mind perception than appearance, whereas appearance may attract more compassion and protection. Exposure to advanced robots significantly influences attitudes toward future artificial intelligence. We discuss the need for more research examining groundbreaking robotics outside the laboratory.},
  language = {en},
  urldate = {2020-09-21},
  journal = {New Media \& Society},
  author = {Küster, Dennis and Swiderska, Aleksandra and Gunkel, David},
  month = sep,
  year = {2020},
  pages = {146144482095419}
}

@article{kuster_seeing_2020,
  title = {Seeing the mind of robots: Harm augments mind perception but benevolent intentions reduce dehumanisation of artificial entities in visual vignettes},
  language = {en},
  author = {Küster, Dennis and Swiderska, Aleksandra},
  url= {https://www.csl.uni-bremen.de/cms/images/documents/publications/Kuster_Swiderska_2020_Seeing_the_mind_of_robots.pdf},
  doi= {10.1002/ijop.12715},
  abstract = {According to moral typecasting theory, good‐ and evil‐doers (agents) interact with the recipients of their actions (patients) in a moral dyad. When this dyad is completed, mind attribution towards intentionally harmed liminal minds is enhanced. However, from a dehumanisation view, malevolent actions may instead result in a denial of humanness. To contrast both accounts, a visual vignette experiment (N = 253) depicted either malevolent or benevolent intentions towards robotic or human avatars. Additionally, we examined the role of harm‐salience by showing patients as either harmed, or still unharmed. The results revealed significantly increased mind attribution towards visibly harmed patients, mediated by perceived pain and expressed empathy. Benevolent and malevolent intentions were evaluated respectively as morally right or wrong, but their impact on the patient was diminished for the robotic avatar. Contrary to dehumanisation predictions, our manipulation of intentions failed to affect mind perception. Nonetheless, benevolent intentions reduced dehumanisation of the patients. Moreover, when pain and empathy were statistically controlled, the effect of intentions on mind perception was mediated by dehumanisation. These findings suggest that perceived intentions might only be indirectly tied to mind perception, and that their role may be better understood when additionally accounting for empathy and dehumanisation.},
  journal = {International Journal of Psychology},
  year = {2020},
  pages = {12}
}

@article{krumhuber_human_2020,
  title = {Human and machine validation of 14 databases of dynamic facial expressions},
  issn = {1554-3528},
  url = {https://www.csl.uni-bremen.de/cms/images/documents/publications/Krumhuber_et_al_2020_Human_and_machine_validation_of_14_databases_of_dynamic_facial_expressions.pdf},
  doi = {10.3758/s13428-020-01443-y},
  abstract = {With a shift in interest toward dynamic expressions, numerous corpora of dynamic facial stimuli have been developed over the past two decades. The present research aimed to test existing sets of dynamic facial expressions (published between 2000 and 2015) in a cross-corpus validation effort. For this, 14 dynamic databases were selected that featured facial expressions of the basic six emotions (anger, disgust, fear, happiness, sadness, surprise) in posed or spontaneous form. In Study 1, a subset of stimuli from each database (N = 162) were presented to human observers and machine analysis, yielding considerable variance in emotion recognition performance across the databases. Classification accuracy further varied with perceived intensity and naturalness of the displays, with posed expressions being judged more accurately and as intense, but less natural compared to spontaneous ones. Study 2 aimed for a full validation of the 14 databases by subjecting the entire stimulus set (N = 3812) to machine analysis. A FACS-based Action Unit (AU) analysis revealed that facial AU configurations were more prototypical in posed than spontaneous expressions. The prototypicality of an expression in turn predicted emotion classification accuracy, with higher performance observed for more prototypical facial behavior. Furthermore, technical features of each database (i.e., duration, face box size, head rotation, and motion) had a significant impact on recognition accuracy. Together, the findings suggest that existing databases vary in their ability to signal specific emotions, thereby facing a trade-off between realism and ecological validity on the one end, and expression uniformity and comparability on the other.},
  language = {en},
  urldate = {2020-09-21},
  journal = {Behavior Research Methods},
  author = {Krumhuber, Eva G. and Küster, Dennis and Namba, Shushi and Skora, Lina},
  month = aug,
  year = {2020}
}

@article{swiderska_robots_2020,
  title = {Robots as malevolent moral agents: Harmful behavior results in dehumanization, not anthropomorphism},
  volume = {44},
  issn = {0364-0213, 1551-6709},
  shorttitle = {Robots as malevolent moral agents},
  url = {https://www.csl.uni-bremen.de/cms/images/documents/publications/Swiderska_Kuester_RobotsAsMalevolentAgents_CognitiveScience_PrePrintVersion.pdf},
  doi = {10.1111/cogs.12872},
  abstract = {A robot’s decision to harm a person is sometimes considered to be the ultimate proof of it gaining a human-like mind. Here, we contrasted predictions about attribution of mental capacities from moral typecasting theory, with the denial of agency from dehumanization literature. Experiments 1 and 2 investigated mind perception for intentionally and accidentally harmful robotic agents based on text and image vignettes. Experiment 3 disambiguated agent intention (malevolent and benevolent), and additionally varied the type of agent (robotic and human) using short computer-generated animations. Harmful robotic agents were consistently imbued with mental states to a lower degree than benevolent agents, supporting the dehumanization account. Further results revealed that a human moral patient appeared to suffer less when depicted with a robotic agent than with another human. The ﬁndings suggest that future robots may become subject to humanlike dehumanization mechanisms, which challenges the established beliefs about anthropomorphism in the domain of moral interactions.},
  language = {en},
  number = {7},
  urldate = {2020-09-21},
  journal = {Cognitive Science},
  author = {Swiderska, Aleksandra and Küster, Dennis},
  month = jul,
  year = {2020}
}

@article{dupre_performance_2020,
  title = {A performance comparison of eight commercially available automatic classifiers for facial affect recognition},
  volume = {15},
  issn = {1932-6203},
  url = {https://www.csl.uni-bremen.de/cms/images/documents/publications/Dupre_et_al_2020_A_performance_comparison_of_eight_commercially_available_automatic_classifiers.pdf},
  doi = {10.1371/journal.pone.0231968},
  language = {en},
  number = {4},
  urldate = {2020-09-21},
  journal = {PLOS ONE},
  author = {Dupré, Damien and Krumhuber, Eva G. and Küster, Dennis and McKeown, Gary J.},
  editor = {D’Mello, Sidney},
  month = apr,
  year = {2020},
  pages = {e0231968}
}

@incollection{kuster_hidden_2020,
  address = {Cham},
  title = {Hidden tears and scrambled joy: On the adaptive costs of unguarded nonverbal social signals},
  isbn = {978-3-030-34964-6},
  shorttitle = {Hidden tears and scrambled joy},
  url = {https://www.csl.uni-bremen.de/cms/images/documents/publications/Kuester_HiddenTears_PrePrint.pdf},
  abstract = {The ability to correctly assess the internal states of another is assumed to have clear adaptive advantages. Yet, the balance of evolutionary costs and benefits appears less obvious for the sender. Rather than to indiscriminately maximize the ratio of signal to noise, human nonverbal signaling is finely tuned to its situational context. We smile naturally and without flinching, out of politeness, to signal positive intentions, or to distract an opponent. Careless displays of fear may draw a predator’s attention, or they may reveal a readiness to abandon resources without a fight. Emotional tears result in blurred vision and reduce visual acuity, akin to a self-imposed handicap. This chapter re-examines socially intelligent nonverbal communication while focusing on the evolutionary costs of signaling too clearly and indiscriminately.},
  language = {en},
  urldate = {2020-09-21},
  booktitle = {Social {Intelligence} and {Nonverbal} {Communication}},
  publisher = {Springer International Publishing},
  author = {Küster, Dennis},
  editor = {Sternberg, Robert J. and Kostić, Aleksandra},
  year = {2020},
  doi = {10.1007/978-3-030-34964-6_10},
  keywords = {Adaptive costs, Display rules, Emotional tears, Nonverbal social signals, Social intelligence},
  pages = {283--304}
}

@article{kuster_opportunities_2020,
  title = {Opportunities and challenges for using automatic human affect analysis in consumer research},
  volume = {14},
  issn = {1662-453X},
  url = {https://www.csl.uni-bremen.de/cms/images/documents/publications/Kuster_et_al_2020_Opportunities_and_Challenges_for_Using_Automatic_Human_Affect_Analysis_in.pdf},
  doi = {10.3389/fnins.2020.00400},
  language = {en},
  urldate = {2020-09-21},
  journal = {Frontiers in Neuroscience},
  author = {Küster, Dennis and Krumhuber, Eva G. and Steinert, Lars and Ahuja, Anuj and Baker, Marc and Schultz, Tanja},
  month = apr,
  year = {2020},
  pages = {400}  
}

@inproceedings{najafabadi_tool-use_2020,
  title = {Tool-use training in augmented reality: Changes on forearm body schema and somatosensory representation},
  booktitle={FENS International Conference 2020},
  abstract = {Body Miller et al. (2014) described altered arm representation and body schema after training to use a mechanical gripper for grasping distant objects. We examined whether similar training with a virtual tool in augmented reality (AR) would have comparable effects. Thirty young adults learned controlling a virtual gripper to grasp virtual objects at various locations in horizontal plane. Vibrotactile feedback was applied to thumb and index fingers through a CyberTouch II cyber glove when the tool touched the object. Participants performed 4 training blocks with 60 trials each. In a tactile distance judgement task performed before, after 2 blocks, and after 4 blocks of training, participants judged distances between two tactile stimuli, synchronously applied to their right forearm. The stimuli were applied either along (“vertical”) or perpendicular (“horizontal”) to the arm, with three distances per orientation (5 trials per orientation and distance). Mean estimation errors were calculated. ANCOVA with orientation as factor and estimation error at t0 as covariate to correct for baseline differences, revealed a significant effect of orientation (F(1,375) = 4.1156, p = .043, pEta² = .011). Estimation errors were smaller for vertical as compared to horizontal orientations, indicating that the stimulated locations on the arm were perceived as being closer together for the vertical orientation. These results confirm that virtual tool use training has a strong short-term effect on the body schema. We conclude that the virtual tool was integrated into the arm representation resulting in a shrinkage of perceived distances on the arm along the vertical axis.},
  language = {en},
  author = {Putze, Felix and Küster, Dennis and Hunter, Mathew and Godde, Ben},
  url = {https://www.csl.uni-bremen.de/cms/images/documents/publications/Najafabadi_Tool-use2020.pdf},
  location = {Glasgow, UK},
  month = jul,
  year = {2020},
  pages = {}
}

@inproceedings{dente2017measures,
  title={Measures and metrics for automatic emotion classification via FACET},
  abstract = {For dynamic emotions to be modelled in a natural and convincing way, systems must rely on accurate affective analysis of facial expressions in the first place. The present work introduces two measures for evaluating automatic emotion classification performance. It further provides a systematic comparison between 14 databases of dynamic expressions. Machine analysis was conducted using the FACET system, with an algorithm calculating recognition sensitivity and confidence. Results revealed the proportion of facial stimuli that could be recognised by the machine algorithm above threshold evidence, showing significant differences in recognition performance between the databases.},
  author={Dente, Pasquale and K{\"u}ster, Dennis and Skora, Lina and Krumhuber, E},
  url = {https://www.csl.uni-bremen.de/cms/images/documents/publications/Dente_et_al_2017_Measures_and_metrics_for_automatic_emotion_classif.pdf},
  booktitle={Proceedings of the Conference on the Study of Artificial Intelligence and Simulation of Behaviour (AISB)},
  pages={160--163},
  year={2017}
}
