Cites,Authors,Title,Year,Source,Publisher,ArticleURL,CitesURL,GSRank,QueryDate,Type,DOI,ISSN,CitationURL,Volume,Issue,StartPage,EndPage,ECC,CitesPerYear,CitesPerAuthor,AuthorCount,Age,Abstract
444,"T Schultz, A Waibel","Language-independent and language-adaptive acoustic modeling for speech recognition",2001,"Speech Communication","Elsevier","https://www.sciencedirect.com/science/article/pii/S0167639300000947","https://scholar.google.com/scholar?cites=10892713572787206172&as_sdt=2005&sciodt=0,5&hl=en",1,"2020-11-06 21:29:44","","","","",,,,,444,23.37,222,2,19,"With the distribution of speech technology products all over the world, the portability to new target languages becomes a practical concern. As a consequence our research focuses on the question of how to port large vocabulary continuous speech recognition (LVCSR) …"
398,"B Denby, T Schultz, K Honda, T Hueber, JM Gilbert…","Silent speech interfaces",2010,"Speech …","Elsevier","https://www.sciencedirect.com/science/article/pii/S0167639309001307","https://scholar.google.com/scholar?cites=1589295871323217157&as_sdt=2005&sciodt=0,5&hl=en",2,"2020-11-06 21:29:44","","","","",,,,,398,39.80,66,6,10,"The possibility of speech processing in the absence of an intelligible acoustic signal has given rise to the idea of a 'silent speech'interface, to be used as an aid for the speech-handicapped, or as part of a communications system operating in silence-required or high …"
318,"L Besacier, E Barnard, A Karpov, T Schultz","Automatic speech recognition for under-resourced languages: A survey",2014,"Speech Communication","Elsevier","https://www.sciencedirect.com/science/article/pii/S0167639313000988","https://scholar.google.com/scholar?cites=5467971984374604304&as_sdt=2005&sciodt=0,5&hl=en",3,"2020-11-06 21:29:44","","","","",,,,,318,53.00,80,4,6,"Speech processing for under-resourced languages is an active field of research, which has experienced significant progress during the past decade. We propose, in this paper, a survey that focuses on automatic speech recognition (ASR) for these languages. The …"
222,"T Schultz","Globalphone: a multilingual speech and text database developed at karlsruhe university",2002,"Seventh International Conference on Spoken …","isca-speech.org","https://www.isca-speech.org/archive/icslp_2002/i02_0345.html","https://scholar.google.com/scholar?cites=15066980250511497559&as_sdt=2005&sciodt=0,5&hl=en",4,"2020-11-06 21:29:44","","","","",,,,,222,12.33,222,1,18,"This paper describes the design, collection, and current status of the multilingual database GlobalPhone, an ongoing project since 1995 at Karlsruhe University. GlobalPhone is a highquality read speech and text database in a large variety of languages which is suitable …"
217,"T Schultz, K Kirchhoff","Multilingual speech processing",2006,"","books.google.com","https://books.google.com/books?hl=en&lr=&id=LC2WKbEr85YC&oi=fnd&pg=PP2&dq=%22tanja+schultz%22&ots=_MY9bfCMq2&sig=YtSIK-cVz9F3KFZSQ4gYJEJmsLo","https://scholar.google.com/scholar?cites=3136522549600665802&as_sdt=2005&sciodt=0,5&hl=en",5,"2020-11-06 21:29:44","BOOK","","","",,,,,217,15.50,109,2,14,"Tanja Schultz and Katrin Kirchhoff have compiled a comprehensive overview of speech processing from a multilingual perspective. By taking this all-inclusive approach to speech processing, the editors have included theories, algorithms, and techniques that are required …"
223,"C Herff, D Heger, O Fortmann, J Hennrich…","Mental workload during n-back task—quantified in the prefrontal cortex using fNIRS",2014,"Frontiers in human …","frontiersin.org","https://www.frontiersin.org/articles/10.3389/fnhum.2013.00935/full","https://scholar.google.com/scholar?cites=10307051163683899700&as_sdt=2005&sciodt=0,5&hl=en",6,"2020-11-06 21:29:44","HTML","","","",,,,,223,37.17,45,5,6,"When interacting with technical systems, users experience mental workload. Particularly in multitasking scenarios (eg interacting with the car navigation system while driving) it is desired to not distract the users from their primary task. For such purposes, human-machine …"
183,"Z Wang, T Schultz, A Waibel","Comparison of acoustic model adaptation techniques on non-native speech",2003,"2003 IEEE International …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/1198837/","https://scholar.google.com/scholar?cites=2715814139691947882&as_sdt=2005&sciodt=0,5&hl=en",7,"2020-11-06 21:29:44","","","","",,,,,183,10.76,61,3,17,"The performance of speech recognition systems is consistently poor on non-native speech. The challenge for non-native speech recognition is to maximize the recognition performance with a small amount of available non-native data. We report on acoustic modeling …"
170,"A Waibel, M Bett, F Metze, K Ries…","Advances in automatic meeting record creation and access",2001,"… , Speech, and Signal …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/940902/","https://scholar.google.com/scholar?cites=7887244976923090628&as_sdt=2005&sciodt=0,5&hl=en",8,"2020-11-06 21:29:44","","","","",,,,,170,8.95,34,5,19,"Oral communication is transient, but many important decisions, social contracts and fact findings are first carried out in an oral setup, documented in written form and later retrieved. At Carnegie Mellon University's Interactive Systems Laboratories we have been …"
169,"T Schultz, M Wand","Modeling coarticulation in EMG-based continuous speech recognition",2010,"Speech Communication","Elsevier","https://www.sciencedirect.com/science/article/pii/S0167639309001770","https://scholar.google.com/scholar?cites=9055257635300961115&as_sdt=2005&sciodt=0,5&hl=en",9,"2020-11-06 21:29:44","","","","",,,,,169,16.90,85,2,10,"This paper discusses the use of surface electromyography for automatic speech recognition. Electromyographic signals captured at the facial muscles record the activity of the human articulatory apparatus and thus allow to trace back a speech signal even if it is spoken …"
153,"H Soltau, T Schultz, M Westphal…","Recognition of music types",1998,"Proceedings of the 1998 …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/675470/","https://scholar.google.com/scholar?cites=4026383609507568779&as_sdt=2005&sciodt=0,5&hl=en",10,"2020-11-06 21:29:44","","","","",,,,,153,6.95,38,4,22,"This paper describes a music type recognition system that can be used to index and search in multimedia databases. A new approach to temporal structure modeling is supposed. The so called ETM-NN (explicit time modelling with neural network) method uses abstraction of …"
155,"M Killer, S Stuker, T Schultz","Grapheme based speech recognition",2003,"Eighth European Conference on …","isca-speech.org","https://www.isca-speech.org/archive/eurospeech_2003/e03_3141.html","https://scholar.google.com/scholar?cites=7597890642680008849&as_sdt=2005&sciodt=0,5&hl=en",11,"2020-11-06 21:29:44","","","","",,,,,155,9.12,52,3,17,"Large vocabulary speech recognition systems traditionally represent words in terms of subword units, usually phonemes. This paper investigates the potential of graphemes acting as subunits. In order to develop context dependent grapheme based speech recognizers …"
152,"C Herff, D Heger, A De Pesters, D Telaar…","Brain-to-text: decoding spoken phrases from phone representations in the brain",2015,"Frontiers in …","frontiersin.org","https://www.frontiersin.org/articles/10.3389/fnins.2015.00217/full","https://scholar.google.com/scholar?cites=10373792138042739738&as_sdt=2005&sciodt=0,5&hl=en",12,"2020-11-06 21:29:44","HTML","","","",,,,,152,30.40,30,5,5,"It has long been speculated whether communication between humans and machines based on natural speech related cortical activity is possible. Over the past decade, studies have suggested that it is feasible to recognize isolated aspects of speech from neural signals …"
135,"A Waibel, T Schultz, M Bett, M Denecke…","SMaRT: The smart meeting room task at ISL",2003,"… , Speech, and Signal …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/1202752/?casa_token=SByke-18WPwAAAAA:Vz2QXwXFlYlJQuFa_aVx2Ywtg_Y0JUoSWD97OYqhUUI_rgbbjUfj19awYjr3ei93mB7Qu3F04A","https://scholar.google.com/scholar?cites=11368825063672847323&as_sdt=2005&sciodt=0,5&hl=en",13,"2020-11-06 21:29:44","","","","",,,,,135,7.94,27,5,17,"As computational and communications systems become increasingly smaller, faster, more powerful, and more integrated, the goal of interactive, integrated meeting support rooms is slowly becoming reality. It is already possible, for instance, to rapidly locate task-related …"
128,"K Schaaff, T Schultz","Towards emotion recognition from electroencephalographic signals",2009,"2009 3rd international conference on …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/5349316/?casa_token=Ti5CuPgFFFUAAAAA:Ogv_tFhAGa8aOYyakTXt_oGYFX4ZngZPkpsvoYPzeV8TgE2smHLprUQG0fQfUbABP_cJBICiOg","https://scholar.google.com/scholar?cites=8607040235483190797&as_sdt=2005&sciodt=0,5&hl=en",14,"2020-11-06 21:29:44","","","","",,,,,128,11.64,64,2,11,"During the last decades, information about the emotional state of users has become more and more important in human-computer interaction. Automatic emotion recognition enables the computer to recognize a user's emotional state and thus allows for appropriate reaction …"
132,"L Maier-Hein, F Metze, T Schultz…","Session independent non-audible speech recognition using surface electromyography",2005,"IEEE Workshop on …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/1566521/?casa_token=qAGeePFAfPUAAAAA:gtcUpeRvWbI0rSKNv5pYW8fwC6-38yxuIHhSHvaOGGQqn0uzYIWWYk2ZMrcU9LpYgk8_6I5JTA","https://scholar.google.com/scholar?cites=1887381390932990719&as_sdt=2005&sciodt=0,5&hl=en",15,"2020-11-06 21:29:44","","","","",,,,,132,8.80,33,4,15,"In this paper we introduce a speech recognition system based on myoelectric signals. The system handles audible and non-audible speech. Major challenges in surface electromyography based speech recognition ensue from repositioning electrodes between …"
126,"M Katzenmaier, R Stiefelhagen, T Schultz","Identifying the addressee in human-human-robot interactions based on head pose and speech",2004,"Proceedings of the 6th …","dl.acm.org","https://dl.acm.org/doi/abs/10.1145/1027933.1027959","https://scholar.google.com/scholar?cites=11809324246116493159&as_sdt=2005&sciodt=0,5&hl=en",16,"2020-11-06 21:29:44","","","","",,,,,126,7.88,42,3,16,"In this work we investigate the power of acoustic and visual cues, and their combination, to identify the addressee in a human-human-robot interaction. Based on eighteen audio-visual recordings of two human beings and a (simulated) robot we discriminate the interaction of …"
124,"T Schultz, A Waibel","Fast bootstrapping of LVCSR systems with multilingual phoneme sets",1997,"Fifth European Conference on Speech …","isca-speech.org","https://www.isca-speech.org/archive/eurospeech_1997/e97_0371.html","https://scholar.google.com/scholar?cites=8468342879656285178&as_sdt=2005&sciodt=0,5&hl=en",17,"2020-11-06 21:29:44","","","","",,,,,124,5.39,62,2,23,"In this paper we described an efficient method to bootstrap continuously spoken, large vocabulary speech recognition systems by multilingual phoneme sets. To evaluate this techniques we collected the multilingual database GlobalPhone which currently consists of …"
128,"SC Jou, T Schultz, M Walliczek, F Kraft…","Towards continuous speech recognition using surface electromyography",2006,"… Conference on Spoken …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2006/i06_1592.html","https://scholar.google.com/scholar?cites=8993131629050403236&as_sdt=2005&sciodt=0,5&hl=en",18,"2020-11-06 21:29:44","","","","",,,,,128,9.14,26,5,14,"We present our research on continuous speech recognition of the surface electromyographic signals that are generated by the human articulatory muscles. Previous research on electromyographic speech recognition was limited to isolated word recognition …"
129,"NT Vu, DC Lyu, J Weiner, D Telaar…","A first speech recognition system for Mandarin-English code-switch conversational speech",2012,"… , Speech and Signal …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/6289015/?casa_token=oXy38VCaIIEAAAAA:cfd6D5Hgj_5o8hz6TulFLFEChZM9TyfECKO72lOoMOX-TcAHVYq2OlNQqhPYtzgWFv9dfzdTOg","https://scholar.google.com/scholar?cites=587982689362947596&as_sdt=2005&sciodt=0,5&hl=en",19,"2020-11-06 21:29:44","","","","",,,,,129,16.13,26,5,8,"This paper presents first steps toward a large vocabulary continuous speech recognition system (LVCSR) for conversational Mandarin-English code-switching (CS) speech. We applied state-of-the-art techniques such as speaker adaptive and discriminative training to …"
112,"T Schultz, A Waibel","Language independent and language adaptive large vocabulary speech recognition",1998,"Fifth International Conference on Spoken …","isca-speech.org","https://www.isca-speech.org/archive/icslp_1998/i98_0577.html","https://scholar.google.com/scholar?cites=12792712254566188893&as_sdt=2005&sciodt=0,5&hl=en",20,"2020-11-06 21:29:44","","","","",,,,,112,5.09,56,2,22,"This paper describes the design of a multilingual speech recognizer using an LVCSR dictation database which has been collected under the project GlobalPhone. This project at the University of Karlsruhe investigates LVCSR systems in 15 languages of the world …"
69,"T Schultz, M Wand, T Hueber…","Biosignal-based spoken communication: A survey",2017,"… on Audio, Speech …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/8114358/?casa_token=Y0qCTClpIXEAAAAA:5C_Fab7hvtH4KRxSKZ35kuVwDwCkXZYchcBKcbThRhekuf7r1r4btyHb_EvBpZQhYwqyq16KVA","https://scholar.google.com/scholar?cites=994726507155754875&as_sdt=2005&sciodt=0,5&hl=en",21,"2020-11-06 21:29:44","","","","",,,,,69,23.00,17,4,3,"Speech is a complex process involving a wide range of biosignals, including but not limited to acoustics. These biosignals-stemming from the articulators, the articulator muscle activities, the neural pathways, and the brain itself-can be used to circumvent limitations of …"
112,"A Waibel, P Geutner, LM Tomokiyo…","Multilinguality in speech and spoken language systems",2000,"Proceedings of the …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/880085/?casa_token=86922tA9cBYAAAAA:RANbdGgScBasHYhdmzmV6UP1F0ZYGruzezPZDRF8Syp5F9a0p7vkf2R9UhDv090ozvvqoi7N0Q","https://scholar.google.com/scholar?cites=10374226289740442627&as_sdt=2005&sciodt=0,5&hl=en",22,"2020-11-06 21:29:44","","","","",,,,,112,5.60,28,4,20,"Building modern speech and language systems currently requires large data resources such as texts, voice recordings, pronunciation lexicons, morphological decomposition information and parsing grammars. Based on a study of the most important differences …"
104,"Q Jin, T Schultz, A Waibel","Far-field speaker recognition",2007,"IEEE Transactions on Audio …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/4291604/?casa_token=Rdnr_WpfMfUAAAAA:nGkeUuWRfOzCcSZ4hsOLLF9GApq4RGRoPMxlwBA6ZpCKNJTjgRhM87iHPpjrWFmcL_i96LIkwA","https://scholar.google.com/scholar?cites=12773873810909881330&as_sdt=2005&sciodt=0,5&hl=en",23,"2020-11-06 21:29:44","","","","",,,,,104,8.00,35,3,13,"In this paper, we study robust speaker recognition in far-field microphone situations. Two approaches are investigated to improve the robustness of speaker recognition in such scenarios. The first approach applies traditional techniques based on acoustic features. We …"
100,"Q Jin, T Schultz","Speaker segmentation and clustering in meetings",2004,"Eighth International Conference on Spoken …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2004/i04_0597.html","https://scholar.google.com/scholar?cites=1102174428108527677&as_sdt=2005&sciodt=0,5&hl=en",24,"2020-11-06 21:29:44","","","","",,,,,100,6.25,50,2,16,"This paper describes the automatic speaker segmentation and clustering system for natural, multi-speaker meeting conversations based on multiple distant microphones. The system was evaluated in the NIST RT-04S Meeting Recognition Evaluation on the speaker …"
100,"M Woszczyna, N Aoki-Waibel, FD Buo…","JANUS 93: Towards spontaneous speech translation",1994,"… of ICASSP'94. IEEE …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/389285/?casa_token=KoAjNG0lW30AAAAA:PWk4oQUn4r2CvmLVrjqnYbrex9NLmgfPtIpOh7JhtJfwI99KpCVKJDvrUwtBuDcp64Qj4YyQfA","https://scholar.google.com/scholar?cites=12720689163340204641&as_sdt=2005&sciodt=0,5&hl=en",25,"2020-11-06 21:29:44","","","","",,,,,100,3.85,25,4,26,"We present first results from our efforts toward translation of spontaneously spoken speech. Improvements include increasing coverage, robustness, generality and speed of JANUS, the speech-to-speech translation system of Carnegie Mellon and Karlsruhe University. The …"
43,"M Angrick, C Herff, E Mugler, MC Tate…","Speech synthesis from ECoG using densely connected 3D convolutional neural networks",2019,"Journal of neural …","iopscience.iop.org","https://iopscience.iop.org/article/10.1088/1741-2552/ab0c59/meta","https://scholar.google.com/scholar?cites=10130441182290228762&as_sdt=2005&sciodt=0,5&hl=en",26,"2020-11-06 21:29:44","","","","",,,,,43,43.00,9,5,1,"Objective. Direct synthesis of speech from neural signals could provide a fast and natural way of communication to people with neurological diseases. Invasively-measured brain activity (electrocorticography; ECoG) supplies the necessary temporal and spatial resolution …"
95,"YC Tam, T Schultz","Dynamic language model adaptation using variational Bayes inference",2005,"Ninth European Conference on Speech …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2005/i05_0005.html","https://scholar.google.com/scholar?cites=6529961798072102798&as_sdt=2005&sciodt=0,5&hl=en",27,"2020-11-06 21:29:44","","","","",,,,,95,6.33,48,2,15,"We propose an unsupervised dynamic language model (LM) adaptation framework using long-distance latent topic mixtures. The framework employs the Latent Dirichlet Allocation model (LDA) which models the latent topics of a document collection in an unsupervised …"
96,"S Stuker, T Schultz, F Metze…","Multilingual articulatory features",2003,"2003 IEEE International …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/1198737/?casa_token=Jqyv7qUqWZkAAAAA:vSacRehllVyPwNrE0885uvP3LBAPAP2FVoSM6BebFmY9fpmbw5zDotAR2nmhNG_O_xfJbtYu0Q","https://scholar.google.com/scholar?cites=14109516619667053936&as_sdt=2005&sciodt=0,5&hl=en",28,"2020-11-06 21:29:44","","","","",,,,,96,5.65,24,4,17,"Speech recognition systems based on or aided by articulatory features, such as place and manner of articulation, have been shown to be useful under varying circumstances. Recognizers based on features better compensate channel and noise variability. We show …"
99,"T Schultz, A Waibel","Multilingual and crosslingual speech recognition",1998,"Proc. DARPA Workshop on Broadcast News …","ri.cmu.edu","http://ri.cmu.edu/pub_files/pub1/schultz_tanja_1998_1/schultz_tanja_1998_1.pdf","https://scholar.google.com/scholar?cites=364376280071578293&as_sdt=2005&sciodt=0,5&hl=en",29,"2020-11-06 21:29:44","PDF","","","",,,,,99,4.50,50,2,22,"This paper describes the design of a multilingual speech recognizer using an LVCSR dictation database which has been collected under the project GlobalPhone. This project at the University of Karlsruhe investigates LVCSR systems in 15 languages of the world …"
101,"NT Vu, D Imseng, D Povey, P Motlicek…","Multilingual deep neural network based acoustic modeling for rapid language adaptation",2014,"… on acoustics, speech …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/6855086/?casa_token=IEJWaEDncxwAAAAA:QMN9Fe4X63OKG1nUes5We1YDmY7aU2YE18KzwKoe0-ZwM5rxSLiR6S-1hqk7RXdgV2H_0MGfZw","https://scholar.google.com/scholar?cites=14317728308436745283&as_sdt=2005&sciodt=0,5&hl=en",30,"2020-11-06 21:29:44","","","","",,,,,101,16.83,20,5,6,"This paper presents a study on multilingual deep neural network (DNN) based acoustic modeling and its application to new languages. We investigate the effect of phone merging on multilingual DNN in context of rapid language adaptation. Moreover, the combination of …"
88,"T Schultz, A Waibel","Experiments on cross-language acoustic modeling",2001,"Seventh European Conference on Speech …","isca-speech.org","https://www.isca-speech.org/archive/eurospeech_2001/e01_2721.html","https://scholar.google.com/scholar?cites=3491147597830838686&as_sdt=2005&sciodt=0,5&hl=en",31,"2020-11-06 21:29:44","","","","",,,,,88,4.63,44,2,19,"With the distribution of speech products all over the world, the portability to new target languages becomes a practical concern. As a consequence our research focuses on rapid transfer of LVCSR systems to other languages. In former studies we evaluated the …"
99,"T Schultz, NT Vu, T Schlippe","Globalphone: A multilingual text & speech database in 20 languages",2013,"2013 IEEE International …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/6639248/?casa_token=lY-yy2ZOQtEAAAAA:HUdWhgO_wfmroMqGn4oai7UAnWD33E2Q7FyCVTPlyqpWrgO9RCX53wRJBf5s8uJiVqBZqI1wVw","https://scholar.google.com/scholar?cites=7794480869455737534&as_sdt=2005&sciodt=0,5&hl=en",32,"2020-11-06 21:29:44","","","","",,,,,99,14.14,33,3,7,"This paper describes the advances in the multilingual text and speech database GlobalPhone, a multilingual database of high-quality read speech with corresponding transcriptions and pronunciation dictionaries in 20 languages. GlobalPhone was designed …"
95,"M Georgi, C Amma, T Schultz","Recognizing Hand and Finger Gestures with IMU based Motion and EMG based Muscle Activity Sensing.",2015,"Biosignals","csl.uni-bremen.de","https://www.csl.uni-bremen.de/cms/images/documents/publications/GeorgiAmmaSchultz_RecognizingHandAndFingerGesturesWithIMUBasedMotionAndEMGBasedMuscleActivitySensing.pdf","https://scholar.google.com/scholar?cites=6900803863196401922&as_sdt=2005&sciodt=0,5&hl=en",33,"2020-11-06 21:29:44","PDF","","","",,,,,95,19.00,32,3,5,"Session-and person-independent recognition of hand and finger gestures is of utmost importance for the practicality of gesture based interfaces. In this paper we evaluate the performance of a wearable gesture recognition system that captures arm, hand, and finger …"
87,"K Carki, P Geutner, T Schultz","Turkish LVCSR: towards better speech recognition for agglutinative languages",2000,"2000 IEEE International …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/861971/?casa_token=qzZvIfmGd3MAAAAA:qR81N6NZ1BDHQegmbG1BeovOy8jI2GfpRUqmK1A6O9DQouDbiPt1u_rYIi011HgraJ2HR_BOzQ","https://scholar.google.com/scholar?cites=7439643765576683228&as_sdt=2005&sciodt=0,5&hl=en",34,"2020-11-06 21:29:44","","","","",,,,,87,4.35,29,3,20,"The Turkish language belongs to the Turkic family. All members of this family are close to one another in terms of linguistic structure. Typological similarities are vowel harmony, verb-final word order and agglutinative morphology. This latter property causes a very fast …"
90,"C Amma, M Georgi, T Schultz","Airwriting: Hands-free mobile text input by spotting and continuous recognition of 3D-space handwriting with inertial sensors",2012,"2012 16th International …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/6246142/?casa_token=PVM8OSbRqtAAAAAA:1KHMfqO9PvCN_-rJQ5FoQLvFLImUaQQf3HALClqHLemDTKPorEuJ4WhIRRExTRRyZCee9_bqlw","https://scholar.google.com/scholar?cites=4780500611260912826&as_sdt=2005&sciodt=0,5&hl=en",35,"2020-11-06 21:29:44","","","","",,,,,90,11.25,30,3,8,"We present an input method which enables complex hands-free interaction through 3d handwriting recognition. Users can write text in the air as if they were using an imaginary blackboard. Motion sensing is done wirelessly by accelerometers and gyroscopes which are …"
81,"F Metze, J McDonough, H Soltau, A Waibel, A Lavie…","The NESPOLE! Speech to Speech Translation System",2002,"","hal.inria.fr","https://hal.inria.fr/inria-00326408/","https://scholar.google.com/scholar?cites=3745999261875175170&as_sdt=2005&sciodt=0,5&hl=en",36,"2020-11-06 21:29:44","","","","",,,,,81,4.50,14,6,18,"The main goal of NESPOLE! is to advance the state-of-the-art of speech-to-speech translation in realistic scenarios and involving naive users. The first showcase presented in this demonstration involves an English, French, or German speaking client enquiring about …"
80,"YC Tam, T Schultz","Unsupervised language model adaptation using latent semantic marginals",2006,"Ninth International Conference on Spoken …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2006/i06_1705.html","https://scholar.google.com/scholar?cites=17938675750916737386&as_sdt=2005&sciodt=0,5&hl=en",37,"2020-11-06 21:29:44","","","","",,,,,80,5.71,40,2,14,"Abstract We integrated the Latent Dirichlet Allocation (LDA) approach, a latent semantic analysis model, into unsupervised language model adaptation framework. We adapted a background language model by minimizing the Kullback-Leibler divergence between the …"
85,"C Amma, T Krings, J Böer, T Schultz","Advancing muscle-computer interfaces with high-density electromyography",2015,"Proceedings of the 33rd Annual …","dl.acm.org","https://dl.acm.org/doi/abs/10.1145/2702123.2702501","https://scholar.google.com/scholar?cites=9450278583300900416&as_sdt=2005&sciodt=0,5&hl=en",38,"2020-11-06 21:29:44","","","","",,,,,85,17.00,21,4,5,"In this paper we present our results on using electromyographic (EMG) sensor arrays for finger gesture recognition. Sensing muscle activity allows to capture finger motion without placing sensors directly at the hand or fingers and thus may be used to build unobtrusive …"
77,"T Schultz, I Rogina, A Waibel","LVCSR-based language identification",1996,"1996 IEEE International …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/543237/?casa_token=wqDbK-o3k_UAAAAA:l9ME-mXEQAEh7bTn4f9GO3EFVuTGqweGs1VkBGH0ScwRsibZqU7e6PYIdJSe5Fi9v0XOEwHCEA","https://scholar.google.com/scholar?cites=11914017411711457251&as_sdt=2005&sciodt=0,5&hl=en",39,"2020-11-06 21:29:44","","","","",,,,,77,3.21,26,3,24,"Automatic language identification is an important problem in building multilingual speech recognition and understanding systems. Building a language identification module for four languages we studied the influence of applying different levels of knowledge sources on a …"
77,"S Stuker, F Metze, T Schultz…","Integrating multilingual articulatory features into speech recognition",2003,"… European Conference on …","isca-speech.org","https://www.isca-speech.org/archive/eurospeech_2003/e03_1033.html","https://scholar.google.com/scholar?cites=12820725964691389648&as_sdt=2005&sciodt=0,5&hl=en",40,"2020-11-06 21:29:44","","","","",,,,,77,4.53,19,4,17,"The use of articulatory features, such as place and manner of articulation, has been shown to reduce the word error rate of speech recognition systems under different conditions and in different settings. For example recognition systems based on features are more robust to …"
75,"K Schaaff, T Schultz","Towards an EEG-based emotion recognizer for humanoid robots",2009,"RO-MAN 2009-The 18th IEEE …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/5326306/?casa_token=DQyz85g0eRQAAAAA:QtNuVZinm9VD12o70AX0_ZMvh0OUOKMtClKRtJ2FiolyS-sUouBbom8TGQTgrz9EJJTqnADmuw","https://scholar.google.com/scholar?cites=15007179334849554597&as_sdt=2005&sciodt=0,5&hl=en",41,"2020-11-06 21:29:44","","","","",,,,,75,6.82,38,2,11,"In the field of interaction between humans and robots emotions have been disregarded for a long time. During the last few years interest in emotion research in this area has been constantly increasing as giving a robot the ability to react to the emotional state of the user …"
75,"NT Vu, T Schultz","Vietnamese large vocabulary continuous speech recognition",2009,"2009 IEEE Workshop on Automatic Speech …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/5373424/?casa_token=_ZRI_Z0BY-QAAAAA:p_6ZfOHzfK5CIAhozBMoqVawD82_yrNioNId24ax0q9JKEDE2MoyN4K6CwaFU57cPpDIuo3IZQ","https://scholar.google.com/scholar?cites=8429209900246731677&as_sdt=2005&sciodt=0,5&hl=en",42,"2020-11-06 21:29:44","","","","",,,,,75,6.82,38,2,11,"We report on our recent efforts toward a large vocabulary Vietnamese speech recognition system. In particular, we describe the Vietnamese text and speech database recently collected as part of our GlobalPhone corpus. The data was complemented by a large …"
75,"H Adel, NT Vu, T Schultz","Combination of recurrent neural networks and factored language models for code-switching language modeling",2013,"Proceedings of the 51st Annual Meeting of the …","aclweb.org","https://www.aclweb.org/anthology/P13-2037.pdf","https://scholar.google.com/scholar?cites=2021233968357299782&as_sdt=2005&sciodt=0,5&hl=en",43,"2020-11-06 21:29:44","PDF","","","",,,,,75,10.71,25,3,7,"In this paper, we investigate the application of recurrent neural network language models (RNNLM) and factored language models (FLM) to the task of language modeling for Code-Switching speech. We present a way to integrate partof-speech tags (POS) and language …"
69,"T Schultz, A Waibel","Polyphone decision tree specialization for language adaptation",2000,"2000 IEEE International Conference on …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/862080/?casa_token=0K6-ABHF3ZEAAAAA:kmmKVadCvmsXDpCHH9RoQVHRY1wtgEj00prXSzMDI8_XUOkhd2rzdPsRT-WNooJherORhpbSHA","https://scholar.google.com/scholar?cites=6067795000637878555&as_sdt=2005&sciodt=0,5&hl=en",44,"2020-11-06 21:29:44","","","","",,,,,69,3.45,35,2,20,"With the distribution of speech technology products all over the world, the fast and efficient portability to new target languages becomes a practical concern. The authors explore the relative effectiveness of adapting multilingual LVCSR systems to a new target language with …"
73,"F Putze, S Hesslinger, CY Tse, YY Huang…","Hybrid fNIRS-EEG based classification of auditory and visual perception processes",2014,"Frontiers in …","frontiersin.org","https://www.frontiersin.org/articles/10.3389/fnins.2014.00373/full","https://scholar.google.com/scholar?cites=13328216315612374994&as_sdt=2005&sciodt=0,5&hl=en",45,"2020-11-06 21:29:44","HTML","","","",,,,,73,12.17,15,5,6,"For multimodal Human-Computer Interaction (HCI), it is very useful to identify the modalities on which the user is currently processing information. This would enable a system to select complementary output modalities to reduce the user's workload. In this paper, we develop a …"
66,"SC Jou, T Schultz, A Waibel","Adaptation for soft whisper recognition using a throat microphone",2004,"Eighth International Conference on …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2004/i04_1493.html","https://scholar.google.com/scholar?cites=8488051616025697726&as_sdt=2005&sciodt=0,5&hl=en",46,"2020-11-06 21:29:44","","","","",,,,,66,4.13,22,3,16,"This paper describes various adaptation methods applied to recognizing soft whisper recorded with a throat microphone. Since the amount of adaptation data is small and the testing data is very different from the training data, a series of adaptation methods is …"
65,"A Waibel, A Badran, AW Black, R Frederking…","Speechalator: two-way speech-to-speech translation in your hand",2003,"Proceedings of the …","dl.acm.org","https://dl.acm.org/citation.cfm?id=1073442","https://scholar.google.com/scholar?cites=1246787264718221911&as_sdt=2005&sciodt=0,5&hl=en",47,"2020-11-06 21:29:44","","","","",,,,,65,3.82,13,5,17,"This demonstration involves two-way automatic speech-to-speech translation on a consumer off-the-shelf PDA. This work was done as part of the DARPA-funded Babylon project, investigating better speech-to-speech translation systems for communication in the …"
70,"H Adel, NT Vu, F Kraus, T Schlippe…","Recurrent neural network language modeling for code switching conversational speech",2013,"… on Acoustics, Speech …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/6639306/?casa_token=IOwedlq_hKEAAAAA:7xne7-FkTBLNfEbxDIqyty00_fe4e-9iXlKgWR95S4z-GL-GbVCfXgRb7-DwvdAeRWaIaBJPqw","https://scholar.google.com/scholar?cites=2243051119620441926&as_sdt=2005&sciodt=0,5&hl=en",48,"2020-11-06 21:29:44","","","","",,,,,70,10.00,14,5,7,"Code-switching is a very common phenomenon in multilingual communities. In this paper, we investigate language modeling for conversational Mandarin-English code-switching (CS) speech recognition. First, we investigate the prediction of code switches based on textual …"
63,"Q Jin, AR Toth, AW Black…","Is voice transformation a threat to speaker identification?",2008,"2008 IEEE International …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/4518742/?casa_token=bwyXwIqtqy0AAAAA:fyrnTxnnskhIRoAJUNcqOlLXuMszax-wESTK4NUsc4-YCaqCQiJbtkRvzitv2QvFeMVCnE_SOg","https://scholar.google.com/scholar?cites=3617871793236900689&as_sdt=2005&sciodt=0,5&hl=en",49,"2020-11-06 21:29:44","","","","",,,,,63,5.25,16,4,12,"With the development of voice transformation and speech synthesis technologies, speaker identification systems are likely to face attacks from imposters who use voice transformed or synthesized speech to mimic a particular speaker. Therefore, we investigated in this paper …"
81,"A Porbadnigk, M Wester, TS Jan-p Calliess","EEG-based speech recognition impact of temporal effects",2009,"","Citeseer","http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.157.8486","https://scholar.google.com/scholar?cites=2007045545535569937&as_sdt=2005&sciodt=0,5&hl=en",50,"2020-11-06 21:29:44","","","","",,,,,81,7.36,27,3,11,"In this paper, we investigate the use of electroencephalograhic signals for the purpose of recognizing unspoken speech. The term unspoken speech refers to the process in which a subject imagines speaking a given word without moving any articulatory muscle or …"
64,"C Amma, M Georgi, T Schultz","Airwriting: a wearable handwriting recognition system",2014,"Personal and ubiquitous computing","Springer","https://idp.springer.com/authorize/casa?redirect_uri=https://link.springer.com/content/pdf/10.1007/s00779-013-0637-3.pdf&casa_token=FVh7hkBdsiQAAAAA:3NZvQ6YG5uFrotZd4cu_mG8mOuAzrpbd5982PEvFAZOpob5LofzCBHsCZtSFNRTK0n2v5mLHRvr1RE9m","https://scholar.google.com/scholar?cites=16762603239614667621&as_sdt=2005&sciodt=0,5&hl=en",51,"2020-11-06 21:29:44","PDF","","","",,,,,64,10.67,21,3,6,"We present a wearable input system which enables interaction through 3D handwriting recognition. Users can write text in the air as if they were using an imaginary blackboard. The handwriting gestures are captured wirelessly by motion sensors applying …"
53,"C Herff, T Schultz","Automatic speech recognition from neural signals: a focused review",2016,"Frontiers in neuroscience","frontiersin.org","https://www.frontiersin.org/articles/10.3389/fnins.2016.00429/full","https://scholar.google.com/scholar?cites=12832997340442672845&as_sdt=2005&sciodt=0,5&hl=en",52,"2020-11-06 21:29:44","HTML","","","",,,,,53,13.25,27,2,4,"Speech interfaces have become widely accepted and are nowadays integrated in various real-life applications and devices. They have become a part of our daily life. However, speech interfaces presume the ability to produce intelligible speech, which might be …"
60,"T Schultz, A Waibel, M Bett, F Metze, Y Pan…","The ISL meeting room system",2001,"Proceedings of the …","cs.cmu.edu","http://www.cs.cmu.edu/afs/.cs.cmu.edu/Web/People/fmetze/interACT/Publications_files/publications/hsc01_tanja.pdf","https://scholar.google.com/scholar?cites=15048159615106281655&as_sdt=2005&sciodt=0,5&hl=en",53,"2020-11-06 21:29:44","PDF","","","",,,,,60,3.16,10,6,19,"Oral communication is transient but many important decisions, social contracts and fact findings are first carried out in an oral setup, documented in written form and later retrieved. At Carnegie Mellons University's Interactive Systems Laboratories we have been …"
60,"T Schultz, AW Black, S Badaskar…","Spice: Web-based tools for rapid language adaptation in speech processing systems",2007,"… Annual Conference of …","isca-speech.org","https://www.isca-speech.org/archive/archive_papers/interspeech_2007/i07_2125.pdf","https://scholar.google.com/scholar?cites=11730213702230485272&as_sdt=2005&sciodt=0,5&hl=en",54,"2020-11-06 21:29:44","","","","",,,,,60,4.62,15,4,13,"In this paper we describe the design and implementation of a user interface for SPICE, a web-based toolkit for rapid prototyping of speech and language processing components. We report on the challenges and experiences gathered from testing these tools in an advanced …"
59,"K Laskowski, M Ostendorf, T Schultz","Modeling vocal interaction for text-independent participant characterization in multi-party conversation",2008,"… of the 9th SIGdial Workshop on …","aclweb.org","https://www.aclweb.org/anthology/W08-0124.pdf","https://scholar.google.com/scholar?cites=11275646661709169817&as_sdt=2005&sciodt=0,5&hl=en",55,"2020-11-06 21:29:44","PDF","","","",,,,,59,4.92,20,3,12,"An important task in automatic conversation understanding is the inference of social structure governing participant behavior. We explore the dependence between several social dimensions, including assigned role, gender, and seniority, and a set of low-level …"
59,"M Wand, T Schultz","Session-independent EMG-based Speech Recognition.",2011,"Biosignals","scitepress.org","https://scitepress.org/papers/2011/31697/31697.pdf","https://scholar.google.com/scholar?cites=3149605872696181578&as_sdt=2005&sciodt=0,5&hl=en",56,"2020-11-06 21:29:44","PDF","","","",,,,,59,6.56,30,2,9,"This paper reports on our recent research in speech recognition by surface electromyography (EMG), which is the technology of recording the electric activation potentials of the human articulatory muscles by surface electrodes in order to recognize …"
64,"T Schultz","Speaker characteristics",2007,"Speaker classification I","Springer","https://link.springer.com/chapter/10.1007/978-3-540-74200-5_3","https://scholar.google.com/scholar?cites=1276251146535175427&as_sdt=2005&sciodt=0,5&hl=en",57,"2020-11-06 21:29:44","","","","",,,,,64,4.92,64,1,13,"In this chapter, we give a brief introduction to speech-driven applications in order to motivate why it is desirable to automatically recognize particular speaker characteristics from speech. Starting from these applications, we derive what kind of characteristics might be useful. After …"
57,"M Honal, T Schultz","Correction of disfluencies in spontaneous speech using a noisy-channel approach",2003,"Eighth European Conference on Speech …","isca-speech.org","https://www.isca-speech.org/archive/eurospeech_2003/e03_2781.html","https://scholar.google.com/scholar?cites=7297432120670759861&as_sdt=2005&sciodt=0,5&hl=en",58,"2020-11-06 21:29:44","","","","",,,,,57,3.35,29,2,17,"In this paper we present a system which automatically corrects disfluencies such as repairs and restarts typically occurring in spontaneously spoken speech. The system is based on a noisy-channel model and its development requires no linguistic knowledge, but only …"
56,"T Schultz, M Westphal, A Waibel","The globalphone project: Multilingual lvcsr with janus-3",1997,"Multilingual Information Retrieval …","Citeseer","http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.153.3278&rep=rep1&type=pdf","https://scholar.google.com/scholar?cites=3415231411735143936&as_sdt=2005&sciodt=0,5&hl=en",59,"2020-11-06 21:29:44","PDF","","","",,,,,56,2.43,19,3,23,"This paper describes our recent effort in developing the Global-Phone database for multilingual large vocabulary continuous speech recognition. In particular we present the current status of the GlobalPhone corpus containing high quality speech data for the 9 …"
56,"M Honal, T Schultz","Automatic disfluency removal on recognized spontaneous speech-rapid adaptation to speaker-dependent disfluencies",2005,"Proceedings.(ICASSP'05). IEEE …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/1415277/?casa_token=KfDGwPZ6KZEAAAAA:E5sXHDTX5LQxxk7ubpnxJ2JcYed0pN46H45ddKkyFRH63XuwfwigXLlVJu0gLqqJhAj5gN3ryg","https://scholar.google.com/scholar?cites=10930174610154814715&as_sdt=2005&sciodt=0,5&hl=en",60,"2020-11-06 21:29:44","","","","",,,,,56,3.73,28,2,15,"In this paper, we investigate methods to adapt a system for disfluency removal to different data properties. A gradient descent algorithm for parameter optimization is presented which achieves 85.1% recall and 93.1% precision on the English Verbmobil corpus and 53.0 …"
57,"NT Vu, F Metze, T Schultz","Multilingual bottle-neck features and its application for under-resourced languages",2012,"Spoken Language Technologies for …","isca-speech.org","https://www.isca-speech.org/archive/sltu_2012/su12_090.html","https://scholar.google.com/scholar?cites=111561338781378956&as_sdt=2005&sciodt=0,5&hl=en",61,"2020-11-06 21:29:44","","","","",,,,,57,7.13,19,3,8,"In this paper we present our latest investigation on multilingual bottle-neck (BN) features and its application to rapid language adaptation to new languages. We show that the overall performance of a Multilayer Perceptron (MLP) network improves significantly by initializing it …"
58,"F Putze, JP Jarvis, T Schultz","Multimodal recognition of cognitive workload for multitasking in the car",2010,"2010 20th International …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/5597574/?casa_token=O_9ULRkVKdcAAAAA:C-0kci488A74tyv8_lqS3eppl6a-zXwdzwkxGRSKqvGYdwoaf6OLVUAh-56yyXsK7vFCWfu18Q","https://scholar.google.com/scholar?cites=14383439022503029780&as_sdt=2005&sciodt=0,5&hl=en",62,"2020-11-06 21:29:44","","","","",,,,,58,5.80,19,3,10,"This work describes the development and evaluation of a recognizer for different levels of cognitive workload in the car. We collected multiple biosignal streams (skin conductance, pulse, respiration, EEG) during an experiment in a driving simulator in which the drivers …"
59,"C Amma, D Gehrig, T Schultz","Airwriting recognition using wearable motion sensors",2010,"Proceedings of the 1st Augmented …","dl.acm.org","https://dl.acm.org/doi/abs/10.1145/1785455.1785465","https://scholar.google.com/scholar?cites=13697517035947136307&as_sdt=2005&sciodt=0,5&hl=en",63,"2020-11-06 21:29:44","","","","",,,,,59,5.90,20,3,10,"In this work we present a wearable input device which enables the user to input text into a computer. The text is written into the air via character gestures, like using an imaginary blackboard. To allow hands-free operation, we designed and implemented a data glove …"
55,"J Kominek, T Schultz, AW Black","Synthesizer voice quality of new languages calibrated with mean mel cepstral distortion",2008,"Spoken Languages Technologies …","isca-speech.org","https://www.isca-speech.org/archive/SLTU_2008/su08_063.html","https://scholar.google.com/scholar?cites=9370062780648397557&as_sdt=2005&sciodt=0,5&hl=en",64,"2020-11-06 21:29:44","","","","",,,,,55,4.58,18,3,12,"When developing synthesizers for new languages one must select a phoneset, record phonetically balanced sentences, build up a pronunciation lexicon, and evaluate the results. An objective measure of voice quality can be very useful, provided it is calibrated across …"
57,"C Herff, D Heger, F Putze, J Hennrich…","Classification of mental tasks in the prefrontal cortex using fNIRS",2013,"2013 35th Annual …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/6609962/?casa_token=1hGB49SRKPgAAAAA:-SSjyQZSVznNrWttBro8trt0Xakgcg2ptwjqUKgDSQwqhmp_H4z0x7fxW3leZ-u1WBEZIKa71w","https://scholar.google.com/scholar?cites=4758065926014466870&as_sdt=2005&sciodt=0,5&hl=en",65,"2020-11-06 21:29:44","","","","",,,,,57,8.14,11,5,7,"Functional near infrared spectroscopy (fNIRS) is rapidly gaining interest in both the Neuroscience, as well as the Brain-Computer-Interface (BCI) community. Despite these efforts, most single-trial analysis of fNIRS data is focused on motor-imagery, or mental …"
50,"S Stüker, T Schultz","A grapheme based speech recognition system for Russian",2004,"9th Conference Speech and Computer","isca-speech.org","https://www.isca-speech.org/archive_open/specom_04/spc4_297.html","https://scholar.google.com/scholar?cites=4692423511074641480&as_sdt=2005&sciodt=0,5&hl=en",66,"2020-11-06 21:29:44","","","","",,,,,50,3.13,25,2,16,"With the increasing availability and deployment of speech recognition technology in real world environments fast and affordable adaptation of speech recognition systems to new languages and/or domains becomes more and more important. One of the most expensive …"
50,"D Gehrig, H Kuehne, A Woerner…","Hmm-based human motion recognition with optical flow data",2009,"2009 9th IEEE-RAS …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/5379546/?casa_token=wcFPAd9mMIIAAAAA:bjAbF-hpHs7_rWGUpzJEsRaIDAEa8ruyCrEPsSOb1PoGdcsgFBUlARBiAJwxjMvm2pG2_MzXZA","https://scholar.google.com/scholar?cites=4210431834764133662&as_sdt=2005&sciodt=0,5&hl=en",67,"2020-11-06 21:29:44","","","","",,,,,50,4.55,13,4,11,"Human motion recognition is traditionally approached by either recognizing basic motions from features derived from video input or by interpreting complex motions by applying a high-level hierarchy of motion primitives. The former method is usually limited to rather simple …"
50,"SC Jou, T Schultz, A Waibel","Whispery speech recognition using adapted articulatory features",2005,"Proceedings.(ICASSP'05). IEEE …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/1415287/?casa_token=YfA4TtKblvkAAAAA:YMSi41svHjKS-UQl_jZ0pRAmSl9bUyg9ui71SUHXR2jkgcuog8fVxl2eVSCX43-NWegkFffHiw","https://scholar.google.com/scholar?cites=15722615271629349975&as_sdt=2005&sciodt=0,5&hl=en",68,"2020-11-06 21:29:44","","","","",,,,,50,3.33,17,3,15,"This paper describes our research on adaptation methods applied to articulatory feature detection on soft whispery speech recorded with a throat microphone. Since the amount of adaptation data is small and the testing data is very different from the training data, a series …"
49,"YC Tam, I Lane, T Schultz","Bilingual LSA-based adaptation for statistical machine translation",2007,"Machine translation","Springer","https://idp.springer.com/authorize/casa?redirect_uri=https://link.springer.com/content/pdf/10.1007/s10590-008-9045-2.pdf&casa_token=EmzdEJiNO4IAAAAA:mmvYB9fxnX_-rHm01PJ15qVP6dnVciPlphmAVtnunc4DBmp5415t_ikm6r2clCVWNmFwYBsKer870WaZ","https://scholar.google.com/scholar?cites=4354438444614841241&as_sdt=2005&sciodt=0,5&hl=en",69,"2020-11-06 21:29:44","PDF","","","",,,,,49,3.77,16,3,13,"We propose a novel approach to cross-lingual language model and translation lexicon adaptation for statistical machine translation (SMT) based on bilingual latent semantic analysis. Bilingual LSA enables latent topic distributions to be efficiently transferred across …"
51,"P Fung, T Schultz","Multilingual spoken language processing",2008,"IEEE Signal Processing Magazine","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/4490205/?casa_token=Q5sngzh6bTEAAAAA:SBEGzC5H51ICnUGH8Z8dPaAlJIW8WNQ1qo1VVURXWipnW3jCKafkfH1NVGakWc8gSUXtPIByZg","https://scholar.google.com/scholar?cites=206500093170320613&as_sdt=2005&sciodt=0,5&hl=en",70,"2020-11-06 21:29:44","","","","",,,,,51,4.25,26,2,12,"In the past decade, the performance of spoken language understanding systems has improved dramatically, including speech recognition, dialog systems, speech summarization, and text and speech translation. This has resulted in an increasingly …"
49,"T Schultz, SC Jou, S Vogel…","Using word latice information for a tighter coupling in speech translation systems",2004,"… Conference on Spoken …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2004/i04_0041.html","https://scholar.google.com/scholar?cites=2251337896910395250&as_sdt=2005&sciodt=0,5&hl=en",71,"2020-11-06 21:29:44","","","","",,,,,49,3.06,12,4,16,"In this paper we present first experiments towards a tighter coupling between Automatic Speech Recognition (ASR) and Statistical Machine Translation (SMT) to improve the overall performance of our speech translation system. In coventional speech translation systems …"
53,"H Adel, NT Vu, K Kirchhoff, D Telaar…","Syntactic and semantic features for code-switching factored language models",2015,"… /ACM transactions on …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/7005440/?casa_token=nLC1uGTXiHcAAAAA:UUkQ3DaOwRcuANDpSeUDZUGsZxzcJdERrWj2k36NlLL0cnIOj1RbLFGBf-wa7nL4jk1q-UuXsQ","https://scholar.google.com/scholar?cites=13121620269248032344&as_sdt=2005&sciodt=0,5&hl=en",72,"2020-11-06 21:29:44","","","","",,,,,53,10.60,11,5,5,"This paper presents our latest investigations on different features for factored language models for Code-Switching speech and their effect on automatic speech recognition (ASR) performance. We focus on syntactic and semantic features which can be extracted from …"
45,"Z Wang, U Topkara, T Schultz…","Towards universal speech recognition",2002,"Proceedings. Fourth IEEE …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/1167001/?casa_token=MJKPeM0ZBuMAAAAA:9_B6F91Cbnbssaw7y0ElJoDoydLeGLb-FIih6mQeKqMN6T4lrQ7QKZbLcT_hxncNn6duXXPv6Q","https://scholar.google.com/scholar?cites=7234431987407550517&as_sdt=2005&sciodt=0,5&hl=en",73,"2020-11-06 21:29:44","","","","",,,,,45,2.50,11,4,18,"The increasing interest in multilingual applications like speech-to-speech translation systems is accompanied by the need for speech recognition front-ends in many languages that can also handle multiple input languages at the same time. We describe a universal …"
44,"D Heger, F Putze, T Schultz","Online workload recognition from EEG data during cognitive tests and human-machine interaction",2010,"Annual Conference on Artificial Intelligence","Springer","https://link.springer.com/chapter/10.1007/978-3-642-16111-7_47","https://scholar.google.com/scholar?cites=8188602703225118652&as_sdt=2005&sciodt=0,5&hl=en",74,"2020-11-06 21:29:44","","","","",,,,,44,4.40,15,3,10,"This paper presents a system for live recognition of mental workload using spectral features from EEG data classified by Support Vector Machines. Recognition rates of more than 90% could be reached for five subjects performing two different cognitive tasks according to the …"
45,"M Wand, C Schulte, M Janke, T Schultz","Array-based Electromyographic Silent Speech Interface.",2013,"Biosignals","scitepress.org","https://www.scitepress.org/Papers/2013/42524/42524.pdf","https://scholar.google.com/scholar?cites=15319723350582299294&as_sdt=2005&sciodt=0,5&hl=en",75,"2020-11-06 21:29:44","PDF","","","",,,,,45,6.43,11,4,7,"An electromygraphic (EMG) Silent Speech Interface is a system which recognizes speech by capturing the electric potentials of the human articulatory muscles, thus enabling the user to communicate silently. This study is concerned with introducing an EMG recording system …"
42,"NT Vu, F Kraus, T Schultz","Cross-language bootstrapping based on completely unsupervised training using multilingual A-stabil",2011,"2011 IEEE International …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/5947479/?casa_token=GCqhbWnlu6sAAAAA:Joffl2ekJp-elBugw1OsmRiu_dcl1KrOGg2iHt3GxdoPV0CiJ8jTjtBcH-bV8_WtlXkfX8psLA","https://scholar.google.com/scholar?cites=6097628769967023575&as_sdt=2005&sciodt=0,5&hl=en",76,"2020-11-06 21:29:44","","","","",,,,,42,4.67,14,3,9,"This paper presents our work on rapid language adaptation of acoustic models based on multilingual cross-language bootstrapping and unsupervised training. We used Automatic Speech Recognition (ASR) systems in English, French, German, and Spanish to build a …"
42,"Q Jin, SCS Jou, T Schultz","Whispering speaker identification",2007,"2007 IEEE international conference …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/4284828/?casa_token=NdUDGQM-n6wAAAAA:VAk6FmVRoFNDvtRM9grdK3RjjmRXJVjTiPfv1jA_lKuWccobLRPHnQopr0L-xCWSgGukdSAn9A","https://scholar.google.com/scholar?cites=11354744136666847469&as_sdt=2005&sciodt=0,5&hl=en",77,"2020-11-06 21:29:44","","","","",,,,,42,3.23,14,3,13,"This paper describes a study of automatically identifying whispering speakers. People usually whisper in order to avoid being identified or overheard by lowering their voices. The study compares performances between normal and whispered speech mode in clean and …"
41,"K Laskowski, Q Jin, T Schultz","Crosscorrelation-based multispeaker speech activity detection",2004,"Eighth International Conference on …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2004/i04_0973.html","https://scholar.google.com/scholar?cites=17837721412175568924&as_sdt=2005&sciodt=0,5&hl=en",78,"2020-11-06 21:29:44","","","","",,,,,41,2.56,14,3,16,"We propose an algorithm for segmenting multispeaker meeting audio, recorded with personal channel microphones, into speech and non-speech intervals for each microphone's wearer. An algorithm of this type turns out to be necessary prior to subsequent …"
43,"A Schick, D Morlock, C Amma, T Schultz…","Vision-based handwriting recognition for unrestricted text input in mid-air",2012,"Proceedings of the 14th …","dl.acm.org","https://dl.acm.org/doi/abs/10.1145/2388676.2388719","https://scholar.google.com/scholar?cites=15387368273080722707&as_sdt=2005&sciodt=0,5&hl=en",79,"2020-11-06 21:29:44","","","","",,,,,43,5.38,9,5,8,"We propose a vision-based system that recognizes handwriting in mid-air. The system does not depend on sensors or markers attached to the users and allows unrestricted character and word input from any position. It is the result of combining handwriting recognition based …"
40,"H Yu, T Schultz","Enhanced tree clustering with single pronunciation dictionary for conversational speech recognition",2003,"Eighth European Conference on Speech …","isca-speech.org","https://www.isca-speech.org/archive/eurospeech_2003/e03_1869.html","https://scholar.google.com/scholar?cites=18404272884526673436&as_sdt=2005&sciodt=0,5&hl=en",80,"2020-11-06 21:29:44","","","","",,,,,40,2.35,20,2,17,"Modeling pronunciation variation is key for recognizing conversational speech. Rather than being limited to dictionary modeling, we argue that triphone clustering is an integral part of pronunciation modeling. We propose a new approach called enhanced tree clustering. This …"
41,"A Waibel, H Soltau, T Schultz, T Schaaf…","Multilingual speech recognition",2000,"Verbmobil: Foundations of …","Springer","https://link.springer.com/chapter/10.1007/978-3-662-04230-4_3","https://scholar.google.com/scholar?cites=6671689966679156505&as_sdt=2005&sciodt=0,5&hl=en",81,"2020-11-06 21:29:44","","","","",,,,,41,2.05,8,5,20,"The speech-to-speech translation system Verbmobil requires a multilingual setting. This consists of recognition engines in the three languages German, English and Japanese that run in one common framework together with a language identification component which is …"
43,"SC Jou, L Maier-Hein, T Schultz…","Articulatory feature classification using surface electromyography",2006,"2006 IEEE International …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/1660093/?casa_token=tLzW0P-7jGUAAAAA:tA6qreAjVvMLtdcFW6jIOtZnLsFAe7qgN9WYrGt3mZAzHv3lscr58yj6-6od6_v81tztb8MQvw","https://scholar.google.com/scholar?cites=9252332058455390545&as_sdt=2005&sciodt=0,5&hl=en",82,"2020-11-06 21:29:44","","","","",,,,,43,3.07,11,4,14,"In this paper, we present an approach for articulatory feature classification based on surface electromyographic signals generated by the facial muscles. With parallel recorded audible speech and electromyographic signals, experiments are conducted to show the anticipatory …"
42,"J Weiner, NT Vu, D Telaar, F Metze…","Integration of language identification into a recognition system for spoken conversations containing code-switches",2012,"… for Under-Resourced …","isca-speech.org","https://www.isca-speech.org/archive/sltu_2012/su12_076.html","https://scholar.google.com/scholar?cites=6064299181460802557&as_sdt=2005&sciodt=0,5&hl=en",83,"2020-11-06 21:29:44","","","","",,,,,42,5.25,8,5,8,"This paper describes the integration of language identification (LID) into a multilingual automatic speech recognition (ASR) system for spoken conversations containing code-switches between Mandarin and English. We apply a multistream approach to combine at …"
40,"YC Tam, T Schultz","Correlated latent semantic model for unsupervised LM adaptation",2007,"… Speech and Signal Processing-ICASSP'07","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/4218032/?casa_token=mkhUxBOpxPAAAAAA:1b4_iuDCbjgGOUZ4FvapRU65wEnI6t2aA5qEaWuTl4dheNSN0104b90Ys5ZcxPiptjTTX2jmNQ","https://scholar.google.com/scholar?cites=14740287764364535942&as_sdt=2005&sciodt=0,5&hl=en",84,"2020-11-06 21:29:44","","","","",,,,,40,3.08,20,2,13,"We propose a latent Dirichlet-tree allocation (LDTA) model-a correlated latent semantic model-for unsupervised language model adaptation. The LDTA model extends the latent Dirichlet allocation (LDA) model by replacing a Dirichlet prior with a Dirichlet-tree prior over …"
40,"T Schultz, Q Jin, K Laskowski, Y Pan…","Issues in meeting transcription-the ISL meeting transcription system",2004,"… on Spoken Language …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2004/i04_1709.html","https://scholar.google.com/scholar?cites=18341308295745591957&as_sdt=2005&sciodt=0,5&hl=en",85,"2020-11-06 21:29:44","","","","",,,,,40,2.50,8,5,16,"This paper describes the Interactive Systems Lab's Meeting transcription system, which performs segmentation, speaker clustering as well as transcriptions of conversational meeting speech. The system described here was evaluated in NIST's RT-04S “Meeting” …"
39,"L Lamel, S Courcinous, J Despres…","Speech recognition for machine translation in Quaero",2011,"… Workshop on Spoken …","isca-speech.org","https://www.isca-speech.org/archive/iwslt_11/sltb_121.html","https://scholar.google.com/scholar?cites=14259869860121506165&as_sdt=2005&sciodt=0,5&hl=en",86,"2020-11-06 21:29:44","","","","",,,,,39,4.33,10,4,9,"This paper describes the speech-to-text systems used to provide automatic transcriptions used in the Quaero 2010 evaluation of Machine Translation from speech. Quaero (www. quaero. org) is a large research and industrial innovation program focusing on technologies …"
40,"A von Lühmann, C Herff, D Heger…","Toward a wireless open source instrument: functional near-infrared spectroscopy in mobile neuroergonomics and BCI applications",2015,"Frontiers in human …","frontiersin.org","https://www.frontiersin.org/articles/10.3389/fnhum.2015.00617/full","https://scholar.google.com/scholar?cites=11757311103512941592&as_sdt=2005&sciodt=0,5&hl=en",87,"2020-11-06 21:29:44","HTML","","","",,,,,40,8.00,10,4,5,"Brain-Computer Interfaces (BCIs) and neuroergonomics research have high requirements regarding robustness and mobility. Additionally, fast applicability and customization are desired. Functional Near-Infrared Spectroscopy (fNIRS) is an increasingly established …"
42,"J Hennrich, C Herff, D Heger…","Investigating deep learning for fNIRS based BCI",2015,"2015 37th Annual …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/7318984/?casa_token=DcQiLyX6CccAAAAA:Zga4sZ9yZyQvgToyee8us2vQF-r076bK-0Dz7IggTxMSAgZTDwLlbyNZcHIrQEan8ZkVNu7Jqg","https://scholar.google.com/scholar?cites=10924773064077643642&as_sdt=2005&sciodt=0,5&hl=en",88,"2020-11-06 21:29:44","","","","",,,,,42,8.40,11,4,5,"Functional Near infrared Spectroscopy (fNIRS) is a relatively young modality for measuring brain activity which has recently shown promising results for building Brain Computer Interfaces (BCI). Due to its infancy, there are still no standard approaches for meaningful …"
38,"H Li, B Ma, KA Lee, H Sun, D Zhu…","The I4U system in NIST 2008 speaker recognition evaluation",2009,"… , Speech and Signal …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/4960555/?casa_token=amfVagB_8lgAAAAA:vZbnngJjNBzhQ4irkR8pph6MLXUrZCTB4qHPknQYNp8JaIDXokXDt_La0YEGFsr-gv_uT1Y6Ag","https://scholar.google.com/scholar?cites=9721877334512365363&as_sdt=2005&sciodt=0,5&hl=en",89,"2020-11-06 21:29:44","","","","",,,,,38,3.45,6,6,11,"This paper describes the performance of the I4U speaker recognition system in the NIST 2008 Speaker Recognition Evaluation. The system consists of seven subsystems, each with different cepstral features and classifiers. We describe the I4U Primary system and report on …"
37,"M Paulik, S Stuker, C Fugen, T Schultz…","Speech translation enhanced automatic speech recognition",2005,"IEEE Workshop on …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/1566488/?casa_token=BhSjbt6uH2kAAAAA:QMDgeUetal0yj7J_PTAVtTsg13-AE37sfC7wUWvtof3-lDtaQkZfhQD6cdpp7w9KZLfCpE2Itw","https://scholar.google.com/scholar?cites=4891278695821687577&as_sdt=2005&sciodt=0,5&hl=en",90,"2020-11-06 21:29:44","","","","",,,,,37,2.47,7,5,15,"Nowadays official documents have to be made available in many languages, like for example in the EU with its 20 official languages. Therefore, the need for effective tools to aid the multitude of human translators in their work becomes easily apparent. An ASR system …"
37,"B Suhm, P Geutner, T Kemp, A Lavie, L Mayfield…","JANUS: Towards multilingual spoken language translation",1995,"","Citeseer","http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.43.9604","https://scholar.google.com/scholar?cites=1524365747155270759&as_sdt=2005&sciodt=0,5&hl=en",91,"2020-11-06 21:29:44","","","","",,,,,37,1.48,6,6,25,"In our effort to build spoken language translation systems we have extended our JANUS system to process spontaneoushuman--human dialogs in a new domain, two people trying to schedule a meeting. Trained on an initial database JANUS-2 is able to translate English …"
37,"T Schlippe, S Ochs, T Schultz","Grapheme-to-phoneme model generation for Indo-European languages",2012,"2012 IEEE International …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/6288993/?casa_token=o6b5GzWEoQUAAAAA:LLVK5LoAfoSK5Sm2EsrW_EqMH_rQGjieNlJZ_epvgkWgEM4OqkFqVQO0BStKTVickRyPon4w8A","https://scholar.google.com/scholar?cites=15247768542799458266&as_sdt=2005&sciodt=0,5&hl=en",92,"2020-11-06 21:29:44","","","","",,,,,37,4.63,12,3,8,"In this paper, we evaluate grapheme-to-phoneme (g2p) models among languages and of different quality. We created g2p models for Indo-European languages with word-pronunciation pairs from the GlobalPhone project and from Wiktionary [1]. Then we checked …"
37,"M Paulik, C Fügen, S Stüker, T Schultz…","Document driven machine translation enhanced ASR",2005,"Ninth European …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2005/i05_2261.html","https://scholar.google.com/scholar?cites=7209783574745537527&as_sdt=2005&sciodt=0,5&hl=en",93,"2020-11-06 21:29:44","","","","",,,,,37,2.47,7,5,15,"In human-mediated translation scenarios a human interpreter translates between a source and a target language using either a spoken or a written representation of the source language. In this paper we improve the recognition performance on the speech of the …"
37,"Q Jin, AR Toth, T Schultz…","Voice convergin: Speaker de-identification by voice transformation",2009,"2009 IEEE International …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/4960482/?casa_token=5lf2Rlg-RnMAAAAA:PZwgBYw57_rid6Dj87vtZajLxIeovPguwaHne4JtFYOUDCU8ml8wa52zwHKmPTdOBJcc15X8Bw","https://scholar.google.com/scholar?cites=1726029727141918189&as_sdt=2005&sciodt=0,5&hl=en",94,"2020-11-06 21:29:44","","","","",,,,,37,3.36,9,4,11,"Speaker identification might be a suitable answer to prevent unauthorized access to personal data. However we also need to provide solutions to secure transmission of spoken information. This challenge divides into two major aspects. First, the secure transmission of …"
38,"NT Vu, F Kraus, T Schultz","Rapid building of an ASR system for Under-Resourced Languages based on Multilingual Unsupervised Training",2011,"Twelfth Annual Conference of the …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2011/i11_3145.html","https://scholar.google.com/scholar?cites=8357213282841031772&as_sdt=2005&sciodt=0,5&hl=en",95,"2020-11-06 21:29:44","","","","",,,,,38,4.22,13,3,9,"This paper presents our work on rapid language adaptation of acoustic models based on multilingual cross-language bootstrapping and unsupervised training. We used Automatic Speech Recognition (ASR) systems in the six source languages English, French, German …"
33,"J Weiner, C Herff, T Schultz","Speech-Based Detection of Alzheimer's Disease in Conversational German.",2016,"INTERSPEECH","pdfs.semanticscholar.org","https://pdfs.semanticscholar.org/2d9d/fb9211bc9b955707b5e0d4e5258dd1fb8698.pdf","https://scholar.google.com/scholar?cites=17289183916928501352&as_sdt=2005&sciodt=0,5&hl=en",96,"2020-11-06 21:29:44","PDF","","","",,,,,33,8.25,11,3,4,"The worldwide population is aging. With a larger population of elderly people, the numbers of people affected by cognitive impairment such as Alzheimer's disease are growing. Unfortunately, there is no known cure for Alzheimer's disease. The only way to alleviate it's …"
36,"NT Vu, T Schlippe, F Kraus, T Schultz","Rapid bootstrapping of five eastern european languages using the rapid language adaptation toolkit",2010,"… Annual Conference of the …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2010/i10_0865.html","https://scholar.google.com/scholar?cites=10426553813853611521&as_sdt=2005&sciodt=0,5&hl=en",97,"2020-11-06 21:29:44","","","","",,,,,36,3.60,9,4,10,"This paper presents our latest efforts toward LVCSR systems for five Eastern European languages such as Bulgarian, Croatian, Czech, Polish, and Russian using our Rapid Language Adaptation Toolkit (RLAT)[1]. We investigated the possibility of crawling large …"
36,"N Bach, M Eck, P Charoenpornsawat…","The CMU TransTac 2007 eyes-free and hands-free two-way speech-to-speech translation system",2007,"… of the IWSLT","isl.anthropomatik.kit.edu","http://isl.anthropomatik.kit.edu/pdf/Bach2007.pdf","https://scholar.google.com/scholar?cites=18431046142730759870&as_sdt=2005&sciodt=0,5&hl=en",98,"2020-11-06 21:29:44","PDF","","","",,,,,36,2.77,9,4,13,"The paper describes our portable two-way speech-tospeech translation system using a completely eyesfree/hands-free user interface. This system translates between the language pair English and Iraqi Arabic as well as between English and Farsi, and was built within the …"
40,"M Wand, M Janke, T Schultz","Tackling speaking mode varieties in EMG-based speech recognition",2014,"IEEE Transactions on …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/6802380/?casa_token=Q6jmWHC5KKoAAAAA:vJDnGq7tTm5wDrefn_Ma-938svhShACb_S-czA9YDtfZeSyqRk5QD7IAG07qxeYXw9PkLw1vwg","https://scholar.google.com/scholar?cites=399554748112941869&as_sdt=2005&sciodt=0,5&hl=en",99,"2020-11-06 21:29:44","","","","",,,,,40,6.67,13,3,6,"An electromyographic (EMG) silent speech recognizer is a system that recognizes speech by capturing the electric potentials of the human articulatory muscles, thus enabling the user to communicate silently. After having established a baseline EMG-based continuous speech …"
35,"D Kiecza, T Schultz, A Waibel","Data-driven determination of appropriate dictionary units for Korean LVCSR",1999,"Proceedings of ICASSP","Citeseer","https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.43.1815&rep=rep1&type=pdf","https://scholar.google.com/scholar?cites=1047682752705023725&as_sdt=2005&sciodt=0,5&hl=en",100,"2020-11-06 21:29:44","PDF","","","",,,,,35,1.67,12,3,21,"This paper describes the design of our Korean large vocabulary speech recognition system using the multilingual dictation database GlobalPhone. Defining appropriate dictionary units for this purpose is not a trivial task since using word phrases (eojeols) gives very high OOV …"
36,"A Waibel, H Yu, T Schultz, Y Pan, M Bett…","Advances in meeting recognition",2001,"Proceedings of the first …","aclweb.org","https://www.aclweb.org/anthology/H01-1003.pdf","https://scholar.google.com/scholar?cites=2470928353701384893&as_sdt=2005&sciodt=0,5&hl=en",101,"2020-11-06 21:29:44","PDF","","","",,,,,36,1.89,6,6,19,"Speech recognition has advanced considerably, but has been limited almost entirely either to situations in which close speaking microphones are natural and acceptable (telephone, dictation, command&control, etc.) or in which high-quality recordings are ensured …"
34,"D Dahlmeier, HT Ng, T Schultz","Joint learning of preposition senses and semantic roles of prepositional phrases",2009,"Proceedings of the 2009 Conference on …","aclweb.org","https://www.aclweb.org/anthology/D09-1047.pdf","https://scholar.google.com/scholar?cites=16268700575362411457&as_sdt=2005&sciodt=0,5&hl=en",102,"2020-11-06 21:29:44","PDF","","","",,,,,34,3.09,11,3,11,"The sense of a preposition is related to the semantics of its dominating prepositional phrase. Knowing the sense of a preposition could help to correctly classify the semantic role of the dominating prepositional phrase and vice versa. In this paper, we propose a joint …"
34,"T Schultz, I Rogina","Acoustic and language modeling of human and nonhuman noises for human-to-human spontaneous speech recognition",1995,"1995 International Conference on …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/479531/?casa_token=_X_RAi04tfoAAAAA:3ibTNYikBdh-8DULb24dpJgG_-kcInArKMSJznBsVUMfY_NgFZfl5AUnllTXBmVQHB24yQGlLQ","https://scholar.google.com/scholar?cites=12363991274027707792&as_sdt=2005&sciodt=0,5&hl=en",103,"2020-11-06 21:29:44","","","","",,,,,34,1.36,17,2,25,"Several improvements of our speech-to-speech translation system JANUS on spontaneous human-to-human dialogs are presented. Common phenomena in spontaneous speech are described, followed by a classification of different types of noise. To handle the variety of …"
35,"D Gehrig, P Krauthausen, L Rybok…","Combined intention, activity, and motion recognition for a humanoid household robot",2011,"2011 IEEE/RSJ …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/6095118/?casa_token=sTfRhU7CnvkAAAAA:VtHdfBMVC7jTLbIwTomQ1oVsck7bB9Z5L7hVDMIQySzomfU2HYcExoC790MYxiIqmpa6X8OVOA","https://scholar.google.com/scholar?cites=542183599964139059&as_sdt=2005&sciodt=0,5&hl=en",104,"2020-11-06 21:29:44","","","","",,,,,35,3.89,9,4,9,"In this paper, a multi-level approach to intention, activity, and motion recognition for a humanoid robot is proposed. Our system processes images from a monocular camera and combines this information with domain knowledge. The recognition works on-line and in real …"
35,"M Walliczek, F Kraft, SC Jou, T Schultz…","Sub-word unit based non-audible speech recognition using surface electromyography",2006,"… Conference on Spoken …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2006/i06_1596.html","https://scholar.google.com/scholar?cites=12687661583574271609&as_sdt=2005&sciodt=0,5&hl=en",105,"2020-11-06 21:29:44","","","","",,,,,35,2.50,7,5,14,"In this paper we present a novel approach for a surface electromyographic speech recognition system based on sub-word units. Rather than using full word models as integrated in our previous work we propose here smaller sub-word units as prerequisites for …"
34,"NT Vu, W Breiter, F Metze, T Schultz","An investigation on initialization schemes for multilayer perceptron training using multilingual data and their effect on ASR performance",2012,"","kilthub.cmu.edu","https://kilthub.cmu.edu/articles/An_Investigation_on_Initialization_Schemes_for_Multilayer_Perceptron_Training_Using_Multilingual_Data_and_Their_Effect_on_ASR_Performance/6473039/1","https://scholar.google.com/scholar?cites=3058672126659846510&as_sdt=2005&sciodt=0,5&hl=en",106,"2020-11-06 21:29:44","","","","",,,,,34,4.25,9,4,8,"In this paper we present our latest investigation on initialization schemes for Multilayer Perceptron (MLP) training using multilingual data. We show that the overall performance of an MLP network improves significantly by initializing it with a multilingual MLP. We propose …"
33,"K Laskowski, T Schultz","Unsupervised learning of overlapped speech model parameters for multichannel speech activity detection in meetings",2006,"2006 IEEE International Conference …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/1660190/?casa_token=Y4nbmmh0HJ8AAAAA:-H3T6Rsrv11Nk2zmIIjW7VEM5rZbUiO66BCyE3WiOAEY0UqPbBCAXFL20Zo5Wi3x6t2udQzFww","https://scholar.google.com/scholar?cites=4343688838856095629&as_sdt=2005&sciodt=0,5&hl=en",107,"2020-11-06 21:29:44","","","","",,,,,33,2.36,17,2,14,"The study of meetings, and multi-party conversation in general, is currently the focus of much attention, calling for more robust and more accurate speech activity detection systems. We present a novel multichannel speech activity detection algorithm, which explicitly models the …"
35,"T Schlippe, S Ochs, T Schultz","Wiktionary as a source for automatic pronunciation extraction",2010,"Eleventh Annual Conference of the …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2010/i10_2290.html","https://scholar.google.com/scholar?cites=7628048505520890401&as_sdt=2005&sciodt=0,5&hl=en",108,"2020-11-06 21:29:44","","","","",,,,,35,3.50,12,3,10,"In this paper, we analyze whether dictionaries from the World Wide Web which contain phonetic notations, may support the rapid creation of pronunciation dictionaries within the speech recognition and speech synthesis system building process. As a representative …"
34,"C Fugen, S Stuker, H Soltau, F Metze…","Efficient handling of multilingual language models",2003,"2003 IEEE Workshop …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/1318481/?casa_token=qacVtd2EzEcAAAAA:U4IuSP9fZPBI9KAaWwh0yKqG1BD1K2z3qpYgm-ERJPJUsX02mGxdJVyH_SwUYRfAvH5Aa-n3Zw","https://scholar.google.com/scholar?cites=3193624549598472089&as_sdt=2005&sciodt=0,5&hl=en",109,"2020-11-06 21:29:44","","","","",,,,,34,2.00,7,5,17,"We introduce techniques for building a multilingual speech recognizer. More specifically, we present a new language model method that allows for the combination of several monolingual into one multilingual language model. Furthermore, we extend our techniques …"
33,"S Suebvisai, P Charoenpornsawat…","Thai automatic speech recognition",2005,"… .(ICASSP'05). IEEE …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/1415249/?casa_token=OXzbO9GWTnsAAAAA:JhWjloh4lGwMiX0CRkyrPGmsQsWliAdPcmBAKxXiOzR8x3_HJpfIjL5RlsWGXB15ude9BpWBRA","https://scholar.google.com/scholar?cites=14322357806600716863&as_sdt=2005&sciodt=0,5&hl=en",110,"2020-11-06 21:29:44","","","","",,,,,33,2.20,11,3,15,"We describe the development of a robust and flexible Thai speech recognizer as integrated into our English-Thai speech-to-speech translation system. We focus on the discussion of the rapid deployment of ASR for Thai under limited time and data resources, including rapid …"
33,"NT Vu, F Kraus, T Schultz","Multilingual A-stabil: A new confidence score for multilingual unsupervised training",2010,"2010 IEEE Spoken Language …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/5700848/?casa_token=jmov5LMJBiQAAAAA:Cx7-30JeitCKOb2SA8EayZlylSe4UWQsr8-xLrs3RdkGc5XqujccCWZDIE7DvZV3ohOD0UHXIA","https://scholar.google.com/scholar?cites=3628143777066900115&as_sdt=2005&sciodt=0,5&hl=en",111,"2020-11-06 21:29:44","","","","",,,,,33,3.30,11,3,10,"This paper presents our work in Automatic Speech Recognition (ASR) in the context of multilingual unsupervised training with application to Czech. Starting without any transcribed acoustic training data we built a Czech ASR by combining cross-language bootstrapping …"
32,"VB Le, L Besacier, T Schultz","Acoustic-phonetic unit similarities for context dependent acoustic model portability",2006,"2006 IEEE International …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/1660217/?casa_token=PekLnDKBevYAAAAA:hPvdSSOheDBM1OfAiv-U4DjvH43wsQ1K7TbC5jWE0OZT-3JdHbSeBsE1XuVzD1oPnfRrVwKEnw","https://scholar.google.com/scholar?cites=9468583261263962152&as_sdt=2005&sciodt=0,5&hl=en",112,"2020-11-06 21:29:44","","","","",,,,,32,2.29,11,3,14,"This paper addresses particularly the use of acoustic-phonetic unit similarities for portability of context dependent acoustic models to new languages. Since the IPA-based method is limited to a source/target phoneme mapping table construction, an estimation method of the …"
32,"K Laskowski, T Schultz","Detection of laughter-in-interaction in multichannel close-talk microphone recordings of meetings",2008,"International Workshop on Machine Learning for …","Springer","https://link.springer.com/chapter/10.1007/978-3-540-85853-9_14","https://scholar.google.com/scholar?cites=12662307182309115383&as_sdt=2005&sciodt=0,5&hl=en",113,"2020-11-06 21:29:44","","","","",,,,,32,2.67,16,2,12,"Laughter is a key element of human-human interaction, occurring surprisingly frequently in multi-party conversation. In meetings, laughter accounts for almost 10% of vocalization effort by time, and is known to be relevant for topic segmentation and the automatic …"
31,"AR Toth, M Wand, T Schultz","Synthesizing speech from electromyography using voice transformation techniques",2009,"Tenth Annual Conference of the …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2009/i09_0652.html","https://scholar.google.com/scholar?cites=14494004543613947243&as_sdt=2005&sciodt=0,5&hl=en",114,"2020-11-06 21:29:44","","","","",,,,,31,2.82,10,3,11,"Surface electromyography (EMG) can be used to record the activation potentials of articulatory muscles while a person speaks. This technique could enable silent speech interfaces, as EMG signals are generated even when people pantomime speech without …"
30,"K Nakamura, M Janke, M Wand…","Estimation of fundamental frequency from surface electromyographic data: EMG-to-F0",2011,"2011 IEEE International …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/5946468/?casa_token=BQ0ZeH0e8KEAAAAA:OTKnTGco4GyBuzXkyP5pcvrmmUgeIM9S57Gjp2LR_XLdMXPwc_mXLi_7a2sdsJnKMEpFy1TNqA","https://scholar.google.com/scholar?cites=15328355793163871532&as_sdt=2005&sciodt=0,5&hl=en",115,"2020-11-06 21:29:44","","","","",,,,,30,3.33,8,4,9,"In this paper, we present our recent studies of F 0 estimation from the surface electromyographic (EMG) data us ing a Gaussian mixture model (GMM)-based voice con version (VC) technique, referred to as EMG-to-F 0. In our approach, a support vector …"
30,"Q Jin, T Schultz, A Waibel","Phonetic speaker identification",2002,"Seventh International Conference on …","isca-speech.org","https://www.isca-speech.org/archive/icslp_2002/i02_1345.html","https://scholar.google.com/scholar?cites=3198774752780326314&as_sdt=2005&sciodt=0,5&hl=en",116,"2020-11-06 21:29:44","","","","",,,,,30,1.67,10,3,18,"This paper describes the exploration of text-independent speaker identification using novel approaches based on speakers' phonetic features instead of traditional acoustic features. Different phonetic speaker identification approaches are discussed in this paper and …"
30,"M Wand, T Schultz","Towards Speaker-adaptive Speech Recognition based on Surface Electromyography.",2009,"Biosignals","researchgate.net","https://www.researchgate.net/profile/Tanja_Schultz/publication/221333944_Towards_Speaker-adaptive_Speech_Recognition_based_on_Surface_Electromyography/links/547836780cf293e2da286147/Towards-Speaker-adaptive-Speech-Recognition-based-on-Surface-Electromyography.pdf","https://scholar.google.com/scholar?cites=5543332975650804143&as_sdt=2005&sciodt=0,5&hl=en",117,"2020-11-06 21:29:44","PDF","","","",,,,,30,2.73,15,2,11,"We present our recent advances in silent speech interfaces using electromyographic signals that capture the movements of the human articulatory muscles at the skin surface for recognizing continuously spoken speech. Previous systems were limited to speaker-and …"
30,"YC Tam, I Lane, T Schultz","Bilingual-LSA based LM adaptation for spoken language translation",2007,"Proceedings of the 45th Annual Meeting of …","aclweb.org","https://www.aclweb.org/anthology/P07-1066.pdf","https://scholar.google.com/scholar?cites=8688368713783050947&as_sdt=2005&sciodt=0,5&hl=en",118,"2020-11-06 21:29:44","PDF","","","",,,,,30,2.31,10,3,13,"We propose a novel approach to crosslingual language model (LM) adaptation based on bilingual Latent Semantic Analysis (bLSA). A bLSA model is introduced which enables latent topic distributions to be efficiently transferred across languages by enforcing a one-to-one …"
22,"J Weiner, M Engelbart, T Schultz","Manual and Automatic Transcriptions in Dementia Detection from Speech.",2017,"INTERSPEECH","isca-speech.org","https://www.isca-speech.org/archive/Interspeech_2017/pdfs/0112.PDF","https://scholar.google.com/scholar?cites=6426090556107777586&as_sdt=2005&sciodt=0,5&hl=en",119,"2020-11-06 21:29:44","","","","",,,,,22,7.33,7,3,3,"As the population in developed countries is aging, larger numbers of people are at risk of developing dementia. In the near future there will be a need for time-and cost-efficient screening methods. Speech can be recorded and analyzed in this manner, and as speech …"
33,"H Adel, K Kirchhoff, D Telaar, NT Vu…","Features for factored language models for code-switching speech",2014,"… for Under-Resourced …","isca-speech.org","https://www.isca-speech.org/archive/sltu_2014/sl14_032.html","https://scholar.google.com/scholar?cites=2582922842527412686&as_sdt=2005&sciodt=0,5&hl=en",120,"2020-11-06 21:29:44","","","","",,,,,33,5.50,7,5,6,"This paper presents investigations of features which can be used to predict Code-Switching speech. For this task, factored language models are applied and implemented into a state-of-the-art decoder. Different possible factors, such as words, part-of-speech tags, Brown word …"
37,"Q Jin, AR Toth, T Schultz…","Speaker de-identification via voice transformation",2009,"2009 IEEE Workshop on …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/5373356/?casa_token=7XYUWJ0lSLgAAAAA:bd2y58_CT_tG_3DzCutEJ-tuLlCLtGsdLECQ5YkQiu3cQCy6r1eiuALmXpAMg1gm5CYK0_yWeA","https://scholar.google.com/scholar?cites=7393610183660428242&as_sdt=2005&sciodt=0,5&hl=en",121,"2020-11-06 21:29:44","","","","",,,,,37,3.36,9,4,11,"It is a common feature of modern automated voice-driven applications and services to record and transmit a user's spoken request. At the same time, several domains and applications may require keeping the content of the user's request confidential and at the same time …"
28,"M Paulik, S Rao, I Lane, S Vogel…","Sentence segmentation and punctuation recovery for spoken language translation",2008,"2008 IEEE International …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/4518807/?casa_token=OCsL8Rh1WRsAAAAA:-VYKXFLqZrtmIJsKGcTEVSIdvXA-qm0TCOxMpdBzyL6X0nUxDUhOyT2Oc9vmcF3kE4qlQamXjg","https://scholar.google.com/scholar?cites=10094589970582635567&as_sdt=2005&sciodt=0,5&hl=en",122,"2020-11-06 21:29:44","","","","",,,,,28,2.33,6,5,12,"Sentence segmentation and punctuation recovery are critical components for effective spoken language translation (SLT). In this paper we describe our recent work on sentence segmentation and punctuation recovery for three different language pairs, namely for …"
29,"Q Yang, Q Jin, T Schultz","Investigation of cross-show speaker diarization",2011,"Twelfth Annual Conference of the …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2011/i11_2925.html","https://scholar.google.com/scholar?cites=5245052428183181465&as_sdt=2005&sciodt=0,5&hl=en",123,"2020-11-06 21:29:44","","","","",,,,,29,3.22,10,3,9,"The goal of cross-show diarization is to index speech segments of speakers from a set of shows, with the particular challenge that reappearing speakers across shows have to be labeled with the same speaker identity. In this paper, we introduce three cross-show …"
27,"P Charoenpornsawat, S Hewavitharana…","Thai grapheme-based speech recognition",2006,"Proceedings of the …","aclweb.org","https://www.aclweb.org/anthology/N06-2005.pdf","https://scholar.google.com/scholar?cites=2893382698734358186&as_sdt=2005&sciodt=0,5&hl=en",124,"2020-11-06 21:29:44","PDF","","","",,,,,27,1.93,9,3,14,"In this paper we present the results for building a grapheme-based speech recognition system for Thai. We experiment with different settings for the initial context independent system, different number of acoustic models and different contexts for the speech unit. In …"
29,"Q Jin, T Schultz, A Waibel","Speaker identification using multilingual phone strings",2002,"2002 IEEE International …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/5743675/?casa_token=06jxEhvdq88AAAAA:z-h92kvjV8ocO89GA-RjcvChkLbRMs8Lxd_E2EfKeiFgCHq-1s3XdXCQ6a4EPnf6_QstZRHSrw","https://scholar.google.com/scholar?cites=6140653713312845836&as_sdt=2005&sciodt=0,5&hl=en",125,"2020-11-06 21:29:44","","","","",,,,,29,1.61,10,3,18,"Far-field speaker identification is very challenging since varying recording conditions often result in un-matching training and testing situations. Although the widely used Gaussian Mixture Models (GMM) approach achieves reasonable good results when training and …"
28,"F Stahlberg, T Schlippe, S Vogel…","Word segmentation through cross-lingual word-to-phoneme alignment",2012,"2012 IEEE Spoken …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/6424202/?casa_token=mlq0h9pWuLQAAAAA:NU1igAqYwmfcldzChW38qk_crDPRL-hK9gCfXHY1jbS6kA01xzULwlnVewzAdpbBcql0nYdqeg","https://scholar.google.com/scholar?cites=12108675723852554029&as_sdt=2005&sciodt=0,5&hl=en",126,"2020-11-06 21:29:44","","","","",,,,,28,3.50,7,4,8,"We present our new alignment model Model 3P for cross-lingual word-to-phoneme alignment, and show that unsupervised learning of word segmentation is more accurate when information of another language is used. Word segmentation with cross-lingual …"
26,"C Herff, G Johnson, L Diener, J Shih…","Towards direct speech synthesis from ECoG: A pilot study",2016,"2016 38th Annual …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/7591004/?casa_token=LoXnI0YBEN8AAAAA:9bb1_PYgiypfVUSpp0sSvZyqEVqmUox1uzSr6MKLGpCnLdOaGLjT67SRaMCB4wTcd0lKIrnG9A","https://scholar.google.com/scholar?cites=2771499252263966016&as_sdt=2005&sciodt=0,5&hl=en",127,"2020-11-06 21:29:44","","","","",,,,,26,6.50,5,5,4,"Most current Brain-Computer Interfaces (BCIs) achieve high information transfer rates using spelling paradigms based on stimulus-evoked potentials. Despite the success of this interfaces, this mode of communication can be cumbersome and unnatural. Direct synthesis …"
30,"NT Vu, T Schultz","Multilingual multilayer perceptron for rapid language adaptation between and across language families.",2013,"Interspeech","isca-speech.org","https://www.isca-speech.org/archive/archive_papers/interspeech_2013/i13_0515.pdf","https://scholar.google.com/scholar?cites=1621148971424594501&as_sdt=2005&sciodt=0,5&hl=en",128,"2020-11-06 21:29:44","","","","",,,,,30,4.29,15,2,7,"In this paper, we present our latest investigations of multilingual Multilayer Perceptrons (MLPs) for rapid language adaptation between and across language families. We explore the impact of the amount of languages and data used for the multilingual MLP training …"
26,"A Lavie, F Metze, R Cattoni, E Costantini, S Burger…","A multi-perspective evaluation of the NESPOLE! speech-to-speech translation system",2002,"","hal.inria.fr","https://hal.inria.fr/inria-00326403/","https://scholar.google.com/scholar?cites=11602361925082254113&as_sdt=2005&sciodt=0,5&hl=en",129,"2020-11-06 21:29:44","","","","",,,,,26,1.44,4,6,18,"Performance and usability of realworld speech-to-speech translation systems, like the one developed within the NESPOLE! project, are affected by several aspects that go beyong the pure translation quality provided by the underlying components of the system. In this paper …"
26,"SCS Jou, T Schultz, A Waibel","Continuous electromyographic speech recognition with a multi-stream decoding architecture",2007,"2007 IEEE International …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/4218122/?casa_token=tgwq6cllw8IAAAAA:GTiKfabPTCRkPG73USoo3rfe2nHHlB-x6xri-uh12Q219xP9lDZDnNtwUe_FUI1JiskUkTQwdQ","https://scholar.google.com/scholar?cites=11720137797052343446&as_sdt=2005&sciodt=0,5&hl=en",130,"2020-11-06 21:29:44","","","","",,,,,26,2.00,9,3,13,"In our previous work, we reported a surface electromyographic (EMG) continuous speech recognition system with a novel EMG feature extraction method, E4, which is more robust to EMG noise than traditional spectral features. In this paper, we show that articulatory feature …"
30,"L Diener, M Janke, T Schultz","Direct conversion from facial myoelectric signals to speech using deep neural networks",2015,"2015 International Joint …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/7280404/?casa_token=S1VduH4i_PMAAAAA:u-qzlk_kGZM03vuFkFqBGtg2EfVdC_iTt7B_tjoFR2YcF9lalvafASI8tgeXvcEGk2d5tzr-eQ","https://scholar.google.com/scholar?cites=4816402021850376158&as_sdt=2005&sciodt=0,5&hl=en",131,"2020-11-06 21:29:44","","","","",,,,,30,6.00,10,3,5,"This paper presents our first results using Deep Neural Networks for surface electromyographic (EMG) speech synthesis. The proposed approach enables a direct mapping from EMG signals captured from the articulatory muscle movements to the acoustic …"
25,"M Janke, M Wand, T Schultz","A Spectral Mapping Method for EMG-based Recognition of Silent Speech.",2010,"B-Interface","pdfs.semanticscholar.org","https://pdfs.semanticscholar.org/a49d/e9c32bb52e66578a5c3ca2f9b9e1ca63ca43.pdf","https://scholar.google.com/scholar?cites=13473372022891998684&as_sdt=2005&sciodt=0,5&hl=en",132,"2020-11-06 21:29:44","PDF","","","",,,,,25,2.50,8,3,10,"This paper reports on our latest study on speech recognition based on surface electromyography (EMG). This technology allows for Silent Speech Interfaces since EMG captures the electrical potentials of the human articulatory muscles rather than the acoustic …"
26,"Z Wang, T Schultz","Non-native spontaneous speech recognition through polyphone decision tree specialization",2003,"Eighth European Conference on Speech …","isca-speech.org","https://www.isca-speech.org/archive/eurospeech_2003/e03_1449.html","https://scholar.google.com/scholar?cites=7516810003296968769&as_sdt=2005&sciodt=0,5&hl=en",133,"2020-11-06 21:29:44","","","","",,,,,26,1.53,13,2,17,"With more and more non-native speakers speaking in English, the fast and efficient adaptation to non-native English speech becomes a practical concern. The performance of speech recognition systems is consistently poor on non-native speech. The challenge for …"
27,"D Heger, R Mutter, C Herff, F Putze…","Continuous recognition of affective states by functional near infrared spectroscopy signals",2013,"… Conference on Affective …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/6681548/?casa_token=D1E0o6psQuIAAAAA:20Ezmnn83hCZZ9ktSmdfDmQT6bF_RAyg05UyRT6V3wahQ8FnWskXp9yA9VMctZx0nYW-4o63xw","https://scholar.google.com/scholar?cites=7755149210429184873&as_sdt=2005&sciodt=0,5&hl=en",134,"2020-11-06 21:29:44","","","","",,,,,27,3.86,5,5,7,"Functional near infrared spectroscopy (fNIRS) is becoming more and more popular as an innovative imaging modality for brain computer interfaces. A continuous (ie asynchronous) affective state monitoring system using fNIRS signals would be highly relevant for numerous …"
25,"M Janke, M Wand, T Schultz","Impact of lack of acoustic feedback in EMG-based silent speech recognition",2010,"Eleventh Annual Conference of the …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2010/i10_2686.html","https://scholar.google.com/scholar?cites=206343125368698352&as_sdt=2005&sciodt=0,5&hl=en",135,"2020-11-06 21:29:44","","","","",,,,,25,2.50,8,3,10,"This paper presents our recent advances in speech recognition based on surface electromyography (EMG). This technology allows for Silent Speech Interfaces since EMG captures the electrical potentials of the human articulatory muscles rather than the acoustic …"
1,"C Botelho, L Diener, D Küster, K Scheck, S Amiriparian…","Toward silent paralinguistics: Speech-to-emg–retrieving articulatory muscle activity from speech",2020,"Small","csl.uni-bremen.de","https://www.csl.uni-bremen.de/cms/images/documents/publications/Interspeech2020_emg_to_speech_revised.pdf","https://scholar.google.com/scholar?cites=5597209961008091754&as_sdt=2005&sciodt=0,5&hl=en",136,"2020-11-06 21:29:44","PDF","","","",,,,,1,1.00,0,6,1,"Electromyographic (EMG) signals recorded during speech production encode information on articulatory muscle activity and also on the facial expression of emotion, thus representing a speech-related biosignal with strong potential for paralinguistic applications …"
24,"Q Jin, Y Pan, T Schultz","Far-field speaker recognition",2006,"2006 IEEE International Conference …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/1660176/?casa_token=WrjjF8aYM1QAAAAA:wHu82fdqzjUb-Num80vu0CYJevzvbovyhqgZvGniT_nt5zMnT29yrt2lWCSeg08t081gQIkJzg","https://scholar.google.com/scholar?cites=1310608884935522089&as_sdt=2005&sciodt=0,5&hl=en",137,"2020-11-06 21:29:44","","","","",,,,,24,1.71,8,3,14,"In this paper we study robust speaker recognition in far-field microphone situations such as meeting scenarios. By applying reverberation compensation and feature warping we achieved significant improvements under mismatched training-testing conditions. To capture …"
24,"A Lavie, F Metze, F Pianesi, S Burger, D Gates, L Levin…","Enhancing the Usability and Performance of NESPOLE!-a Real-World Speech-to-Speech Translation System",2002,"","hal.inria.fr","https://hal.inria.fr/inria-00326412/","https://scholar.google.com/scholar?cites=10455995160624229893&as_sdt=2005&sciodt=0,5&hl=en",138,"2020-11-06 21:29:44","","","","",,,,,24,1.33,3,7,18,"Over the past year, we have developed a fully functional showcase of the NESPOLE! system within the domain of travel and tourism, and have significantly improved system performance and usability based on a series of studies and evaluations wih real users. Our experience …"
26,"H Adel, K Kirchhoff, NT Vu, D Telaar…","Comparing approaches to convert recurrent neural networks into backoff language models for efficient decoding",2014,"… Annual Conference of …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2014/i14_0651.html","https://scholar.google.com/scholar?cites=9205282701243617184&as_sdt=2005&sciodt=0,5&hl=en",139,"2020-11-06 21:29:44","","","","",,,,,26,4.33,5,5,6,"In this paper, we investigate and compare three different possibilities to convert recurrent neural network language models (RNNLMs) into backoff language models (BNLM). While RNNLMs often outperform traditional n-gram approaches in the task of language modeling …"
25,"D Telaar, M Wand, D Gehrig, F Putze…","BioKIT—real-time decoder for biosignal processing",2014,"… Annual Conference of …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2014/i14_2650.html","https://scholar.google.com/scholar?cites=3139202818286512636&as_sdt=2005&sciodt=0,5&hl=en",140,"2020-11-06 21:29:44","","","","",,,,,25,4.17,5,5,6,"We introduce BioKIT, a new Hidden Markov Model based toolkit to preprocess, model and interpret biosignals such as speech, motion, muscle and brain activities. The focus of this toolkit is to enable researchers from various communities to pursue their experiments and …"
23,"S Rao, I Lane, T Schultz","Optimizing sentence segmentation for spoken language translation",2007,"Eighth Annual Conference of the …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2007/i07_2845.html","https://scholar.google.com/scholar?cites=584104365405498093&as_sdt=2005&sciodt=0,5&hl=en",141,"2020-11-06 21:29:44","","","","",,,,,23,1.77,8,3,13,"The conventional approach in text-based machine translation (MT) is to translate complete sentences, which are conveniently indicated by sentence boundary markers. However, since such boundary markers are not available for speech, new methods are required that …"
24,"HA Engelbrecht, T Schultz","Rapid development of an afrikaans-english speech-to-speech translator",2005,"International Workshop on Spoken …","isca-speech.org","https://www.isca-speech.org/archive/iwslt_05/slt5_159.html","https://scholar.google.com/scholar?cites=11431845369167474906&as_sdt=2005&sciodt=0,5&hl=en",142,"2020-11-06 21:29:44","","","","",,,,,24,1.60,12,2,15,"In this paper we investigate the rapid deployment of a twoway Afrikaans to English Speech-to-Speech Translation system. We discuss the approaches and amount of work involved to port a system to a new language pair, ie the steps required to rapidly adapt ASR, MT and …"
23,"M Wand, T Schultz","Pattern learning with deep neural networks in EMG-based speech recognition",2014,"… Conference of the IEEE Engineering in …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/6944550/?casa_token=5285CLfjkKAAAAAA:PlwE9e87ZI4lmXH8H3JHKyej4vpPu8sYGs3jFaPOAscEHX4ktDSm-PrTf79jPT-sDO8i7R3qnQ","https://scholar.google.com/scholar?cites=4489866261819510178&as_sdt=2005&sciodt=0,5&hl=en",143,"2020-11-06 21:29:44","","","","",,,,,23,3.83,12,2,6,"We report on classification of phones and phonetic features from facial electromyographic (EMG) data, within the context of our EMG-based Silent Speech interface. In this paper we show that a Deep Neural Network can be used to perform this classification task, yielding a …"
24,"F Putze, J Hild, R Kärgel, C Herff, A Redmann…","Locating user attention using eye tracking and EEG for spatio-temporal event selection",2013,"Proceedings of the …","dl.acm.org","https://dl.acm.org/doi/abs/10.1145/2449396.2449415","https://scholar.google.com/scholar?cites=769471621677822465&as_sdt=2005&sciodt=0,5&hl=en",144,"2020-11-06 21:29:44","","","","",,,,,24,3.43,4,6,7,"In expert video analysis, the selection of certain events in a continuous video stream is a frequently occurring operation, eg, in surveillance applications. Due to the dynamic and rich visual input, the constantly high attention and the required hand-eye coordination for mouse …"
22,"T Schultz, AW Black","Challenges with rapid adaptation of speech translation systems to new language pairs",2006,"2006 IEEE International Conference on …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/1661500/?casa_token=ehXf7CQurqIAAAAA:9tLkJzTFvTZyJqJ4BSQxeAFVmHiS6__ubgT2WX7nH5QJQvKeoRtqBufWh7ECleYonwuHmM2xMA","https://scholar.google.com/scholar?cites=4195190880948843072&as_sdt=2005&sciodt=0,5&hl=en",145,"2020-11-06 21:29:44","","","","",,,,,22,1.57,11,2,14,"Although we have far from solved the issues in porting speech translation systems to new languages, we have gathered sufficient experience by now to identify a number of major challenges in the process. Although well-defined processes exist for building speech …"
23,"AW Black, T Schultz","Speaker clustering for multilingual synthesis",2006,"Multilingual Speech and Language …","isca-speech.org","https://www.isca-speech.org/archive_open/ml06/ml06_024.html","https://scholar.google.com/scholar?cites=11315551054706491208&as_sdt=2005&sciodt=0,5&hl=en",146,"2020-11-06 21:29:44","","","","",,,,,23,1.64,12,2,14,"Today, speech synthesizers in new languages are typically built by collecting several hours of well recorded speech in the target language. The time and effort involved in collection and correction can be prohibitive when lack of resources is common in addressing under …"
22,"C Fügen, M Westphal, M Schneider, T Schultz…","LingWear: a mobile tourist information system",2001,"Proceedings of the first …","aclweb.org","https://www.aclweb.org/anthology/H01-1048.pdf","https://scholar.google.com/scholar?cites=5258045751036128335&as_sdt=2005&sciodt=0,5&hl=en",147,"2020-11-06 21:29:44","PDF","","","",,,,,22,1.16,4,5,19,"In this aper, we describe LingWear, a mobile tourist information system that allows uninformed users to find their way around in foreign cities and to ask for information about sights, accommodations, and other places of interest. The user can communicate with Lin …"
22,"S Rao, I Lane, T Schultz","Improving spoken language translation by automatic disfluency removal: Evidence from conversational speech transcripts",2007,"Training","Citeseer","http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.183.511&rep=rep1&type=pdf","https://scholar.google.com/scholar?cites=14321933231327429712&as_sdt=2005&sciodt=0,5&hl=en",148,"2020-11-06 21:29:44","PDF","","","",,,,,22,1.69,7,3,13,"Abstract Machine translation of spoken language has made significant progress in recent years, however, translation quality is still limited due to specific idiosyncrasies of spoken language; including the lack of well-formed sentences and the presence of disfluencies. In …"
22,"F Metze, T Kemp, T Schaaf, T Schultz…","Confidence measure based language identification",2000,"… on Acoustics, Speech …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/862110/?casa_token=fueCryohgjkAAAAA:aRAbrEenpBFGkNlASY-Eq8C1EujyZDBsSK0JoBgxatjHDCyJ-LqunEL7Woz082Luc84EBDnJWQ","https://scholar.google.com/scholar?cites=744959679637233434&as_sdt=2005&sciodt=0,5&hl=en",149,"2020-11-06 21:29:44","","","","",,,,,22,1.10,4,5,20,"In this paper we present a new application for confidence measures in spoken language processing. In today's computerized dialogue systems, language identification (LID) is typically achieved via dedicated modules. In our approach, LID is integrated into the speech …"
22,"F Putze, T Schultz","Adaptive cognitive technical systems",2014,"Journal of neuroscience methods","Elsevier","https://www.sciencedirect.com/science/article/pii/S0165027014002416","https://scholar.google.com/scholar?cites=18437880621908296088&as_sdt=2005&sciodt=0,5&hl=en",150,"2020-11-06 21:29:44","","","","",,,,,22,3.67,11,2,6,"Adaptive cognitive technical systems are capable of sensing the internal state of its user and of adapting its behavior appropriately to those measurements to improve the usability of the system. One important example of such user state is the user's mental workload level. This …"
24,"T Schlippe, C Zhu, J Gebhardt…","Text normalization based on statistical machine translation and internet user support",2010,"… Annual Conference of the …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2010/i10_1816.html","https://scholar.google.com/scholar?cites=172156191253730876&as_sdt=2005&sciodt=0,5&hl=en",151,"2020-11-06 21:29:44","","","","",,,,,24,2.40,6,4,10,"In this paper, we describe and compare systems for text normalization based on statistical machine translation (SMT) methods which are constructed with the support of internet users. Internet users normalize text displayed in a web interface, thereby providing a parallel …"
20,"B Thürer, C Stockinger, A Focke, F Putze, T Schultz…","Increased gamma band power during movement planning coincides with motor memory retrieval",2016,"Neuroimage","Elsevier","https://www.sciencedirect.com/science/article/pii/S1053811915009027?casa_token=Dw4LM-M02VYAAAAA:LZ_rwlp816DWtuNW2-gu8qtX1QlTNSAEMw09uIJr8g2YjenDEn3WehYfHF4ictpPQS9qQIpbCw","https://scholar.google.com/scholar?cites=17651014122646190102&as_sdt=2005&sciodt=0,5&hl=en",152,"2020-11-06 21:29:44","HTML","","","",,,,,20,5.00,3,6,4,"The retrieval of motor memory requires a previous memory encoding and subsequent consolidation of the specific motor memory. Previous work showed that motor memory seems to rely on different memory components (eg, implicit, explicit). However, it is still …"
21,"F Metze, R Hsiao, Q Jin, U Nallasamy…","The 2010 CMU GALE speech-to-text system",2010,"… Annual Conference of …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2010/i10_1501.html","https://scholar.google.com/scholar?cites=4983950960362236482&as_sdt=2005&sciodt=0,5&hl=en",153,"2020-11-06 21:29:44","","","","",,,,,21,2.10,4,5,10,"This paper describes the latest Speech-to-Text system developed for the Global Autonomous Language Exploitation (“GALE”) domain by Carnegie Mellon University (CMU). This systems uses discriminative training, bottle-neck features and other techniques that …"
24,"M Janke, M Wand, T Heistermann…","Fundamental frequency generation for whisper-to-audible speech conversion",2014,"… , Speech and Signal …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/6854066/?casa_token=SGOesXm3pRUAAAAA:0F3IwowZM1vbsXFGjkPa8wdVnWwtm8aMBjGXbuW7crro4KLko2tq9XXyah1i2DjCr-Kx8-Ni4w","https://scholar.google.com/scholar?cites=13124978181998546342&as_sdt=2005&sciodt=0,5&hl=en",154,"2020-11-06 21:29:44","","","","",,,,,24,4.00,6,4,6,"In this work, we address the issues involved in whisper-to-audible speech conversion. Spectral mapping techniques using Gaussian mixture models or Artificial Neural Networks borrowed from voice conversion have been applied to transform whisper spectral features to …"
21,"H Yu, YC Tam, T Schaaf, S Stüker, Q Jin…","The isl rt04 mandarin broadcast news evaluation system",2004,"EARS Rich …","cs.cmu.edu","http://www.cs.cmu.edu/afs/.cs.cmu.edu/Web/People/yct/papers/rt04.pdf","https://scholar.google.com/scholar?cites=8789151941614710459&as_sdt=2005&sciodt=0,5&hl=en",155,"2020-11-06 21:29:44","PDF","","","",,,,,21,1.31,4,6,16,"This paper describes our effort in developing a Mandarin Broadcast News system for the RT-04f (Rich Transcription) evaluation. Starting from a legacy system, we revisited all the issues including partitioning, acoustic modeling, language modeling, decoding and system …"
21,"T Schlippe, L Gren, NT Vu, T Schultz","Unsupervised language model adaptation for automatic speech recognition of broadcast news using web 2.0.",2013,"Interspeech","isca-speech.org","https://www.isca-speech.org/archive/archive_papers/interspeech_2013/i13_2698.pdf","https://scholar.google.com/scholar?cites=3232605227801089575&as_sdt=2005&sciodt=0,5&hl=en",156,"2020-11-06 21:29:44","","","","",,,,,21,3.00,5,4,7,"We improve the automatic speech recognition of broadcast news using paradigms from Web 2.0 to obtain time-and topicrelevant text data for language modeling. We elaborate an unsupervised text collection and decoding strategy that includes crawling appropriate texts …"
25,"G Gibert, M Pruzinec, T Schultz, C Stevens","Enhancement of human computer interaction with facial electromyographic sensors",2009,"Proceedings of the 21st …","dl.acm.org","https://dl.acm.org/doi/abs/10.1145/1738826.1738914","https://scholar.google.com/scholar?cites=8941856116006237254&as_sdt=2005&sciodt=0,5&hl=en",157,"2020-11-06 21:29:44","","","","",,,,,25,2.27,6,4,11,"In this paper we describe a way to enhance human computer interaction using facial Electromyographic (EMG) sensors. Indeed, to know the emotional state of the user enables adaptable interaction specific to the mood of the user. This way, Human Computer …"
22,"NT Vu, H Adel, T Schultz","An investigation of code-switching attitude dependent language modeling",2013,"International Conference on Statistical …","Springer","https://link.springer.com/chapter/10.1007/978-3-642-39593-2_26","https://scholar.google.com/scholar?cites=13185200194501216077&as_sdt=2005&sciodt=0,5&hl=en",158,"2020-11-06 21:29:44","","","","",,,,,22,3.14,7,3,7,"In this paper, we investigate the adaptation of language modeling for conversational Mandarin-English Code-Switching (CS) speech and its effect on speech recognition performance. First, we investigate the prediction of code switches based on textual features …"
21,"NT Vu, J Weiner, T Schultz","Investigating the learning effect of multilingual bottle-neck features for ASR",2014,"Fifteenth Annual Conference Of The …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2014/i14_0825.html","https://scholar.google.com/scholar?cites=12256536705507796277&as_sdt=2005&sciodt=0,5&hl=en",159,"2020-11-06 21:29:44","","","","",,,,,21,3.50,7,3,6,"Deep neural networks (DNNs) have become state-of-the-art techniques of automatic speech recognition in the last few years. They can be used at the preprocessing level (Tandem or Bottle-Neck features) or at the acoustic model level (hybrid Hidden Markov Model/DNN) …"
20,"T Schultz, A Black","Rapid language adaptation tools and technologies for multilingual speech processing",2008,"Proc. ICASSP Las Vegas, USA","","","https://scholar.google.com/scholar?cites=3161427837037493383&as_sdt=2005&sciodt=0,5&hl=en",160,"2020-11-06 21:29:44","CITATION","","","",,,,,20,1.67,10,2,12,""
20,"J Jarvis, F Putze, D Heger, T Schultz","Multimodal person independent recognition of workload related biosignal patterns",2011,"Proceedings of the 13th …","dl.acm.org","https://dl.acm.org/doi/abs/10.1145/2070481.2070516","https://scholar.google.com/scholar?cites=13113759515212674083&as_sdt=2005&sciodt=0,5&hl=en",161,"2020-11-06 21:29:44","","","","",,,,,20,2.22,5,4,9,"This paper presents an online multimodal person independent workload classification system using blood volume pressure, respiration measures, electrodermal activity and electroencephalography. For each modality a classifier based on linear discriminant …"
21,"T Schlippe, S Ochs, T Schultz","Web-based tools and methods for rapid pronunciation dictionary creation",2014,"Speech Communication","Elsevier","https://www.sciencedirect.com/science/article/pii/S0167639313000885","https://scholar.google.com/scholar?cites=15588016361406079008&as_sdt=2005&sciodt=0,5&hl=en",162,"2020-11-06 21:29:44","","","","",,,,,21,3.50,7,3,6,"In this paper we study the potential as well as the challenges of using the World Wide Web as a seed for the rapid generation of pronunciation dictionaries in new languages. In particular, we describe Wiktionary, a community-driven resource of pronunciations in IPA …"
19,"M Wölfel, Q Yang, Q Jin, T Schultz","Speaker identification using warped MVDR cepstral features",2009,"Tenth Annual Conference of …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2009/i09_0912.html","https://scholar.google.com/scholar?cites=10852976409631870169&as_sdt=2005&sciodt=0,5&hl=en",163,"2020-11-06 21:29:44","","","","",,,,,19,1.73,5,4,11,"It is common practice to use similar or even the same feature extraction methods for automatic speech recognition and speaker identification. While the front-end for the former requires to preserve phoneme discrimination and to compensate for speaker differences to …"
23,"M Janke, M Wand, K Nakamura…","Further investigations on EMG-to-speech conversion",2012,"2012 IEEE International …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/6287892/?casa_token=p-YiKNQVxAwAAAAA:Aq545dlRp6ydyLK2FHKPT1PPXz8HlW6iOk5LNP3CLBZoohGFH8R73_8S45xphwemI-1U9P8_BQ","https://scholar.google.com/scholar?cites=16174458936120534029&as_sdt=2005&sciodt=0,5&hl=en",164,"2020-11-06 21:29:44","","","","",,,,,23,2.88,6,4,8,"Our study deals with a Silent Speech Interface based on mapping surface electromyographic (EMG) signals to speech waveforms. Electromyographic signals recorded from the facial muscles capture the activity of the human articulatory apparatus and …"
21,"C Herff, F Putze, D Heger, C Guan…","Speaking mode recognition from functional near infrared spectroscopy",2012,"… Conference of the IEEE …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/6346279/?casa_token=BX3bT6nmwe0AAAAA:q_WlIX_wv8PK1Q3DiL54XhFr_CaAXzPeyzBEiCVf4vg6__oGcYLJp4rBcazLqCE5wquPPuODeQ","https://scholar.google.com/scholar?cites=4516578562884900702&as_sdt=2005&sciodt=0,5&hl=en",165,"2020-11-06 21:29:44","","","","",,,,,21,2.63,4,5,8,"Speech is our most natural form of communication and even though functional Near Infrared Spectroscopy (fNIRS) is an increasingly popular modality for Brain Computer Interfaces (BCIs), there are, to the best of our knowledge, no previous studies on speech related tasks …"
19,"T Schultz, Q Jin, K Laskowski, A Tribble, A Waibel","Speaker, accent, and language identification using multilingual phone strings",2002,"HLT 2002","csl.uni-bremen.de","https://csl.uni-bremen.de/cms/images/documents/publications/schultz_hlt2002.pdf","https://scholar.google.com/scholar?cites=12658409413288787696&as_sdt=2005&sciodt=0,5&hl=en",166,"2020-11-06 21:29:44","PDF","","","",,,,,19,1.06,4,5,18,"The identification of an utterance's non-verbal cues, such as speaker, accent and language, can provide useful information for speech analysis. In this paper we investigate far-field speaker identification, as well as accent and language identification, using multilingual …"
20,"D Heger, F Putze, T Schultz","Online recognition of facial actions for natural EEG-based BCI applications",2011,"International Conference on Affective …","Springer","https://link.springer.com/chapter/10.1007/978-3-642-24571-8_56","https://scholar.google.com/scholar?cites=8098471102192334208&as_sdt=2005&sciodt=0,5&hl=en",167,"2020-11-06 21:29:44","","","","",,,,,20,2.22,7,3,9,"We present a system for classification of nine voluntary facial actions, ie Neutral, Smile, Sad, Surprise, Angry, Speak, Blink, Left, and Right. The data is assessed by an Emotiv EPOC wireless EEG head-set. We derive spectral features and step function features that represent …"
19,"M Wand, T Schultz","Analysis of phone confusion in EMG-based speech recognition",2011,"2011 IEEE International Conference on …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/5946514/?casa_token=zxTy1TLmCPcAAAAA:W10uCrXxEMpO0sgTLrnbRoB8-HSrVkloPo1CUCZ0aRNWQ0WKsYZGSmEubUKjJcpOnH13Kfo5aQ","https://scholar.google.com/scholar?cites=3909878957743045496&as_sdt=2005&sciodt=0,5&hl=en",168,"2020-11-06 21:29:44","","","","",,,,,19,2.11,10,2,9,"In this paper we present a study on phone confusabilities based on phone recognition experiments from facial surface electromyographic (EMG) signals. In our study EMG captures the electrical potentials of the human articulatory muscles. This technology can be …"
18,"B Mimer, S Stüker, T Schultz","Flexible decision trees for grapheme based speech recognition",2004,"Proceedings of the 15th …","csl.uni-bremen.de","https://csl.uni-bremen.de/cms/images/documents/publications/SchultzMimer_ESSV04.pdf","https://scholar.google.com/scholar?cites=12763999833882347239&as_sdt=2005&sciodt=0,5&hl=en",169,"2020-11-06 21:29:44","PDF","","","",,,,,18,1.13,6,3,16,"Over the last decades research in the field of automatic speech recognition (ASR) has seen enormous progress. Speech recognition systems are now deployed in real world applications, such as commercial software systems on PCs or Workstations, embedded in …"
16,"J Weiner, C Frankenberg, D Telaar…","Towards automatic transcription of ILSE―An interdisciplinary longitudinal study of adult development and aging",2016,"Proceedings of the …","aclweb.org","https://www.aclweb.org/anthology/L16-1114.pdf","https://scholar.google.com/scholar?cites=10421235247584416064&as_sdt=2005&sciodt=0,5&hl=en",170,"2020-11-06 21:29:44","PDF","","","",,,,,16,4.00,4,4,4,"Abstract The Interdisciplinary Longitudinal Study on Adult Development and Aging (ILSE) was created to facilitate the study of challenges posed by rapidly aging societies in developed countries such as Germany. ILSE contains over 8,000 hours of biographic …"
17,"T Schultz, A Waibel","Adaptation of pronunciation dictionaries for recognition of unseen languages",1998,"… on Speech and Communication (SPECOM-1998)","ri.cmu.edu","http://ri.cmu.edu/pub_files/pub1/schultz_tanja_1998_3/schultz_tanja_1998_3.pdf","https://scholar.google.com/scholar?cites=3705572550607604733&as_sdt=2005&sciodt=0,5&hl=en",171,"2020-11-06 21:29:44","PDF","","","",,,,,17,0.77,9,2,22,"This paper studies the relative effectiveness of different methods for multilingual model combination and dictionary mapping for recognizing a new unseen target language if training data are limited. We examine the crosslanguage transfer from monolingual and …"
17,"K Laskowski, M Ostendorf, T Schultz","Modeling vocal interaction for text-independent classification of conversation type",2007,"… of the 8th SIGdial Workshop on …","aclweb.org","https://www.aclweb.org/anthology/2007.sigdial-1.33.pdf","https://scholar.google.com/scholar?cites=18173809158946105191&as_sdt=2005&sciodt=0,5&hl=en",172,"2020-11-06 21:29:44","PDF","","","",,,,,17,1.31,6,3,13,"We describe a system for conversation type classification which relies exclusively on multi-participant vocal activity patterns. Using a variation on a well-studied model from stochastic dynamics, we extract features which represent the transition probabilities that characterize …"
18,"M Wand, T Schultz","Towards real-life application of EMG-based speech recognition by using unsupervised adaptation",2014,"… Annual Conference of the International Speech …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2014/i14_1189.html","https://scholar.google.com/scholar?cites=9485715469490711215&as_sdt=2005&sciodt=0,5&hl=en",173,"2020-11-06 21:29:44","","","","",,,,,18,3.00,9,2,6,"This paper deals with a Silent Speech Interface based on Surface Electromyography (EMG), where electrodes capture the electric activity generated by the articulatory muscles from a user's face in order to decode the underlying speech, allowing speech to be recognized …"
17,"A Lavie, L Levin, T Schultz, C Langley, B Han…","Domain portability in speech-to-speech translation",2001,"Proceedings of the first …","aclweb.org","https://www.aclweb.org/anthology/H01-1018.pdf","https://scholar.google.com/scholar?cites=5748105324699965933&as_sdt=2005&sciodt=0,5&hl=en",174,"2020-11-06 21:29:44","PDF","","","",,,,,17,0.89,3,6,19,"Speech-to-speech translation has made significant advances over the past decade, with several high-visibility projects (C-STAR, Verbmobil, the Spoken Language Translator, and others) significantly advancing the state-of-the-art. While speech recognition can currently …"
18,"R Hsiao, A Venugopal, T Köhler, Y Zhang…","Optimizing components for handheld two-way speech translation for an English-Iraqi Arabic system",2006,"… on Spoken Language …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2006/i06_1712.html","https://scholar.google.com/scholar?cites=15781501759807427365&as_sdt=2005&sciodt=0,5&hl=en",175,"2020-11-06 21:29:44","","","","",,,,,18,1.29,4,5,14,"This paper described our handheld two-way speech translation system for English and Iraqi. The focus is on developing a field usable handheld device for speech-to-speech translation. The computation and memory limitations on the handheld impose critical constraints on the …"
17,"T Schultz, AW Black, S Vogel…","Flexible speech translation systems",2006,"IEEE Transactions on …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/1597246/?casa_token=YVqJwWJ4y1EAAAAA:mqJJgssy0pYg6IRQQj-wqdTAjoPPJZl6e4KkzAwg2KPuIpbcnDZPQOI0MrRmFZbtdw_PpMhuYg","https://scholar.google.com/scholar?cites=57926453979636448&as_sdt=2005&sciodt=0,5&hl=en",176,"2020-11-06 21:29:44","","","","",,,,,17,1.21,4,4,14,"Speech translation research has made significant progress over the years with many high-visibility efforts showing that translation of spontaneously spoken speech from and to diverse languages is possible and applicable in a variety of domains. As language and domains …"
17,"U Nallasamy, F Metze, T Schultz","Enhanced polyphone decision tree adaptation for accented speech recognition",2012,"Thirteenth Annual Conference of …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2012/i12_1902.html","https://scholar.google.com/scholar?cites=15004813452258589372&as_sdt=2005&sciodt=0,5&hl=en",177,"2020-11-06 21:29:44","","","","",,,,,17,2.13,6,3,8,"State-of-the-art Automatic Speech Recognition (ASR) systems struggle to handle accented speech, particularly if the target accent is under-represented in the training data. The acoustic variations presented by an unfamiliar accent render the ASR polyphone decision …"
5,"F Putze, D Weiβ, LM Vortmann…","Augmented reality interface for smart home control using SSVEP-BCI and eye gaze",2019,"2019 IEEE International …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/8914390/?casa_token=4WUEkjaBphEAAAAA:0O5h3gFOeLVl4bci3Wcv3wvE8W_ozAn2mra3gIR1P1H-EYtDkAbYAUDVflkf8lIGDMHKPjPn4w","https://scholar.google.com/scholar?cites=7725150492833202283&as_sdt=2005&sciodt=0,5&hl=en",178,"2020-11-06 21:29:44","","","","",,,,,5,5.00,1,4,1,"In this paper, we investigate the integration of eye-tracking and a Brain-Computer Interface into an Augmented Reality system to control a smart home environment. Through a head-mounted display, we present context-dependent control elements which the user selects by …"
17,"T Schlippe, EGK Djomgang, NT Vu…","Hausa large vocabulary continuous speech recognition",2012,"… for Under-Resourced …","isca-speech.org","https://www.isca-speech.org/archive/sltu_2012/su12_011.html","https://scholar.google.com/scholar?cites=11540361049312216627&as_sdt=2005&sciodt=0,5&hl=en",179,"2020-11-06 21:29:44","","","","",,,,,17,2.13,4,4,8,"We report on our efforts toward an LVCSR system for the African language Hausa. We describe the Hausa text and speech database recently collected as a part of our Global-Phone corpus [1]. The data was complemented by a large collection of text data crawled …"
18,"T Schultz","Towards rapid language portability of speech processing systems",2004,"Conference on Speech and Language Systems for …","csl.uni-bremen.de","https://csl.uni-bremen.de/cms/images/documents/publications/Schultz_SPLASH04.pdf","https://scholar.google.com/scholar?cites=4931665257937963962&as_sdt=2005&sciodt=0,5&hl=en",180,"2020-11-06 21:29:44","PDF","","","",,,,,18,1.13,18,1,16,"In recent years, more and more speech processing products in several languages have been widely distributed all over the world. This fact reflects the general believe that speech technologies have a huge potential to let everyone participate in today's information …"
17,"D Reich, F Putze, D Heger, J Ijsselmuiden…","A real-time speech command detector for a smart control room",2011,"… Annual Conference of …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2011/i11_2641.html","https://scholar.google.com/scholar?cites=16845635956420411974&as_sdt=2005&sciodt=0,5&hl=en",181,"2020-11-06 21:29:44","","","","",,,,,17,1.89,3,5,9,"In this work we present an always-on speech recognition system that discriminates spoken commands directed to the system from other spoken input. For discrimination we integrated various features ranging from prosodic cues and decoding features to linguistic information …"
17,"T Schultz, D Alexander, AW Black, K Peterson…","A Thai speech translation system for medical dialogs",2004,"… Papers at HLT-NAACL …","aclweb.org","https://www.aclweb.org/anthology/N04-3010.pdf","https://scholar.google.com/scholar?cites=14292383518280427248&as_sdt=2005&sciodt=0,5&hl=en",182,"2020-11-06 21:29:44","PDF","","","",,,,,17,1.06,3,5,16,"2. Speech Recognition The language adaptation techniques developed in our lab [5] enables us to rapidly bootstrap a speech recognition system in a new target language given very limited amount of training data. The Thailand's National Electronics and Technology …"
15,"K Laskowski, C Fügen, T Schultz","Simultaneous multispeaker segmentation for automatic meeting recognition",2007,"2007 15th European Signal …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/7099014/","https://scholar.google.com/scholar?cites=3731067523563451753&as_sdt=2005&sciodt=0,5&hl=en",183,"2020-11-06 21:29:44","","","","",,,,,15,1.15,5,3,13,"Vocal activity detection is an important technology for both automatic speech recognition and automatic speech understanding. In meetings, participants typically vocalize for only a fraction of the recorded time, and standard vocal activity detection algorithms for close-talk …"
15,"C Herff, D Heger, F Putze, C Guan, T Schultz","Cross-subject classification of speaking modes using fNIRS",2012,"International Conference on …","Springer","https://link.springer.com/chapter/10.1007/978-3-642-34481-7_51","https://scholar.google.com/scholar?cites=1205405519845348370&as_sdt=2005&sciodt=0,5&hl=en",184,"2020-11-06 21:29:44","","","","",,,,,15,1.88,3,5,8,"Abstract In Brain-Computer Interface (BCI) research, subject and session specific training data is usually used to ensure satisfying classification results. In this paper, we show that neural responses to different speaking tasks recorded with functional Near Infrared …"
16,"T Schultz, T Schlippe","GlobalPhone: Pronunciation Dictionaries in 20 Languages.",2014,"LREC","researchgate.net","https://www.researchgate.net/profile/Tim_Schlippe/publication/268578432_GlobalPhone_Pronunciation_Dictionaries_in_20_Languages/links/54715f130cf216f8cfad0e02.pdf","https://scholar.google.com/scholar?cites=11826861391045166970&as_sdt=2005&sciodt=0,5&hl=en",185,"2020-11-06 21:29:44","PDF","","","",,,,,16,2.67,8,2,6,"This paper describes the advances in the multilingual text and speech database GLOBALPHONE a multilingual database of high-quality read speech with corresponding transcriptions and pronunciation dictionaries in 20 languages. GLOBALPHONE was …"
15,"R Hsiao, YC Tam, T Schultz","Generalized baum-welch algorithm for discriminative training on large vocabulary continuous speech recognition system",2009,"2009 IEEE International …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/4960447/?casa_token=lYSSZXMJ-o0AAAAA:rEjrNTKI1FSsmj58nzHhK6J3bnUnllTsDQxIEfKsqQ-x6nhMAzh_5FlJwoErgVXLJ5vzn0CgbA","https://scholar.google.com/scholar?cites=6522287820673900190&as_sdt=2005&sciodt=0,5&hl=en",186,"2020-11-06 21:29:44","","","","",,,,,15,1.36,5,3,11,"We propose a new optimization algorithm called Generalized Baum Welch (GBW) algorithm for discriminative training on hidden Markov model (HMM). GBW is based on Lagrange relaxation on a transformed optimization problem. We show that both Baum-Welch (BW) …"
16,"M Honal, T Schultz","Identifying user state using electroencephalographic data",2005,"… on Multimodal Input (ICMI), Trento, Italy","csl.uni-bremen.de","https://csl.uni-bremen.de/cms/images/documents/publications/HonalSchultz_ICMI2005.pdf","https://scholar.google.com/scholar?cites=18072924837172590126&as_sdt=2005&sciodt=0,5&hl=en",187,"2020-11-06 21:29:44","PDF","","","",,,,,16,1.07,8,2,15,"In modern meeting environments people interact a lot with electronic communication devices such as computers, cellphones, PDAs etc. which notify their users of events like incoming phone calls, text messages or e-mails. Depending on the current user state (eg …"
15,"K Laskowski, T Schultz","Modeling vocal interaction for segmentation in meeting recognition",2007,"International Workshop on Machine Learning for …","Springer","https://link.springer.com/chapter/10.1007/978-3-540-78155-4_23","https://scholar.google.com/scholar?cites=1542317810828963095&as_sdt=2005&sciodt=0,5&hl=en",188,"2020-11-06 21:29:44","","","","",,,,,15,1.15,8,2,13,"Automatic segmentation is an important technology for both automatic speech recognition and automatic speech understanding. In meetings, participants typically vocalize for only a fraction of the recorded time, but standard vocal activity detection algorithms for close-talk …"
15,"N Bach, R Hsiao, M Eck, P Charoenpornsawat…","Incremental adaptation of speech-to-speech translation",2009,"Proceedings of Human …","aclweb.org","https://www.aclweb.org/anthology/N09-2038.pdf","https://scholar.google.com/scholar?cites=971095338584391367&as_sdt=2005&sciodt=0,5&hl=en",189,"2020-11-06 21:29:44","PDF","","","",,,,,15,1.36,3,5,11,"In building practical two-way speech-to-speech translation systems the end user will always wish to use the system in an environment different from the original training data. As with all speech systems, it is important to allow the system to adapt to the actual usage situations …"
15,"M Westphal, T Schultz, A Waibel","Linear discriminant-a new criterion for speaker normalization",1998,"Fifth International Conference on …","isca-speech.org","https://www.isca-speech.org/archive/icslp_1998/i98_0755.html","https://scholar.google.com/scholar?cites=3722546187059096250&as_sdt=2005&sciodt=0,5&hl=en",190,"2020-11-06 21:29:44","","","","",,,,,15,0.68,5,3,22,"ABSTRACT In Vocal Tract Length Normalization (VTLN) a linear or nonlinear frequency transformation compensates for different vocal tract lengths. Finding good estimates for the speaker specific warp parameters is a critical issue. Despite good results using the …"
7,"M Angrick, C Herff, G Johnson, J Shih, D Krusienski…","Interpretation of convolutional neural networks for speech spectrogram regression from intracranial recordings",2019,"Neurocomputing","Elsevier","https://www.sciencedirect.com/science/article/pii/S092523121930133X","https://scholar.google.com/scholar?cites=9789313965832524485&as_sdt=2005&sciodt=0,5&hl=en",191,"2020-11-06 21:29:44","","","","",,,,,7,7.00,1,6,1,"The direct synthesis of continuously spoken speech from neural activity could provide a fast and natural way of communication for users suffering from speech disorders. Mapping the complex dynamics of neural activity to spectral representations of speech is a demanding …"
10,"B Thürer, C Stockinger, F Putze, T Schultz…","Mechanisms within the parietal cortex correlate with the benefits of random practice in motor adaptation",2017,"Frontiers in human …","frontiersin.org","https://www.frontiersin.org/articles/10.3389/fnhum.2017.00403/full","https://scholar.google.com/scholar?cites=16559902609245025823&as_sdt=2005&sciodt=0,5&hl=en",192,"2020-11-06 21:29:44","HTML","","","",,,,,10,3.33,2,5,3,"The motor learning literature shows an increased retest or transfer performance after practicing under unstable (random) conditions. This random practice effect (also known as contextual interference effect) is frequently investigated on the behavioral level and …"
15,"M Zahner, M Janke, M Wand…","Conversion from facial myoelectric signals to speech: A unit selection approach",2014,"… Annual Conference of the …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2014/i14_1184.html","https://scholar.google.com/scholar?cites=8977602313846441520&as_sdt=2005&sciodt=0,5&hl=en",193,"2020-11-06 21:29:44","","","","",,,,,15,2.50,4,4,6,"This paper reports on our recent research on surface electromyographic (EMG) speech synthesis: a direct conversion of the EMG signals of the articulatory muscle movements to the acoustic speech signal. In this work we introduce a unit selection approach which …"
14,"M Noamany, T Schaaf, T Schultz","Advances in the CMU/InterACT Arabic GALE transcription system",2007,"… 2007: The Conference of the North …","aclweb.org","https://www.aclweb.org/anthology/N07-2033.pdf","https://scholar.google.com/scholar?cites=14788688740648085249&as_sdt=2005&sciodt=0,5&hl=en",194,"2020-11-06 21:29:44","PDF","","","",,,,,14,1.08,5,3,13,"This paper describes the CMU/InterACT effort in developing an Arabic Automatic Speech Recognition (ASR) system for broadcast news and conversations within the GALE 2006 evaluation. Through the span of 9 month in preparation for this evaluation we improved our …"
15,"D Heger, F Putze, C Amma, M Wand, I Plotkin…","BiosignalsStudio: a flexible framework for biosignal capturing and processing",2010,"Annual Conference on …","Springer","https://link.springer.com/chapter/10.1007/978-3-642-16111-7_3","https://scholar.google.com/scholar?cites=4579113770727357006&as_sdt=2005&sciodt=0,5&hl=en",195,"2020-11-06 21:29:44","","","","",,,,,15,1.50,3,6,10,"In this paper we introduce BiosignalsStudio (BSS), a framework for multimodal sensor data acquisition. Due to its flexible architecture it can be used for large scale multimodal data collections as well as a multimodal input layer for intelligent systems. The paper describes …"
14,"M Wand, SCS Jou, AR Toth…","Impact of different speaking modes on EMG-based speech recognition",2009,"Tenth Annual Conference …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2009/i09_0648.html","https://scholar.google.com/scholar?cites=13441344660204451165&as_sdt=2005&sciodt=0,5&hl=en",196,"2020-11-06 21:29:44","","","","",,,,,14,1.27,4,4,11,"We present our recent results on speech recognition by surface electromyography (EMG), which captures the electric potentials that are generated by the human articulatory muscles. This technique can be used to enable Silent Speech Interfaces, since EMG signals are …"
14,"T Schultz, A Waibel","Language portability in acoustic modeling",2000,"Workshop On Multilingual Speech …","researchgate.net","https://www.researchgate.net/profile/Tanja_Schultz/publication/36452925_Language_portability_in_acoustic_modeling/links/547836820cf2a961e484b542/Language-portability-in-acoustic-modeling.pdf","https://scholar.google.com/scholar?cites=4705629335005102516&as_sdt=2005&sciodt=0,5&hl=en",197,"2020-11-06 21:29:44","PDF","","","",,,,,14,0.70,7,2,20,"With the distribution of speech technology products all over the world, the portability to new target languages becomes a practical concern. As a consequence our research focuses on the question of how to port LVCSR systems in a fast and efficient way. More specifically we …"
20,"M Wand, M Janke, T Schultz","The EMG-UKA corpus for electromyographic speech processing",2014,"Fifteenth Annual Conference of the …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2014/i14_1593.html","https://scholar.google.com/scholar?cites=9769513811486083379&as_sdt=2005&sciodt=0,5&hl=en",198,"2020-11-06 21:29:44","","","","",,,,,20,3.33,7,3,6,"This article gives an overview of the EMG-UKA corpus, a corpus of electromyographic (EMG) recordings of articulatory activity enabling speech processing (in particular speech recognition and synthesis) based on EMG signals, with the purpose of building Silent …"
8,"F Putze, M Schünemann, T Schultz…","Automatic classification of auto-correction errors in predictive text entry based on EEG and context information",2017,"Proceedings of the 19th …","dl.acm.org","https://dl.acm.org/doi/abs/10.1145/3136755.3136784","https://scholar.google.com/scholar?cites=15750897073996500077&as_sdt=2005&sciodt=0,5&hl=en",199,"2020-11-06 21:29:44","","","","",,,,,8,2.67,2,4,3,"State-of-the-art auto-correction methods for predictive text entry systems work reasonably well, but can never be perfect due to the properties of human language. We present an approach for the automatic detection of erroneous auto-corrections based on brain activity …"
15,"C Herff, O Fortmann, CY Tse, X Cheng…","Hybrid fNIRS-EEG based discrimination of 5 levels of memory load",2015,"2015 7th …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/7146546/?casa_token=KF35A5lTtK4AAAAA:RElWGySLnwfdOKNj3nOy0KHXHUNOo5uQvpb9yY7rBHaAtpZweZbDPfuZC3pzdH-47SAeEG2E-Q","https://scholar.google.com/scholar?cites=4907287606917348826&as_sdt=2005&sciodt=0,5&hl=en",200,"2020-11-06 21:29:44","","","","",,,,,15,3.00,3,5,5,"In this study, we show that both electroencephalograhy (EEG) and functional Near-Infrared Spectroscopy (fNIRS) can be used to discriminate between 5 levels of memory load. We induce memory load with the memory updating task, which is known to robustly generate …"
15,"T Schlippe, W Quaschningk…","Combining grapheme-to-phoneme converter outputs for enhanced pronunciation generation in low-resource scenarios",2014,"… Language Technologies for …","isca-speech.org","https://www.isca-speech.org/archive/sltu_2014/sl14_139.html","https://scholar.google.com/scholar?cites=447019230445477917&as_sdt=2005&sciodt=0,5&hl=en",201,"2020-11-06 21:29:44","","","","",,,,,15,2.50,5,3,6,"For pronunciation dictionary creation, we propose the combination of grapheme-to-phoneme (G2P) converter outputs where low resources are available to train the single converters. Our experiments with German, English, French, and Spanish show that in most …"
13,"M Honal, T Schultz","Determine Task Demand from Brain Activity.",2008,"BIOSIGNALS (1)","csl.uni-bremen.de","https://www.csl.uni-bremen.de/cms/images/documents/publications/HonalSchultz_Biosignals2008.pdf","https://scholar.google.com/scholar?cites=11850576461354342310&as_sdt=2005&sciodt=0,5&hl=en",202,"2020-11-06 21:29:44","PDF","","","",,,,,13,1.08,7,2,12,"Our society demands ubiquitous mobile devices that offer seamless interaction with everybody, everything, everywhere, at any given time. However, the effectiveness of these devices is limited due to their lack of situational awareness and sense for the users' needs …"
13,"T Schultz, A Waibel","Language adaptive lvcsr through polyphone decision tree specialization",2000,"","KARLSRUHE UNIV (GERMANY FR)","","https://scholar.google.com/scholar?cites=1702410786936981539&as_sdt=2005&sciodt=0,5&hl=en",203,"2020-11-06 21:29:44","CITATION","","","",,,,,13,0.65,7,2,20,""
14,"F Stahlberg, T Schlippe, S Vogel…","Towards automatic speech recognition without pronunciation dictionary, transcribed speech and text resources in the target language using cross-lingual word-to …",2014,"… Technologies for Under …","isca-speech.org","https://www.isca-speech.org/archive/sltu_2014/sl14_073.html","https://scholar.google.com/scholar?cites=3984321960211966318&as_sdt=2005&sciodt=0,5&hl=en",204,"2020-11-06 21:29:44","","","","",,,,,14,2.33,4,4,6,"In this paper we tackle the task of bootstrapping an Automatic Speech Recognition system without an a priori given language model, a pronunciation dictionary, or transcribed speech data for the target language Slovene–only untranscribed speech and translations to other …"
13,"R Hsiao, M Fuhs, YC Tam, Q Jin…","The CMU-InterACT 2008 mandarin transcription system",2008,"Ninth Annual Conference …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2008/i08_1445.html","https://scholar.google.com/scholar?cites=17412998706269650646&as_sdt=2005&sciodt=0,5&hl=en",205,"2020-11-06 21:29:44","","","","",,,,,13,1.08,3,5,12,"We present our Mandarin BN/BC transcription system recently developed for the GALE07 evaluation. The system employs a 3-pass decoding strategy trained with over 1300 hours of quickly transcribed audio. We successfully apply discriminative training, dynamic …"
13,"D Heger, C Herff, F Putze, R Mutter…","Continuous affective states recognition using functional near infrared spectroscopy",2014,"Brain-Computer …","Taylor & Francis","https://www.tandfonline.com/doi/abs/10.1080/2326263X.2014.912884","https://scholar.google.com/scholar?cites=16070512356309744003&as_sdt=2005&sciodt=0,5&hl=en",206,"2020-11-06 21:29:44","","","","",,,,,13,2.17,3,5,6,"Monitoring the affective states of a person can be highly relevant for numerous disciplines, including adaptive user interfaces, entertainment, ergonomics, medicine and therapy. In many situations, the affective state of a user is not easily observable from outside by audio or …"
13,"D Heger, F Putze, T Schultz","An EEG adaptive information system for an empathic robot",2011,"International Journal of Social Robotics","Springer","https://link.springer.com/content/pdf/10.1007/s12369-011-0107-x.pdf","https://scholar.google.com/scholar?cites=5909431796671690300&as_sdt=2005&sciodt=0,5&hl=en",207,"2020-11-06 21:29:44","","","","",,,,,13,1.44,4,3,9,"This article introduces a speech-driven information system for a humanoid robot that is able to adapt its information presentation strategy according to brain patterns of its user. Brain patterns are classified from electroencephalographic (EEG) signals and correspond to …"
13,"P Charoenpornsawat, T Schultz","Example-based Grapheme-to-Phoneme conversion for Thai",2006,"Ninth International Conference …","isca-speech.org","https://www.isca-speech.org/archive/archive_papers/interspeech_2006/i06_1782.pdf","https://scholar.google.com/scholar?cites=16793369170052097178&as_sdt=2005&sciodt=0,5&hl=en",208,"2020-11-06 21:29:44","","","","",,,,,13,0.93,7,2,14,"Several characteristics of the Thai writing system make Thai grapheme-to-phoneme (G2P) conversion very challenging. In this paper, we propose an Example-Based Grapheme-to-Phoneme conversion approach. It generates the pronunciation of a word by selecting …"
10,"F Putze, J Popp, J Hild, J Beyerer…","Intervention-free selection using EEG and eye tracking",2016,"Proceedings of the 18th …","dl.acm.org","https://dl.acm.org/doi/abs/10.1145/2993148.2993199","https://scholar.google.com/scholar?cites=6496522399884085272&as_sdt=2005&sciodt=0,5&hl=en",209,"2020-11-06 21:29:44","","","","",,,,,10,2.50,2,5,4,"In this paper, we show how recordings of gaze movements (via eye tracking) and brain activity (via electroencephalography) can be combined to provide an interface for implicit selection in a graphical user interface. This implicit selection works completely without …"
11,"L Diener, C Herff, M Janke…","An initial investigation into the real-time conversion of facial surface EMG signals to audible speech",2016,"2016 38th Annual …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/7590843/?casa_token=92SDIVphSigAAAAA:RCx5lZrSv4tvEif7P3q8zZf_cZxlaDWIPS_TsrXDJNDDvgPex0yCrMnHQOk0xu6uuI2IzUXPcA","https://scholar.google.com/scholar?cites=15845609935101408311&as_sdt=2005&sciodt=0,5&hl=en",210,"2020-11-06 21:29:44","","","","",,,,,11,2.75,3,4,4,"This paper presents early-stage results of our investigations into the direct conversion of facial surface electromyographic (EMG) signals into audible speech in a real-time setting, enabling novel avenues for research and system improvement through real-time feedback …"
13,"C Herff, M Janke, M Wand, T Schultz","Impact of different feedback mechanisms in EMG-based speech recognition",2011,"Twelfth Annual Conference …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2011/i11_2213.html","https://scholar.google.com/scholar?cites=2704585161699541521&as_sdt=2005&sciodt=0,5&hl=en",211,"2020-11-06 21:29:44","","","","",,,,,13,1.44,3,4,9,"This paper reports on our recent research in the feedback effects of Silent Speech. Our technology is based on surface electromyography (EMG) which captures the electrical potentials of the human articulatory muscles rather than the acoustic speech signal. While …"
12,"K Laskowski, T Schultz","A geometric interpretation of non-target-normalized maximum cross-channel correlation for vocal activity detection in meetings",2007,"… Technologies 2007: The Conference of the …","aclweb.org","https://www.aclweb.org/anthology/N07-2023.pdf","https://scholar.google.com/scholar?cites=2142330723016427235&as_sdt=2005&sciodt=0,5&hl=en",212,"2020-11-06 21:29:44","PDF","","","",,,,,12,0.92,6,2,13,"Vocal activity detection is an important technology for both automatic speech recognition and automatic speech understanding. In meetings, standard vocal activity detection algorithms have been shown to be ineffective, because participants typically vocalize for …"
12,"M Wand, M Janke, T Schultz","Investigations on speaking mode discrepancies in EMG-based speech recognition",2011,"Twelfth Annual Conference of the …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2011/i11_0601.html","https://scholar.google.com/scholar?cites=10399974029514436478&as_sdt=2005&sciodt=0,5&hl=en",213,"2020-11-06 21:29:44","","","","",,,,,12,1.33,4,3,9,"In this paper we present our recent study on the impact of speaking mode variabilities on speech recognition by surface electromyography (EMG). Surface electromyography captures the electric potentials of the human articulatory muscles, which enables a user to …"
12,"F Stahlberg, T Schlippe, S Vogel, T Schultz","Pronunciation extraction from phoneme sequences through cross-lingual word-to-phoneme alignment",2013,"International Conference on …","Springer","https://link.springer.com/chapter/10.1007/978-3-642-39593-2_23","https://scholar.google.com/scholar?cites=14057486484355863354&as_sdt=2005&sciodt=0,5&hl=en",214,"2020-11-06 21:29:44","","","","",,,,,12,1.71,3,4,7,"With the help of written translations in a source language, we cross-lingually segment phoneme sequences in a target language into word units using our new alignment model Model 3P [17]. From this, we deduce phonetic transcriptions of target language words …"
13,"T Schlippe, S Ochs, NT Vu, T Schultz","Automatic error recovery for pronunciation dictionaries",2012,"… Annual Conference of the …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2012/i12_2298.html","https://scholar.google.com/scholar?cites=17795025512122005334&as_sdt=2005&sciodt=0,5&hl=en",215,"2020-11-06 21:29:44","","","","",,,,,13,1.63,3,4,8,"In this paper, we present our latest investigations on pronunciation modeling and its impact on ASR. We propose completely automatic methods to detect, remove, and substitute inconsistent or flawed entries in pronunciation dictionaries. The experiments were …"
13,"Q Jin, R Li, Q Yang, K Laskowski…","Speaker identification with distant microphone speech",2010,"2010 IEEE International …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/5495590/?casa_token=bKIXpCbmaWsAAAAA:lOB_60hYVhhKQVtwINg8IGFktT8Xm0Y7Zu936YZwPzGTbzeDpkunwAyUvxkXen9jOn8YlOfEnw","https://scholar.google.com/scholar?cites=16871751592486080325&as_sdt=2005&sciodt=0,5&hl=en",216,"2020-11-06 21:29:44","","","","",,,,,13,1.30,3,5,10,"The field of speaker identification has recently seen significant advancement, but improvements have tended to be benchmarked on near-field speech, ignoring the more realistic setting of far-field-instrumented speakers. In this work we present several findings …"
13,"U Nallasamy, F Metze, T Schultz","Active learning for accent adaptation in automatic speech recognition",2012,"2012 IEEE Spoken …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/6424250/?casa_token=l-dwctCuf08AAAAA:LyP5L82xA0M9t3A6Uics54ABx7rW6RjpGdBvUZ3oQqcbdSBW2qndAfTnRxtdLmHvgU4CWs0EuQ","https://scholar.google.com/scholar?cites=14949222298687127327&as_sdt=2005&sciodt=0,5&hl=en",217,"2020-11-06 21:29:44","","","","",,,,,13,1.63,4,3,8,"We experiment with active learning for speech recognition in the context of accent adaptation. We adapt a source recognizer on the target accent by selecting a relatively small, matched subset of utterances from a large, untranscribed and multi-accented corpus …"
3,"M Barandas, D Folgado, L Fernandes, S Santos…","TSFEL: Time Series Feature Extraction Library",2020,"SoftwareX","Elsevier","https://www.sciencedirect.com/science/article/pii/S2352711020300017","https://scholar.google.com/scholar?cites=4241177767128955227&as_sdt=2005&sciodt=0,5&hl=en",218,"2020-11-06 21:29:44","HTML","","","",,,,,3,3.00,1,5,1,"Time series feature extraction is one of the preliminary steps of conventional machine learning pipelines. Quite often, this process ends being a time consuming and complex task as data scientists must consider a combination between a multitude of domain knowledge …"
4,"F Putze, C Herff, C Tremmel, T Schultz…","Decoding mental workload in virtual environments: a fNIRs study using an immersive n-back task",2019,"2019 41st Annual …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/8856386/?casa_token=6RuLu6zqPGsAAAAA:rKRIkF2doik3dPNnUc38HE8dcdCRmqpuhGc7FtpwQKp7c2maYDcEWnaSacmXWGK2bmc5V-g0zQ","https://scholar.google.com/scholar?cites=7036422055586197456&as_sdt=2005&sciodt=0,5&hl=en",219,"2020-11-06 21:29:44","","","","",,,,,4,4.00,1,5,1,"Virtual Reality (VR) has emerged as a novel paradigm for immersive applications in training, entertainment, rehabilitation, and other domains. In this paper, we investigate the automatic classification of mental workload from brain activity measured through functional near …"
7,"J Weiner, M Angrick, S Umesh, T Schultz","Investigating the Effect of Audio Duration on Dementia Detection Using Acoustic Features.",2018,"INTERSPEECH","csl.uni-bremen.de","https://www.csl.uni-bremen.de/cms/images/documents/publications/Interspeech2018_WeinerEtAl.pdf","https://scholar.google.com/scholar?cites=7764713870730459213&as_sdt=2005&sciodt=0,5&hl=en",220,"2020-11-06 21:29:44","PDF","","","",,,,,7,3.50,2,4,2,"This paper presents recent progress toward our goal to enable area-wide pre-screening methods for the early detection of dementia based on automatically processing conversational speech of a representative group of more than 200 subjects. We focus on …"
11,"D Gehrig, T Stein, A Fischer, H Schwameder…","Towards semantic segmentation of human motion sequences",2010,"Annual Conference on …","Springer","https://link.springer.com/chapter/10.1007/978-3-642-16111-7_50","https://scholar.google.com/scholar?cites=324603926570875576&as_sdt=2005&sciodt=0,5&hl=en",221,"2020-11-06 21:29:44","","","","",,,,,11,1.10,2,5,10,"In robotics research is an increasing need for knowledge about human motions. However humans tend to perceive motion in terms of discrete motion primitives. Most systems use data-driven motion segmentation to retrieve motion primitives. Besides that the actual …"
13,"D Gehrig, T Schultz","Selecting relevant features for human motion recognition",2008,"2008 19th International Conference on …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/4761290/?casa_token=YS67BPzAQ84AAAAA:sa6fzyQ9Q1C-DfYrNz9IgdNBklQ_Nsr0TBQwe-qqwQ2b8UvzobB-hmhDx0WOi2yMg4CThtvKXg","https://scholar.google.com/scholar?cites=4748120568782647686&as_sdt=2005&sciodt=0,5&hl=en",222,"2020-11-06 21:29:44","","","","",,,,,13,1.08,7,2,12,"Recently, there is a growing interest in automatic recognition of human motion for applications, such as humanoid robots, human activity monitoring, and surveillance. In this paper we investigate motion recognition based on joint angle trajectories derived from …"
12,"T Schultz, I Rogina, A Waibel","Experiments with LVCSR based language identification",1995,"proc. ICASSP","researchgate.net","https://www.researchgate.net/profile/Tanja_Schultz/publication/2302841_Experiments_With_Lvcsr_Based_Language_Identification/links/5d9b1186458515c1d39c8179/Experiments-With-Lvcsr-Based-Language-Identification.pdf","https://scholar.google.com/scholar?cites=6788498793361762313&as_sdt=2005&sciodt=0,5&hl=en",223,"2020-11-06 21:29:44","PDF","","","",,,,,12,0.48,4,3,25,"Automatic language identi cation is an important problem in building multilingual speech recognition and understanding systems. We have developed a front-end LID module based on LVCSR to identify English, German, and Spanish language for use in spontaneous …"
11,"R Li, T Schultz, Q Jin","Improving speaker segmentation via speaker identification and text segmentation",2009,"Tenth Annual Conference of the …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2009/i09_0904.html","https://scholar.google.com/scholar?cites=5676229437900986618&as_sdt=2005&sciodt=0,5&hl=en",224,"2020-11-06 21:29:44","","","","",,,,,11,1.00,4,3,11,"Speaker segmentation is an essential part of a speaker diarization system. Common segmentation systems usually miss speaker change points when speakers switch fast. These errors seriously confuse the following speaker clustering step and result in high …"
11,"R Sarikaya, K Kirchhoff, T Schultz…","Introduction to the special issue on processing morphologically rich languages",2009,"IEEE Transactions on …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/5075779/","https://scholar.google.com/scholar?cites=16302022161884222511&as_sdt=2005&sciodt=0,5&hl=en",225,"2020-11-06 21:29:44","","","","",,,,,11,1.00,3,4,11,"THE past decade has witnessed significant advances in core speech and natural language processing algorithms as well as a continual increase in the amount of linguistic resources. As a consequence, speech and natural language pro- cessing technology (including applications …"
12,"T Schultz, K Kirchhoff","Multilingual acoustic modeling",2006,"Multilingual Speech Processing","","","https://scholar.google.com/scholar?cites=13480518919671442920&as_sdt=2005&sciodt=0,5&hl=en",226,"2020-11-06 21:29:44","CITATION","","","",,,,,12,0.86,6,2,14,""
11,"NT Vu, W Breiter, F Metze, T Schultz","Initialization schemes for multilayer perceptron training and their impact on asr performance using multilingual data",2012,"… Annual Conference of the …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2012/i12_2586.html","https://scholar.google.com/scholar?cites=3226106332513277726&as_sdt=2005&sciodt=0,5&hl=en",227,"2020-11-06 21:29:44","","","","",,,,,11,1.38,3,4,8,"In this paper we present our latest investigation on initialization schemes for Multilayer Perceptron (MLP) training using multilingual data. We show that the overall performance of a MLP network improves significantly by initializing it with a multilingual MLP. We propose a …"
12,"H Adel, D Telaar, NT Vu, K Kirchhoff…","Combining recurrent neural networks and factored language models during decoding of code-switching speech",2014,"… Annual Conference of …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2014/i14_1415.html","https://scholar.google.com/scholar?cites=3369120050816265651&as_sdt=2005&sciodt=0,5&hl=en",228,"2020-11-06 21:29:44","","","","",,,,,12,2.00,2,5,6,"In this paper, we present our latest investigations of language modeling for Code-Switching. Since there is only little text material for Code-Switching speech available, we integrate syntactic and semantic features into the language modeling process. In particular, we use …"
2,"D Küster, EG Krumhuber, L Steinert…","Opportunities and challenges for using automatic human affect analysis in consumer research",2020,"Frontiers in …","ncbi.nlm.nih.gov","https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7199103/","https://scholar.google.com/scholar?cites=15075166526644153699&as_sdt=2005&sciodt=0,5&hl=en",229,"2020-11-06 21:29:44","HTML","","","",,,,,2,2.00,1,4,1,"The ability to automatically assess emotional responses via contact-free video recording taps into a rapidly growing market aimed at predicting consumer choices. If consumer attention and engagement are measurable in a reliable and accessible manner, relevant …"
13,"C Amma, TM Schultz","Method and system for handwriting and gesture recognition",2016,"US Patent App. 15/246,639","Google Patents","https://patents.google.com/patent/US20160364010A1/en","https://scholar.google.com/scholar?cites=10282089288513558539&as_sdt=2005&sciodt=0,5&hl=en",230,"2020-11-06 21:29:44","","","","",,,,,13,3.25,7,2,4,"In general, a system can include an interface component configured to receive measurement data from a motion sensor unit physically coupled with a movable part of a body of a user. The measurement data can include sensor data of a sensor of the motion …"
3,"MY Tachbelie, ST Abate, T Schultz","Analysis of globalphone and ethiopian languages speech corpora for multilingual asr",2020,"Proceedings of The 12th Language …","aclweb.org","https://www.aclweb.org/anthology/2020.lrec-1.511/","https://scholar.google.com/scholar?cites=3940517749573960319&as_sdt=2005&sciodt=0,5&hl=en",231,"2020-11-06 21:29:44","","","","",,,,,3,3.00,1,3,1,"In this paper, we present the analysis of GlobalPhone (GP) and speech corpora of Ethiopian languages (Amharic, Tigrigna, Oromo and Wolaytta). The aim of the analysis is to select speech data from GP for the development of multilingual Automatic Speech Recognition …"
11,"M Wand, T Schultz","Speaker-adaptive speech recognition based on surface electromyography",2009,"… Joint Conference on Biomedical Engineering Systems …","Springer","https://link.springer.com/chapter/10.1007/978-3-642-11721-3_21","https://scholar.google.com/scholar?cites=9607476524938765179&as_sdt=2005&sciodt=0,5&hl=en",232,"2020-11-06 21:29:44","","","","",,,,,11,1.00,6,2,11,"We present our recent advances in silent speech interfaces using electromyographic signals that capture the movements of the human articulatory muscles at the skin surface for recognizing continuously spoken speech. Previous systems were limited to speaker-and …"
12,"NT Vu, T Schultz","Exploration of the impact of maximum entropy in recurrent neural network language models for code-switching speech",2014,"Proceedings of The First Workshop on Computational …","aclweb.org","https://www.aclweb.org/anthology/W14-3904.pdf","https://scholar.google.com/scholar?cites=10635567175978228247&as_sdt=2005&sciodt=0,5&hl=en",233,"2020-11-06 21:29:44","PDF","","","",,,,,12,2.00,6,2,6,"This paper presents our latest investigations of the jointly trained maximum entropy and recurrent neural network language models for Code-Switching speech. First, we explore extensively the integration of part-of-speech tags and language identifier information in …"
10,"T Schultz, A Waibel","Development of Multi-lingual Acoustic Models in the GlobalPhone Project",1998,"Proceedings of the 1st Workshop on Text, Speech …","Citeseer","http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.10.6999&rep=rep1&type=pdf","https://scholar.google.com/scholar?cites=9011297897342492284&as_sdt=2005&sciodt=0,5&hl=en",234,"2020-11-06 21:29:44","PDF","","","",,,,,10,0.45,5,2,22,"This paper describes our recent e ort in developing the GlobalPhone recognizer for multilingual large vocabulary continuous speech. This project investigates LVCSR systems in 15 languages, namely Arabic, Chinese (Mandarin and Wu), Croatian, English, French …"
10,"P Geutner, B Suhm, FD Buø, T Kemp, L Mayfield…","Integrating different learning approaches into a multilingual spoken language translation system",1995,"… Joint Conference on …","Springer","https://link.springer.com/chapter/10.1007/3-540-60925-3_42","https://scholar.google.com/scholar?cites=7240081456567007416&as_sdt=2005&sciodt=0,5&hl=en",235,"2020-11-06 21:29:44","","","","",,,,,10,0.40,2,6,25,"Building multilingual spoken language translation systems requires knowledge about both acoustic models and language models of each language to be translated. Our multilingual translation system JANUS-2 is able to translate English and German spoken input into either …"
11,"YC Tam, T Schultz","Correlated bigram LSA for unsupervised language model adaptation",2009,"Advances in Neural Information Processing …","papers.nips.cc","http://papers.nips.cc/paper/3564-correlated-bigram-lsa-for-unsupervised-language-model-adaptation","https://scholar.google.com/scholar?cites=6769041926700275409&as_sdt=2005&sciodt=0,5&hl=en",236,"2020-11-06 21:29:44","","","","",,,,,11,1.00,6,2,11,"We propose using correlated bigram LSA for unsupervised LM adaptation for automatic speech recognition. The model is trained using efficient variational EM and smoothed using the proposed fractional Kneser-Ney smoothing which handles fractional counts. Our …"
13,"M Wand, A Himmelsbach…","Artifact removal algorithm for an EMG-based Silent Speech Interface",2013,"2013 35th Annual …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/6610857/?casa_token=f0vjqGp4nesAAAAA:SAg15bU_mkRhXKgdcKmTnZZyD1IVQEiHUlwMkFqO_vSCSSdxZEA0aBSylFZgsDiRcpHF_mAQ6Q","https://scholar.google.com/scholar?cites=5269233261043402925&as_sdt=2005&sciodt=0,5&hl=en",237,"2020-11-06 21:29:44","","","","",,,,,13,1.86,4,3,7,"An electromygraphic (EMG) Silent Speech Interface is a system which recognizes speech by capturing the electric potentials of the human articulatory muscles, thus enabling the user to communicate silently. This study deals with improving the EMG signal quality by removing …"
10,"NT Vu, Y Wang, M Klose, Z Mihaylova…","Improving ASR performance on non-native speech using multilingual and crosslingual information",2014,"… Annual Conference of …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2014/i14_0011.html","https://scholar.google.com/scholar?cites=14589447301876565120&as_sdt=2005&sciodt=0,5&hl=en",238,"2020-11-06 21:29:44","","","","",,,,,10,1.67,2,5,6,"This paper presents our latest investigation of automatic speech recognition (ASR) on non-native speech. We first report on a non-native speech corpus-an extension of the GlobalPhone database-which contains English with Bulgarian, Chinese, German and Indian …"
5,"F Putze, M Salous, T Schultz","Detecting memory-based interaction obstacles with a recurrent neural model of user behavior",2018,"23rd International Conference on …","dl.acm.org","https://dl.acm.org/doi/abs/10.1145/3172944.3173006","https://scholar.google.com/scholar?cites=9840620894694782860&as_sdt=2005&sciodt=0,5&hl=en",239,"2020-11-06 21:29:44","","","","",,,,,5,2.50,2,3,2,"ABSTRACT A memory-based interaction obstacle is a condition which impedes human memory during Human-Computer Interaction, for example a memory-loading secondary task. In this paper, we present an approach to detect the presence of such memory-based …"
1,"L Diener, S Amiriparian, C Botelho…","Towards silent paralinguistics: Deriving speaking mode and speaker ID from electromyographic signals",2020,"Proc …","indico2.conference4me.psnc.pl","https://indico2.conference4me.psnc.pl/event/35/contributions/3549/attachments/1109/1151/Wed-3-3-1.pdf","https://scholar.google.com/scholar?cites=9699671864203866089&as_sdt=2005&sciodt=0,5&hl=en",240,"2020-11-06 21:29:44","PDF","","","",,,,,1,1.00,0,4,1,"Abstract Silent Computational Paralinguistics (SCP)–the assessment of speaker states and traits from non-audibly spoken communication–has rarely been targeted in the rich body of either Computational Paralinguistics or Silent Speech Processing. Here, we provide first …"
8,"M Wand, T Schultz, J Schmidhuber","Domain-Adversarial Training for Session Independent EMG-based Speech Recognition.",2018,"INTERSPEECH","isca-speech.org","https://www.isca-speech.org/archive/Interspeech_2018/pdfs/2318.pdf","https://scholar.google.com/scholar?cites=17323112853041956871&as_sdt=2005&sciodt=0,5&hl=en",241,"2020-11-06 21:29:44","","","","",,,,,8,4.00,3,3,2,"We present our research on continuous speech recognition based on Surface Electromyography (EMG), where speech information is captured by electrodes attached to the speaker's face. This method allows speech processing without requiring that an acoustic …"
9,"YC Tam, T Schultz","Bilingual LSA-based translation lexicon adaptation for spoken language translation",2007,"Eighth Annual Conference of the International …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2007/i07_2461.html","https://scholar.google.com/scholar?cites=16051567459155293211&as_sdt=2005&sciodt=0,5&hl=en",242,"2020-11-06 21:29:44","","","","",,,,,9,0.69,5,2,13,"We present a bilingual LSA (bLSA) framework for translation lexicon adaptation. The idea is to apply marginal adaptation on a translation lexicon so that the lexicon marginals match to indomain marginals. In the framework of speech translation, the bLSA method transfers topic …"
9,"D Heger, F Putze, T Schultz","An adaptive information system for an empathic robot using EEG data",2010,"International Conference on Social Robotics","Springer","https://link.springer.com/chapter/10.1007/978-3-642-17248-9_16","https://scholar.google.com/scholar?cites=10983484833111975836&as_sdt=2005&sciodt=0,5&hl=en",243,"2020-11-06 21:29:44","","","","",,,,,9,0.90,3,3,10,"In this paper we introduce a speech-based information system for a humanoid robot that is able to adapt its information presentation strategy to different brain patterns of its user. Brain patterns are classified from electroencephalographic (EEG) signals and correspond to …"
9,"R Hsiao, T Schultz","Generalized Baum-Welch algorithm and its implication to a new extended Baum-Welch algorithm",2011,"Twelfth Annual Conference of the International …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2011/i11_0773.html","https://scholar.google.com/scholar?cites=6519570309074636763&as_sdt=2005&sciodt=0,5&hl=en",244,"2020-11-06 21:29:44","","","","",,,,,9,1.00,5,2,9,"This paper describes how we can use the generalized Baum-Welch (GBW) algorithm to develop better extended Baum-Welch (EBW) algorithms. Based on GBW, we show that the backoff term in the EBW algorithm comes from KL-divergence which is used as a …"
9,"T Heistermann, M Janke, M Wand, T Schultz","Spatial Artifact Detection for Multi-channel EMG-based Speech Recognition.",2014,"BIOSIGNALS","scitepress.org","https://www.scitepress.org/papers/2014/47939/47939.pdf","https://scholar.google.com/scholar?cites=8814790083481215738&as_sdt=2005&sciodt=0,5&hl=en",245,"2020-11-06 21:29:44","PDF","","","",,,,,9,1.50,2,4,6,"We introduce a spatial artifact detection method for a surface electromyography (EMG) based speech recognition system. The EMG signals are recorded using grid-shaped electrode arrays affixed to the speakers face. Continuous speech recognition is performed …"
9,"T Schultz","Multilinguale Spracherkennung",2000,"Kombination akustischer Modelle zur Portierung auf …","","","https://scholar.google.com/scholar?cites=13819914434114144339&as_sdt=2005&sciodt=0,5&hl=en",246,"2020-11-06 21:29:44","CITATION","","","",,,,,9,0.45,9,1,20,""
10,"B Zhao, T Schultz","Toward robust parametric trajectory segmental model for vowel recognition",2002,"IEEE INTERNATIONAL CONFERENCE ON …","Citeseer","http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.65.1553&rep=rep1&type=pdf","https://scholar.google.com/scholar?cites=11655238904017843130&as_sdt=2005&sciodt=0,5&hl=en",247,"2020-11-06 21:29:44","PDF","","","",,,,,10,0.56,5,2,18,"In this paper we present a robust and discriminative segmental trajectory modeling for vowel recognition. We proposed two new approaches. One is using weighted least square estimation for the parametric trajectory parameter, which gives a much more robust …"
9,"F Putze, T Schultz","Cognitive memory modeling for interactive systems in dynamic environments",2009,"International Workshop Series on …","pdfs.semanticscholar.org","https://pdfs.semanticscholar.org/a22c/f4c5af4f6c0f24219d84d5c9e15c751e27a8.pdf","https://scholar.google.com/scholar?cites=14766132009152018605&as_sdt=2005&sciodt=0,5&hl=en",248,"2020-11-06 21:29:44","PDF","","","",,,,,9,0.82,5,2,11,"This paper presents our ongoing work on cognitive modeling components designed for applications in adaptive dialog systems for dynamic environments. We believe that insight into which information the user currently processes is necessary to build dialog systems that …"
9,"D Rebelo, C Amma, H Gamboa, T Schultz","Human Activity Recognition for an Intelligent Knee Orthosis.",2013,"BIOSIGNALS","scitepress.org","https://scitepress.org/papers/2013/42549/42549.pdf","https://scholar.google.com/scholar?cites=11863465876862021612&as_sdt=2005&sciodt=0,5&hl=en",249,"2020-11-06 21:29:44","PDF","","","",,,,,9,1.29,2,4,7,"This paper investigates the possibility to classify isolated human activities from biosignal sensors integrated into a knee orthosis. An intelligent orthosis that is capable to recognize its wearers activity would be able to adapt itself to the users situation for enhanced comfort. We …"
9,"A Kurematsu, Y Akegami, S Burger…","Verbmobil dialogues: Multifaced analysis",2000,"… on Spoken Language …","isca-speech.org","https://www.isca-speech.org/archive/archive_papers/icslp_2000/i00_4712.pdf","https://scholar.google.com/scholar?cites=10935001708625790684&as_sdt=2005&sciodt=0,5&hl=en",250,"2020-11-06 21:29:44","","","","",,,,,9,0.45,2,4,20,"This paper describes the outline of collecting and transcribing spontaneous spoken dialogues for VERBMOBIL, the German research project on multilingual processing of spontaneous speech. The method and conditions of data collection performed using the …"
8,"M Wand, SCS Jou, T Schultz","Wavelet-based front-end for electromyographic speech recognition",2007,"Eighth Annual Conference of the …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2007/i07_0686.html","https://scholar.google.com/scholar?cites=16664837013489756911&as_sdt=2005&sciodt=0,5&hl=en",251,"2020-11-06 21:29:44","","","","",,,,,8,0.62,3,3,13,"In this paper we present our investigations on the potential of wavelet-based preprocessing for surface electromyographic speech recognition. We implemented several variants of the Discrete Wavelet Transform and applied them to electromyographical data. First we …"
9,"F Stahlberg, T Schlippe, S Vogel, T Schultz","Word segmentation and pronunciation extraction from phoneme sequences through cross-lingual word-to-phoneme alignment",2016,"Computer Speech & …","Elsevier","https://www.sciencedirect.com/science/article/pii/S0885230814000977","https://scholar.google.com/scholar?cites=4792603259529004322&as_sdt=2005&sciodt=0,5&hl=en",252,"2020-11-06 21:29:44","","","","",,,,,9,2.25,2,4,4,"In this paper, we study methods to discover words and extract their pronunciations from audio data for non-written and under-resourced languages. We examine the potential and the challenges of pronunciation extraction from phoneme sequences through cross-lingual …"
8,"S Leidig, T Schlippe, T Schultz","Automatic detection of anglicisms for the pronunciation dictionary generation: a case study on our German IT corpus",2014,"Spoken Language Technologies …","isca-speech.org","https://www.isca-speech.org/archive/sltu_2014/sl14_207.html","https://scholar.google.com/scholar?cites=4301562999119143135&as_sdt=2005&sciodt=0,5&hl=en",253,"2020-11-06 21:29:44","","","","",,,,,8,1.33,3,3,6,"With the globalization more and more words from other languages come into a language without assimilation to the phonetic system of the new language. To economically build up lexical resources with automatic or semi-automatic methods, it is important to detect and …"
8,"J Kominek, T Schultz, AW Black","Voice building from insufficient data-classroom experiences with web-based language development tools.",2007,"SSW","cs.cmu.edu","https://www.cs.cmu.edu/afs/cs.cmu.edu/Web/People/awb/papers/ssw6/ssw6_322.pdf","https://scholar.google.com/scholar?cites=3117273626428948436&as_sdt=2005&sciodt=0,5&hl=en",254,"2020-11-06 21:29:44","PDF","","","",,,,,8,0.62,3,3,13,"To make the goal of building voices in new languages easier and more accessible to non-experts, the combined tasks of phoneme set definition, text selection, prompt recording, lexicon building, and voice creation in Festival are now integrated behind a web-based …"
8,"M Wand, M Janke, T Schultz","Decision-tree based Analysis of Speaking Mode Discrepancies in EMG-based Speech Recognition.",2012,"BIOSIGNALS","scitepress.org","https://www.scitepress.org/Papers/2012/37872/37872.pdf","https://scholar.google.com/scholar?cites=3543761512637152177&as_sdt=2005&sciodt=0,5&hl=en",255,"2020-11-06 21:29:44","PDF","","","",,,,,8,1.00,3,3,8,"This study is concerned with the impact of speaking mode variabilities on speech recognition by surface electromyography (EMG). In EMG-based speech recognition, we capture the electric potentials of the human articulatory muscles by surface electrodes, so …"
3,"MY Tachbelie, A Abulimiti, ST Abate…","Dnn-based speech recognition for globalphone languages",2020,"ICASSP 2020-2020 …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/9053144/?casa_token=WHYMn_9WsDIAAAAA:G65BJJdFQM4SVsi8phpJgZ9fxM-V4KowWZetNAj6xpSd4woIksGEPsBphZCEOAoh-8EIbFc3ew","https://scholar.google.com/scholar?cites=12787073622949353673&as_sdt=2005&sciodt=0,5&hl=en",256,"2020-11-06 21:29:44","","","","",,,,,3,3.00,1,4,1,"This paper describes new reference benchmark results based on hybrid Hidden Markov Model and Deep Neural Networks (HMM-DNN) for the GlobalPhone (GP) multilingual text and speech database. GP is a multilingual database of high-quality read speech with …"
1,"S Manghat, S Manghat, T Schultz","Malayalam-English Code-Switched: Grapheme to Phoneme System",2020,"Proc. Interspeech 2020","isca-speech.org","https://isca-speech.org/archive/Interspeech_2020/pdfs/1936.pdf","https://scholar.google.com/scholar?cites=9336354185655845479&as_sdt=2005&sciodt=0,5&hl=en",257,"2020-11-06 21:29:44","","","","",,,,,1,1.00,0,3,1,"Grapheme to phoneme conversion is an integral aspect of speech processing. Conversational speech in Malayalam–a low resource Indic language has inter-sentential, intrasentential code-switching as well as frequent intra-word codeswitching with English …"
0,"F Putze, T Ihrig, T Schultz, W Stuerzlinger","Platform for Studying Self-Repairing Auto-Corrections in Mobile Text Entry based on Brain Activity, Gaze, and Context",2020,"Proceedings of the 2020 CHI …","dl.acm.org","https://dl.acm.org/doi/abs/10.1145/3313831.3376815","",258,"2020-11-06 21:29:44","","","","",,,,,0,0.00,0,4,1,"Auto-correction is a standard feature of mobile text entry. While the performance of state-of-the-art auto-correct methods is usually relatively high, any errors that occur are cumbersome to repair, interrupt the flow of text entry, and challenge the user's agency over the process. In …"
2,"C Frankenberg, J Weiner, T Schultz, M Knebel…","Perplexity–a new predictor of cognitive changes in spoken language?–results of the Interdisciplinary Longitudinal Study on Adult Development and Aging (ILSE)",2019,"Linguistics …","degruyter.com","https://www.degruyter.com/downloadpdf/journals/lingvan/5/s2/article-20180026.xml","https://scholar.google.com/scholar?cites=13990215037981912659&as_sdt=2005&sciodt=0,5&hl=en",259,"2020-11-06 21:29:44","","","","",,,,,2,2.00,0,5,1,"In addition to memory loss, progressive deterioration of speech and language skills is among the main symptoms at the onset of Alzheimer's disease (AD) as well as in mild cognitive impairment (MCI). Detailed interview analyses demonstrated early symptoms …"
7,"F Putze, M Scherer, T Schultz","Starring into the void? Classifying Internal vs. External Attention from EEG",2016,"… of the 9th Nordic Conference on Human …","dl.acm.org","https://dl.acm.org/doi/abs/10.1145/2971485.2971555","https://scholar.google.com/scholar?cites=6996296008590104824&as_sdt=2005&sciodt=0,5&hl=en",260,"2020-11-06 21:29:44","","","","",,,,,7,1.75,2,3,4,"For any HCI system, it would be a great advantage if it was aware of the attentional state of its user: Is he or she paying attention to external stimuli provided by the user's environment or is the user focusing his or her attention on internal mental tasks? In this paper, we …"
8,"SE Navarro, F Heger, F Putze, T Beyl…","Telemanipulation with force-based display of proximity fields",2015,"2015 IEEE/RSJ …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/7354027/","https://scholar.google.com/scholar?cites=2341109882181049787&as_sdt=2005&sciodt=0,5&hl=en",261,"2020-11-06 21:29:44","","","","",,,,,8,1.60,2,5,5,"In this paper we show and evaluate the design of a novel telemanipulation system that maps proximity values, acquired inside of a gripper, to forces a user can feel through a haptic input device. The command console is complemented by input-devices that give the user an …"
11,"C Herff, L Diener, M Angrick, E Mugler…","Generating Natural, Intelligible Speech From Brain Activity in Motor, Premotor, and Inferior Frontal Cortices",2019,"Frontiers in …","frontiersin.org","https://www.frontiersin.org/articles/10.3389/fnins.2019.01267/full?utm_source=S-TWT&utm_medium=SNET&utm_campaign=ECO_FNINS_XXXXXXXX_auto-dlvrit","https://scholar.google.com/scholar?cites=4902202305552040683&as_sdt=2005&sciodt=0,5&hl=en",262,"2020-11-06 21:29:44","HTML","","","",,,,,11,11.00,2,5,1,"Neural interfaces that directly produce intelligible speech from brain activity would allow people with severe impairment from neurological disorders to communicate more naturally. Here, we record neural population activity in motor, premotor and inferior frontal cortices …"
5,"L Diener, T Schultz","Investigating Objective Intelligibility in Real-Time EMG-to-Speech Conversion.",2018,"INTERSPEECH","csl.uni-bremen.de","https://csl.uni-bremen.de/cms/images/documents/publications/IS2018_EMG_Realtime.pdf","https://scholar.google.com/scholar?cites=11922971226098683141&as_sdt=2005&sciodt=0,5&hl=en",263,"2020-11-06 21:29:44","PDF","","","",,,,,5,2.50,3,2,2,"This paper presents an analysis of the influence of various system parameters on the output quality of our neural network based real-time EMG-to-Speech conversion system. This EMG-to-Speech system allows for the direct conversion of facial surface electromyographic …"
3,"H Schultz, U Skræp, TS Larsen, LE Rekvad…","Psychometric evaluation of the Danish version of a modified Revised American Pain Society Patient Outcome Questionnaire (APS-POQ-RD) for patients hospitalized …",2019,"… journal of pain","degruyter.com","https://www.degruyter.com/view/journals/sjpain/19/1/article-p117.xml","https://scholar.google.com/scholar?cites=1973652110875254686&as_sdt=2005&sciodt=0,5&hl=en",264,"2020-11-06 21:29:44","","","","",,,,,3,3.00,1,5,1,"Background and aims This paper forms part of a study evaluating the effect of patient-controlled oral analgesia for patients admitted to hospital with acute abdominal pain. Pain is a subjective experience, and a multifaceted evaluation tool concerning patient-reported …"
3,"J Weiner, T Schultz","Automatic screening for transition into dementia using speech",2018,"Speech Communication; 13th ITG …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/8577993/","https://scholar.google.com/scholar?cites=17796563654296240147&as_sdt=2005&sciodt=0,5&hl=en",265,"2020-11-06 21:29:44","","","","",,,,,3,1.50,2,2,2,"Diagnosing dementia early is crucial in mitigating the consequences of the disease for patients, their care-givers and relatives. We present automatic screening for personal transition into dementia from speech using information from more than one point in time …"
7,"A Waibel, H Soltau, T Schultz, T Schaaf, F Metze","Multilingual Speech Recognition. W: W. Wahlster (red.), Verbmobil: Foundations of Speech-to-Speech Translation (ss. 33-45)",2000,"","Berlin: Springer","","https://scholar.google.com/scholar?cites=5704628520274943400&as_sdt=2005&sciodt=0,5&hl=en",266,"2020-11-06 21:29:44","CITATION","","","",,,,,7,0.35,1,5,20,""
7,"C Amma, T Schultz","Airwriting: demonstrating mobile text input by 3D-space handwriting",2012,"Proceedings of the 2012 ACM international …","dl.acm.org","https://dl.acm.org/doi/abs/10.1145/2166966.2167032","https://scholar.google.com/scholar?cites=4473602760712291180&as_sdt=2005&sciodt=0,5&hl=en",267,"2020-11-06 21:29:44","","","","",,,,,7,0.88,4,2,8,"We demonstrate our airwriting interface for mobile hands-free text entry. The interface enables a user to input text into a computer by writing in the air like on an imaginary blackboard. Hand motion is measured by an accelerometer and a gyroscope attached to the …"
7,"D Heger, R Jäkel, F Putze, M Lösch…","Filling a glass of water: continuously decoding the speed of 3D hand movements from EEG signals",2012,"… Conference of the IEEE …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/6346867/?casa_token=Y5xsYNSGNpMAAAAA:vTAi2T31vz4vAeprA2oEHThVbSmxPjeNFBlwSfyU_vFyInahu8mhWhuLm_k7q7zkAUNPmr42Ug","https://scholar.google.com/scholar?cites=3400322164976699046&as_sdt=2005&sciodt=0,5&hl=en",268,"2020-11-06 21:29:44","","","","",,,,,7,0.88,1,5,8,"We present a new system for the continuous decoding of hand movement speed in three-dimensional (3D) space from EEG signals. We recorded experimental data of five subjects during mimicking the natural task of filling a glass of water. The proposed system uses filter …"
7,"N Bach, M Noamany, I Lane…","Handling oov words in arabic asr via flexible morphological constraints",2007,"Eighth Annual Conference …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2007/i07_2373.html","https://scholar.google.com/scholar?cites=9330113413500970169&as_sdt=2005&sciodt=0,5&hl=en",269,"2020-11-06 21:29:44","","","","",,,,,7,0.54,2,4,13,"We propose a novel framework to detect and recognize outof-vocabulary (OOV) words in automated speech recognition (ASR). In the proposed framework a hybrid language model combining words and sub-word units is incorporated during ASR decoding then three …"
7,"T Schultz, A Walbel","Methods and apparatuses for myoelectric-based speech processing",2011,"US Patent 8,082,149","Google Patents","https://patents.google.com/patent/US8082149B2/en","https://scholar.google.com/scholar?cites=449489911880274339&as_sdt=2005&sciodt=0,5&hl=en",270,"2020-11-06 21:29:44","","","","",,,,,7,0.78,4,2,9,"A method for myoelectric-based processing of speech. The method includes capturing a myoelectric signal from a user using at least one electrode, wherein the electrode converts an ionic current generated by muscle contraction into an electric current. The method also …"
7,"J Kominek, T Schultz, AW Black","Synthesizer voice quality on new languages calibrated with mel-cepstral distorion",2008,"in SLTU 2008, Hanoi, Viet Nam","Citeseer","http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.207.9283","https://scholar.google.com/scholar?cites=14497198924023481672&as_sdt=2005&sciodt=0,5&hl=en",271,"2020-11-06 21:29:44","","","","",,,,,7,0.58,2,3,12,"When developing synthesizers for new languages one must select a phoneset, record phonetically balanced sentences, build up a pronunciation lexicon, and evaluate the results. An objective measure of voice quality can be very useful, provided it is calibrated across …"
7,"G Ruske, B Plannerer, T Schultz","Stochastic modeling of syllable-based units for continuous speech recognition",1992,"Second International Conference …","isca-speech.org","https://www.isca-speech.org/archive/icslp_1992/i92_1503.html","https://scholar.google.com/scholar?cites=14872155350092239041&as_sdt=2005&sciodt=0,5&hl=en",272,"2020-11-06 21:29:44","","","","",,,,,7,0.25,2,3,28,"This paper presents a new concept for a demisyllable-based speech recognition system for German where final consonant clu-stcrs are subdivided into rudiments and suffixes. These units are represented by Semicontinuous HMMs. All equations for modeling the time …"
8,"T Schultz","ICCHP keynote: Recognizing silent and weak speech based on electromyography",2010,"… Conference on Computers for Handicapped Persons","Springer","https://link.springer.com/chapter/10.1007/978-3-642-14097-6_96","https://scholar.google.com/scholar?cites=13672763184836228103&as_sdt=2005&sciodt=0,5&hl=en",273,"2020-11-06 21:29:44","","","","",,,,,8,0.80,8,1,10,"In the past decade, the performance of automatic speech processing systems, including speech recognition, spoken language translation, and speech synthesis, has improved dramatically. This has resulted in an increasingly widespread use of speech and language …"
7,"H Kuehne, D Gehrig, T Schultz, R Stiefelhagen","On-line Action Recognition from Sparse Feature Flow.",2012,"VISAPP (1)","scitepress.org","https://scitepress.org/papers/2012/38615/38615.pdf","https://scholar.google.com/scholar?cites=2138536973160562835&as_sdt=2005&sciodt=0,5&hl=en",274,"2020-11-06 21:29:44","PDF","","","",,,,,7,0.88,2,4,8,"The fast and robust recognition of human actions is an important aspect for many video-based applications in the field of human computer interaction and surveillance. Although current recognition algorithms provide more and more advanced results, their usability for on …"
5,"C Mason, M Meier, F Ahrens, T Fehr, M Herrmann…","Human activities data collection and labeling using a think-aloud protocol in a table setting scenario",2018,"","csl.uni-bremen.de","https://www.csl.uni-bremen.de/cms/images/documents/publications/mason_iros_2018.pdf","https://scholar.google.com/scholar?cites=2124127707657789960&as_sdt=2005&sciodt=0,5&hl=en",275,"2020-11-06 21:29:44","PDF","","","",,,,,5,2.50,1,6,2,"We describe our efforts in developing a Biosignals Acquisition Space and Environment (BASE) to acquire a large database of human everyday activities along with a procedure to automatically structure and label these high-dimensional data into a valuable resource for …"
25,"T Schultz","Multilinguale Spracherkennung: Kombination akustischer Modelle zur Portierung auf neue Sprachen",2000,"","Shaker","","https://scholar.google.com/scholar?cites=5041703159144092140&as_sdt=2005&sciodt=0,5&hl=en",276,"2020-11-06 21:29:44","CITATION","","","",,,,,25,1.25,25,1,20,""
6,"D Heger, C Herff, A Pesters, D Telaar…","Continuous speech recognition from ECOG",2015,"… Annual Conference of …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2015/i15_1131.html","https://scholar.google.com/scholar?cites=6988587874196206171&as_sdt=2005&sciodt=0,5&hl=en",277,"2020-11-06 21:29:44","","","","",,,,,6,1.20,1,5,5,"Continuous speech production is a highly complex process involving many parts of the human brain. To date, no fundamental representation that allows for decoding of continuous speech from neural signals has been presented. Here we show that techniques from …"
6,"D Heger, E Terziyska, T Schultz","Connectivity based feature-level filtering for single-trial eeg bcis",2014,"2014 IEEE International …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/6853962/?casa_token=zYm5QwhwpI8AAAAA:5X-9wKJ1lwzCKy-l__GnpJolUHisNV_WJFwnCr3qNQb0coRo-DzdjhVfwp_iSkyR81GhHF_u4w","https://scholar.google.com/scholar?cites=3202634302670800489&as_sdt=2005&sciodt=0,5&hl=en",278,"2020-11-06 21:29:44","","","","",,,,,6,1.00,2,3,6,"EEG-based Brain Computer interfaces (BCIs) often rely on power spectral density features to represent relevant aspects of brain activity. The information flow within human brain networks and the corresponding connectivity patterns may contain useful information to …"
7,"F Putze, C Amma, T Schultz","Design and evaluation of a self-correcting gesture interface based on error potentials from EEG",2015,"Proceedings of the 33rd Annual ACM …","dl.acm.org","https://dl.acm.org/doi/abs/10.1145/2702123.2702184","https://scholar.google.com/scholar?cites=4032757941004469434&as_sdt=2005&sciodt=0,5&hl=en",279,"2020-11-06 21:29:44","","","","",,,,,7,1.40,2,3,5,"Any user interface which automatically interprets the user's input using natural modalities like gestures makes mistakes. System behavior depending on such mistakes will confuse the user and lead to an erroneous interaction flow. The automatic detection of error …"
7,"VN Thang, S Tanja","Vietnamese large vocabulary continuous speech recognition",2009,"IEEE Workshop on Automatic Speech Recognition …","","","https://scholar.google.com/scholar?cites=12626713240942894546&as_sdt=2005&sciodt=0,5&hl=en",280,"2020-11-06 21:29:44","CITATION","","","",,,,,7,0.64,4,2,11,""
6,"F Putze, T Schultz","Utterance selection for speech acts in a cognitive tourguide scenario",2010,"… Annual Conference of the International Speech …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2010/i10_3014.html","https://scholar.google.com/scholar?cites=17994839367050640657&as_sdt=2005&sciodt=0,5&hl=en",281,"2020-11-06 21:29:44","","","","",,,,,6,0.60,3,2,10,"This paper describes the integration of a cognitive memory model into a spoken dialog system for an in-car tourguide application. This memory model enhances the capabilities of the system and of the simulated user by estimating if and which information is relevant and …"
6,"T Schultz, M Westphal, A Waibel","The GlobalPhone Project: Multilingual LVCSR with Janus-3 in: Proc",,"SQEL","","","https://scholar.google.com/scholar?cites=10474005311864844397&as_sdt=2005&sciodt=0,5&hl=en",282,"2020-11-06 21:29:44","CITATION","","","",,,,,6,0.00,2,3,,""
6,"M Wand, C Schulte, M Janke…","Compensation of recording position shifts for a myoelectric silent speech recognizer",2014,"2014 IEEE International …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/6853968/?casa_token=u4nrJSSriJkAAAAA:rksbGh90ctVmRZpSLv8mAmf1NimGP5xXPIXiKjC8hZRMOe623ETVD3vuRc-7JQFeJwMbGgN0QQ","https://scholar.google.com/scholar?cites=10353369026485683129&as_sdt=2005&sciodt=0,5&hl=en",283,"2020-11-06 21:29:44","","","","",,,,,6,1.00,2,4,6,"A myoelectric Silent Speech Recognizer is a system which recognizes speech by capturing the electrical activity of the human articulatory muscles, thus enabling the user to communicate silently. We recently devised a recording setup based on electrode arrays with …"
6,"S Stüker, T Schultz, A Waibel","Automatic Generation of Pronunciation Dictionaries-For New, Unseen Languages by Voting among Phoneme Recognizers in Nine Different Languages",2002,"University of Karlsruhe","Citeseer","http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.4.8065","https://scholar.google.com/scholar?cites=9119536729493665023&as_sdt=2005&sciodt=0,5&hl=en",284,"2020-11-06 21:29:44","","","","",,,,,6,0.33,2,3,18,"CiteSeerX - Document Details (Isaac Councill, Lee Giles, Pradeep Teregowda): In this report we will describe a data driven approach for creating pronunciation dictionaries for a new unseen target language by voting among phoneme recognizers …"
8,"T Schlippe, C Zhu, D Lemcke…","Statistical machine translation based text normalization with crowdsourcing",2013,"2013 IEEE International …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/6639305/?casa_token=D7F7TTlQFewAAAAA:IPDRtop3NXZn_7mTT8c1h-9VNpRQXvwvjWsfg3_l18Rv02-s-yASpmn2JBbhNJwjDtvsWDaSZQ","https://scholar.google.com/scholar?cites=11764096819810350496&as_sdt=2005&sciodt=0,5&hl=en",285,"2020-11-06 21:29:44","","","","",,,,,8,1.14,2,4,7,"In [1], we have proposed systems for text normalization based on statistical machine translation (SMT) methods which are constructed with the support of Internet users and evaluated those with French texts. Internet users normalize text displayed in a web interface …"
6,"D Heger, F Putze, C Herff…","Subject-to-subject transfer for CSP based BCIs: Feature space transformation and decision-level fusion",2013,"2013 35th Annual …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/6610823/?casa_token=_qGchs9EZ9wAAAAA:SsgYSZ7yC82dQsNxYxbK2TEAJFwwoPjxgNZpw58j4Y3eTZ7IsixJqrGBakOy9e8QQJcEeyGJSg","https://scholar.google.com/scholar?cites=121729572331621926&as_sdt=2005&sciodt=0,5&hl=en",286,"2020-11-06 21:29:44","","","","",,,,,6,0.86,2,4,7,"Modern Brain Computer Interfaces (BCIs) usually require a calibration session to train a machine learning system before each usage. In general, such trained systems are highly specialized to the subject's characteristic activation patterns and cannot be used for other …"
7,"M Wand, T Schultz","Modeling coarticulation in EMG-based continuous speech recognition",2010,"Speech Communication","publikationen.bibliothek.kit.edu","https://publikationen.bibliothek.kit.edu/1000026321","https://scholar.google.com/scholar?cites=4722840896332314269&as_sdt=2005&sciodt=0,5&hl=en",287,"2020-11-06 21:29:44","","","","",,,,,7,0.70,4,2,10,"This paper discusses the use of surface electromyography for automatic speech recognition. Electromyographic signals captured at the facial muscles record the activity of the human articulatory apparatus and thus allow to trace back a speech signal even if it is spoken …"
6,"R Hsiao, T Schultz","Generalized discriminative feature transformation for speech recognition",2009,"Tenth Annual Conference of the International …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2009/i09_0664.html","https://scholar.google.com/scholar?cites=3255684075905944372&as_sdt=2005&sciodt=0,5&hl=en",288,"2020-11-06 21:29:44","","","","",,,,,6,0.55,3,2,11,"We propose a new algorithm called Generalized Discriminative Feature Transformation (GDFT) for acoustic models in speech recognition. GDFT is based on Lagrange relaxation on a transformed optimization problem. We show that the existing discriminative feature …"
4,"L Diener, S Bredehoeft, T Schultz","A comparison of EMG-to-Speech Conversion for Isolated and Continuous Speech",2018,"… Communication; 13th ITG …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/8577996/","https://scholar.google.com/scholar?cites=16591142955950015136&as_sdt=2005&sciodt=0,5&hl=en",289,"2020-11-06 21:29:44","","","","",,,,,4,2.00,1,3,2,"This paper presents initial results of performing EMG-to-Speech conversion within our new EMG-to-Speech corpus. This new corpus consists of parallel facial array sEMG and read audible speech signals recorded from multiple speakers. It contains different styles of …"
4,"J Weiner, T Schultz","Selecting Features for Automatic Screening for Dementia Based on Speech",2018,"International Conference on Speech and Computer","Springer","https://link.springer.com/chapter/10.1007/978-3-319-99579-3_76","https://scholar.google.com/scholar?cites=15728813980718671553&as_sdt=2005&sciodt=0,5&hl=en",290,"2020-11-06 21:29:44","","","","",,,,,4,2.00,2,2,2,"As the population in developed countries ages, larger numbers of people are at risk of developing dementia. In the near future large-scale time-and cost-efficient screening methods will be needed. Speech can be recorded and analyzed in this manner, and as …"
0,"L Diener, MR Vishkasougheh, T Schultz","CSL-EMG Array: An Open Access Corpus for EMG-to-Speech Conversion",2020,"Proc. Interspeech 2020","csl.uni-bremen.de","https://www.csl.uni-bremen.de/cms/images/documents/publications/Diener_IS2020_CSLEMGArray.pdf","",291,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,3,1,"We present a new open access corpus for the training and evaluation of EMG-to-Speech conversion systems based on array electromyographic recordings. The corpus is recorded with a recording paradigm closely mirroring realistic EMG-to-Speech usage scenarios, and …"
4,"C Herff, A de Pesters, D Heger, P Brunner…","Towards continuous speech recognition for BCI",2017,"Brain-Computer …","Springer","https://link.springer.com/chapter/10.1007/978-3-319-57132-4_3","https://scholar.google.com/scholar?cites=10279458704466695538&as_sdt=2005&sciodt=0,5&hl=en",292,"2020-11-06 21:29:44","","","","",,,,,4,1.33,1,5,3,"For the last two decades, brain-computer interface (BCI) research has worked towards practical and useful applications for communication and control. Yet, many BCI communication approaches suffer from unnatural interaction or time-consuming user …"
0,"ST Abate, MY Tachbelie, T Schultz","Multilingual Acoustic and Language Modeling for Ethio-Semitic Languages",2020,"Proc. Interspeech 2020","isca-speech.org","https://isca-speech.org/archive/Interspeech_2020/pdfs/2856.pdf","",293,"2020-11-06 21:29:44","","","","",,,,,0,0.00,0,3,1,"Abstract Development of Multilingual Automatic Speech Recognition (ASR) systems enables to share existing speech and text corpora among languages. We have conducted experiments on the development of multilingual Acoustic Models (AM) and Language …"
5,"YC Tam, T Schultz","Incorporating monolingual corpora into bilingual latent semantic analysis for crosslingual LM adaptation",2009,"2009 IEEE International Conference on …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/4960710/?casa_token=dSHh2CDC6asAAAAA:9xObMzewbUCEEsYU6sgfAPpoaPZK99UHvkh-nSBSLYOm87POMgHiq1cdjkXw16mRPQDBsd79Eg","https://scholar.google.com/scholar?cites=12376461413335712259&as_sdt=2005&sciodt=0,5&hl=en",294,"2020-11-06 21:29:44","","","","",,,,,5,0.45,3,2,11,"The major limitation in bilingual latent semantic analysis (bLSA) is the requirement of parallel training corpora. Motivated by semi-supervised learning, we propose a clusterbased bLSA training approach to incorporate monolingual corpora. Treating each parallel …"
5,"J Kominek, T Schultz, W Alan","Black. 2008. Synthesizer voice quality of new languages calibrated with mean Mel Cepstral Distortion",,"Spoken Languages Technologies for Under …","","","https://scholar.google.com/scholar?cites=4075898404700875847&as_sdt=2005&sciodt=0,5&hl=en",295,"2020-11-06 21:29:44","CITATION","","","",,,,,5,0.00,2,3,,""
5,"VB Le, L Besacier, T Schultz","Acousticphonetic unit similarities for context dependant acoustic model portability Carnegie Mellon University",,"Pittsburgh, PA, USA","","","https://scholar.google.com/scholar?cites=9653890964647039976&as_sdt=2005&sciodt=0,5&hl=en",296,"2020-11-06 21:29:44","CITATION","","","",,,,,5,0.00,2,3,,""
5,"C Johner, M Janke, M Wand, T Schultz","Inferring prosody from facial cues for EMG-based synthesis of silent speech",2012,"Proc. AHFE","researchgate.net","https://www.researchgate.net/profile/Tanja_Schultz/publication/267201281_Inferring_prosody_from_facial_cues_for_EMG-based_synthesis_of_silent_speech/links/5478368f0cf2a961e484b55a.pdf","https://scholar.google.com/scholar?cites=15928839322836499735&as_sdt=2005&sciodt=0,5&hl=en",297,"2020-11-06 21:29:44","PDF","","","",,,,,5,0.63,1,4,8,"In this paper we introduce a system which is able to detect prosodic elements in a spoken utterance based on signals from the facial muscles. The proposed system can augment our surface electromyography (EMG) based Silent Speech Interface in order to make …"
5,"T Schlippe, M Volovyk, K Yurchenko…","Rapid bootstrapping of a ukrainian large vocabulary continuous speech recognition system",2013,"… on Acoustics, Speech …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/6639086/?casa_token=LZPE1XqVf_YAAAAA:0m_5KLvQy4RJukM9RjDcBiX6KMAVlYRXIsCk4YSaMZ3kv8SzSJmDcxSpCd1i0C7YJ6ecLxRAgQ","https://scholar.google.com/scholar?cites=4110454235511461894&as_sdt=2005&sciodt=0,5&hl=en",298,"2020-11-06 21:29:44","","","","",,,,,5,0.71,1,4,7,"We report on our efforts toward an LVCSR system for the Slavic language Ukrainian. We describe the Ukrainian text and speech database recently collected as a part of our GlobalPhone corpus [1] with our Rapid Language Adaptation Toolkit [2]. The data was …"
6,"P Charoenpornsawat, T Schultz","Improving word segmentation for Thai speech translation",2008,"2008 IEEE Spoken …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/4777885/?casa_token=FGRwmSpTUHoAAAAA:Sxde3PFEwcjphdyIw0T496jj2hmcgpBodq6o2ZSPsHDnORswkeqtjV49ou_E3KlQ3u5q9eTFog","https://scholar.google.com/scholar?cites=7694965981597783549&as_sdt=2005&sciodt=0,5&hl=en",299,"2020-11-06 21:29:44","","","","",,,,,6,0.50,3,2,12,"A vocabulary list and language model are primary components in a speech translation system. Generating both from plain text is a straightforward task for English. However, it is quite challenging for Chinese, Japanese, or Thai which provide no word segmentation, ie …"
5,"J Reichert, T Schultz, A Waibel","Mandarin large vocabulary speech recognition using the globalphone database",1999,"Sixth European Conference on …","isca-speech.org","https://www.isca-speech.org/archive/eurospeech_1999/e99_0815.html","https://scholar.google.com/scholar?cites=18148443899688624122&as_sdt=2005&sciodt=0,5&hl=en",300,"2020-11-06 21:29:44","","","","",,,,,5,0.24,2,3,21,"This paper presents our recent efforts in developing a speaker independent LVCSR engine for Mandarin Chinese using our multilingual database GlobalPhone. We describe a two pass approach, in which the recognition first generates phoneme hypotheses and second …"
5,"NT Vu, T Schultz","Optimization on Vietnamese large vocabulary speech recognition",2010,"Spoken Languages Technologies for Under …","isca-speech.org","https://www.isca-speech.org/archive/SLTU_2010/su10_104.html","https://scholar.google.com/scholar?cites=16521051942088567622&as_sdt=2005&sciodt=0,5&hl=en",301,"2020-11-06 21:29:44","","","","",,,,,5,0.50,3,2,10,"This paper summarizes our latest efforts toward a large vocabulary speech recognition system for Vietnamese. We describe the Vietnamese text and speech database which we collected as part of our GlobalPhone corpus. Based on these data we improve our initial …"
6,"C Amma, T Schultz","Airwriting: bringing text entry to wearable computers",2013,"XRDS: Crossroads, the ACM Magazine for …","dl.acm.org","https://dl.acm.org/doi/fullHtml/10.1145/2540048","https://scholar.google.com/scholar?cites=14566344388613816807&as_sdt=2005&sciodt=0,5&hl=en",302,"2020-11-06 21:29:44","","","","",,,,,6,0.86,3,2,7,"Twiddler is a commercially available device with key buttons that can be worn around the hand. Such a system allows fast and unobtrusive writing, but requires the user to have a device fixed to their palm. Another idea is to project the keyboard and control ele- ments onto any kind …"
5,"U Nallasamy, M Garbus, F Metze, Q Jin…","Analysis of dialectal influence in pan-arabic asr",2011,"… Annual Conference of …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2011/i11_1721.html","https://scholar.google.com/scholar?cites=7659313631224558432&as_sdt=2005&sciodt=0,5&hl=en",303,"2020-11-06 21:29:44","","","","",,,,,5,0.56,1,5,9,"In this paper, we analyze the impact of five Arabic dialects on the front-end and pronunciation dictionary components of an Automatic Speech Recognition (ASR) system. We use ASR's phonetic decision tree as a diagnostic tool to compare the robustness of …"
5,"F Putze, T Schultz","Cognitive dialog systems for dynamic environments: Progress and challenges",2012,"Digital signal processing for in-vehicle systems and …","Springer","https://link.springer.com/chapter/10.1007/978-1-4419-9607-7_8","https://scholar.google.com/scholar?cites=17570125627104361822&as_sdt=2005&sciodt=0,5&hl=en",304,"2020-11-06 21:29:44","","","","",,,,,5,0.63,3,2,8,"In this chapter, we present our existing setup and ongoing research on the development of cognitive dialog systems for dynamic environments like cars, including the main components that we consider necessary to build dialog systems to estimate the user's mental processes …"
5,"T Schultz, Q Jin, K Laskowski, A Tribble…","Improvements in non-verbal cue identification using multilingual phone strings",2002,"Proceedings of the ACL …","aclweb.org","https://www.aclweb.org/anthology/W02-0714.pdf","https://scholar.google.com/scholar?cites=10955926221116473484&as_sdt=2005&sciodt=0,5&hl=en",305,"2020-11-06 21:29:44","PDF","","","",,,,,5,0.28,1,5,18,"Today's state-of-the-art front-ends for multilingual speechto-speech translation systems apply monolingual speech recognizers trained for a single language and/or accent. The monolingual speech engine is usually adaptable to an unknown speaker over time using …"
6,"F Putze, D Heger, T Schultz","Reliable subject-adapted recognition of EEG error potentials using limited calibration data",2013,"2013 6th International IEEE …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/6695961/?casa_token=8S4-CaVEFksAAAAA:K9SMxvIPs3uVvpivorKChblJKLiUDIzUv0OK-zFHIW3YJ1gU7vbrp89WDBBFPw60hLitIJsCiA","https://scholar.google.com/scholar?cites=11443214660588701156&as_sdt=2005&sciodt=0,5&hl=en",306,"2020-11-06 21:29:44","","","","",,,,,6,0.86,2,3,7,"For the development of efficient Brain Computer Interfaces (BCIs), recognizing when the system reacts erroneously to a user's input is a much desired functionality. In this paper, we investigate a system for the recognition of error potentials from single-trial …"
5,"SCS Jou, T Schultz","Automatic speech recognition based on electromyographic biosignals",2008,"… Conference on Biomedical Engineering Systems and …","Springer","https://link.springer.com/chapter/10.1007/978-3-540-92219-3_23","https://scholar.google.com/scholar?cites=9688330979645338843&as_sdt=2005&sciodt=0,5&hl=en",307,"2020-11-06 21:29:44","","","","",,,,,5,0.42,3,2,12,"This paper presents our studies of automatic speech recognition based on electromyographic biosignals captured from the articulatory muscles in the face using surface electrodes. We develop a phone-based speech recognizer and describe how the …"
1,"A Abulimiti, T Schultz","Building Language Models for Morphological Rich Low-Resource Languages using Data from Related Donor Languages: the Case of Uyghur",2020,"Proceedings of the 1st Joint Workshop on Spoken …","aclweb.org","https://www.aclweb.org/anthology/2020.sltu-1.38/","https://scholar.google.com/scholar?cites=16336526057765350812&as_sdt=2005&sciodt=0,5&hl=en",308,"2020-11-06 21:29:44","","","","",,,,,1,1.00,1,2,1,"Huge amounts of data are needed to build reliable statistical language models. Automatic speech processing tasks in low-resource languages typically suffer from lower performances due to weak or unreliable language models. Furthermore, language modeling for …"
6,"J Weiner, T Schultz","Detection of intra-personal development of cognitive impairment from conversational speech",2016,"Speech Communication; 12. ITG …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/7776183/","https://scholar.google.com/scholar?cites=16204143918586524854&as_sdt=2005&sciodt=0,5&hl=en",309,"2020-11-06 21:29:44","","","","",,,,,6,1.50,3,2,4,"As the population in developed countries is aging, cognitive impairment such as Alzheimer's disease becomes an urging challenge for these societies. In order to mitigate the consequences, diagnosing cognitive impairment early is crucial. We present automatic …"
6,"L Diener, G Felsch, M Angrick…","Session-Independent Array-Based EMG-to-Speech Conversion using Convolutional Neural Networks",2018,"… Communication; 13th ITG …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/8578038/","https://scholar.google.com/scholar?cites=18321749552582013643&as_sdt=2005&sciodt=0,5&hl=en",310,"2020-11-06 21:29:44","","","","",,,,,6,3.00,2,4,2,"This paper presents an evaluation of the performance of EMG-to-Speech conversion based on convolutional neural networks. We present an analysis of two different architectures and network design considerations and evaluate CNN-based systems for their within-session …"
3,"H Liu, T Schultz","ASK: A Framework for Data Acquisition and Activity Recognition.",2018,"BIOSIGNALS","scitepress.org","https://www.scitepress.org/papers/2018/67329/67329.pdf","https://scholar.google.com/scholar?cites=12684647950455587521&as_sdt=2005&sciodt=0,5&hl=en",311,"2020-11-06 21:29:44","PDF","","","",,,,,3,1.50,2,2,2,"This work puts forward a framework for the acquisition and processing of biosignals to indicate strain on the knee inflicted by human everyday activities. Such a framework involves the appropriate equipment in devices and sensors to capture factors that inflict strain on the …"
4,"F Putze, T Schultz, S Ehret…","Model-based Evaluation of Playing Strategies in a Memo Game for Elderly Users",2015,"… on Systems, Man …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/7379302/?casa_token=ZJsANaH0sqkAAAAA:GzD0bFyPFL1uFMjjyLIuUAKPIAwSY4Lcp58HMdOrBaCwUpbJXQsmYVbswaHZppht0zuZ90PSPQ","https://scholar.google.com/scholar?cites=9995271222725262817&as_sdt=2005&sciodt=0,5&hl=en",312,"2020-11-06 21:29:44","","","","",,,,,4,0.80,1,4,5,"In this paper, we analyze game protocols for a Memo game for elderly users. We show how we can use generative statistical models to automatically reveal different playing strategies. We present a quantitative and qualitative evaluation of the approach on simulated and real …"
4,"D Telaar, J Weiner, T Schultz","Error Signatures to identify Errors in ASR in an unsupervised fashion",2015,"Proceedings of the Errare …","csl.uni-bremen.de","https://www.csl.uni-bremen.de/cms/images/documents/publications/TelaarEtAl_Errare2015.pdf","https://scholar.google.com/scholar?cites=15367884193083802982&as_sdt=2005&sciodt=0,5&hl=en",313,"2020-11-06 21:29:44","PDF","","","",,,,,4,0.80,1,3,5,"Large scale ASR systems are trained on thousands of hours of speech. Usually, many of these training data were automatically transcribed by another ASR system due to a lack of manual transcriptions and a lack of resources to transcribe them. Systems trained in such a …"
3,"M Angrick, C Herff, GD Johnson, JJ Shih, DJ Krusienski…","interpretation of convolutional neural networks for speech regression from electrocorticography.",2018,"ESANN","elen.ucl.ac.be","https://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es2018-102.pdf","https://scholar.google.com/scholar?cites=7145834928115349844&as_sdt=2005&sciodt=0,5&hl=en",314,"2020-11-06 21:29:44","PDF","","","",,,,,3,1.50,1,6,2,"The direct synthesis of continuously spoken speech from neural activity is envisioned to enable fast and intuitive Brain-Computer Interfaces. Earlier results indicate that intracranial recordings reveal very suitable signal characteristics for direct synthesis. To map the …"
4,"SCS Jou, T Schultz","EARS: Electromyographical Automatic Recognition of Speech.",2008,"BIOSIGNALS (1)","cs.cmu.edu","http://www.cs.cmu.edu/afs/.cs.cmu.edu/Web/People/scjou/paper/scjou_biosig08.pdf","https://scholar.google.com/scholar?cites=15412488200997616214&as_sdt=2005&sciodt=0,5&hl=en",315,"2020-11-06 21:29:44","PDF","","","",,,,,4,0.33,2,2,12,"In this paper, we present our research on automatic speech recognition of surface electromyographic signals that are generated by the human articulatory muscles. With parallel recorded audible speech and electromyographic signals, experiments are …"
4,"D Heger, F Putze, T Schultz","Online Workload Recognition from EEG data during Cognitive Tests and Human-Computer Interaction",2010,"proceedings of 33rd Annual …","csl.uni-bremen.de","https://www.csl.uni-bremen.de/cms/images/documents/publications/HegerPutzeSchultz_KI10.pdf","https://scholar.google.com/scholar?cites=14804350428964745333&as_sdt=2005&sciodt=0,5&hl=en",316,"2020-11-06 21:29:44","PDF","","","",,,,,4,0.40,1,3,10,"This paper presents a system for live recognition of mental workload using data segments of one second length from 16 channel EEG. Recognition rates of more than 90% could be reached for five subjects performing two different cognitive tests: the flanker and the …"
4,"MJJ Premkumar, NT Vu, T Schultz","Experiments towards a better LVCSR System for Tamil",2013,"Training","isca-speech.org","https://www.isca-speech.org/archive/archive_papers/interspeech_2013/i13_2202.pdf","https://scholar.google.com/scholar?cites=15461382371555621994&as_sdt=2005&sciodt=0,5&hl=en",317,"2020-11-06 21:29:44","","","","",,,,,4,0.57,1,3,7,"This paper summarizes our latest efforts in the development of a Large Vocabulary Continuous Speech Recognition (LVCSR) system for Tamil at different levels: pronunciation dictionary, language modeling (LM) and front-end. Usually in Tamil there are not many word …"
5,"M Georgi, C Amma, T Schultz","Fusion and comparison of imu and emg signals for wearable gesture recognition",2015,"International Joint Conference on …","Springer","https://link.springer.com/chapter/10.1007/978-3-319-27707-3_19","https://scholar.google.com/scholar?cites=9021894457033661860&as_sdt=2005&sciodt=0,5&hl=en",318,"2020-11-06 21:29:44","","","","",,,,,5,1.00,2,3,5,"We evaluate the performance of a wearable gesture recognition system for arm, hand, and finger motions, using the signals of an Inertial Measurement Unit (IMU) worn at the wrist, and the Electromyogram (EMG) of muscles in the forearm. A set of 12 gestures was defined …"
4,"E Stoimenov, T Schultz","A multiplatform speech recognition decoder based on weighted finite-state transducers",2009,"2009 IEEE Workshop on Automatic …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/5373404/?casa_token=dMoT5DJS62MAAAAA:bcsfUyidYrDTh87t6b2PrXugdLy59pstSEXuasGUq-FpPPg8NDe7DXokSirT87wfD14sXSkWBw","https://scholar.google.com/scholar?cites=17635889838194798014&as_sdt=2005&sciodt=0,5&hl=en",319,"2020-11-06 21:29:44","","","","",,,,,4,0.36,2,2,11,"Speech recognition decoders based on static graphs have recently proven to significantly outperform the traditional approach of prefix tree expansion in terms of decoding speed. The reduced search effort makes static graph decoders an attractive alternative for tasks …"
4,"J Hild, F Putze, D Kaufman, C Kühnle…","Spatio-temporal event selection in basic surveillance tasks using eye tracking and EEG",2014,"Proceedings of the 7th …","dl.acm.org","https://dl.acm.org/doi/abs/10.1145/2666642.2666645","https://scholar.google.com/scholar?cites=5268272102157578640&as_sdt=2005&sciodt=0,5&hl=en",320,"2020-11-06 21:29:44","","","","",,,,,4,0.67,1,5,6,"In safety-and security-critical applications like video surveillance it is crucial that human operators detect task-relevant events in the continuous video streams and select them for report or dissemination to other authorities. Usually, the selection operation is performed …"
4,"T Schultz, A Waibel","Experiments towards a multi-language LVCSR interface",2000,"Int. Conf. on Spoken Language Processing","Citeseer","http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.6.3249&rep=rep1&type=pdf","https://scholar.google.com/scholar?cites=5346820839445789766&as_sdt=2005&sciodt=0,5&hl=en",321,"2020-11-06 21:29:44","PDF","","","",,,,,4,0.20,2,2,20,"This paper describes experiments towards a multilanguage human-computer speech interface. Our interface is designed for large vocabulary continuous speech input. For this purpose a multilingual dictation database has been collected under GlobalPhone, which is a …"
5,"R Pröpper, F Putze, T Schultz","Jam: Java-based associative memory",2011,"… of the Paralinguistic Information and its …","Springer","https://link.springer.com/chapter/10.1007/978-1-4614-1335-6_16","https://scholar.google.com/scholar?cites=17343427232378958991&as_sdt=2005&sciodt=0,5&hl=en",322,"2020-11-06 21:29:44","","","","",,,,,5,0.56,2,3,9,"In dynamic environments, conversational dialog systems have to deal with ambiguous input, topic shifts and the users' limited memory resources. Therefore, systems need to model cognitive processes of its users to predict “what is on the user's mind”. In this paper, we …"
4,"NT Vu, T Schultz","Initial experiments with Tamil LVCSR",2012,"2012 International Conference on Asian …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/6473701/","https://scholar.google.com/scholar?cites=16963404188128105285&as_sdt=2005&sciodt=0,5&hl=en",323,"2020-11-06 21:29:44","","","","",,,,,4,0.50,2,2,8,"In this paper we present our recent efforts towards building a large vocabulary continuous speech recognizer for Tamil. We describe the text and speech corpus collected to realize this task. The data was complemented by a large amount of text data crawled from various …"
4,"NT Vu, DC Lyu, J Weiner, D Telaar, T Schlippe…","System for Mandarin-English Code-Switch Conversational Speech",,"Proc. of ICASSP","","","https://scholar.google.com/scholar?cites=1109892450794547832&as_sdt=2005&sciodt=0,5&hl=en",324,"2020-11-06 21:29:44","CITATION","","","",,,,,4,0.00,1,6,,""
4,"T Schultz","Rapid language adaptation tools for multilingual speech processing",2009,"2009 IEEE Workshop on Automatic Speech …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/5373503/","https://scholar.google.com/scholar?cites=18208928258818020934&as_sdt=2005&sciodt=0,5&hl=en",325,"2020-11-06 21:29:44","","","","",,,,,4,0.36,4,1,11,"Summary form only given: The performance of speech and language processing technologies has improved dramatically over the past decade, with an increasing number of systems being deployed in a large variety of applications, such as spoken dialog systems …"
4,"U Nallasamy, F Metze, T Schultz","Semi-supervised learning for speech recognition in the context of accent adaptation",2012,"Symposium on Machine …","isca-speech.org","https://www.isca-speech.org/archive/mlslp_2012/ml12_013.html","https://scholar.google.com/scholar?cites=11968450046081170641&as_sdt=2005&sciodt=0,5&hl=en",326,"2020-11-06 21:29:44","","","","",,,,,4,0.50,1,3,8,"Accented speech that is under-represented in the training data still suffers high Word Error Rate (WER) with state-of-the-art Automatic Speech Recognition (ASR) systems. Careful collection and transcription of training data for different accents can address this issue, but it …"
4,"U Nallasamy, AW Black, T Schultz, RE Frederking","NineOneOne: Recognizing and Classifying Speech for Handling Minority Language Emergency Calls.",2008,"LREC","cs.cmu.edu","http://www.cs.cmu.edu/~./911/LREC2008-911.pdf","https://scholar.google.com/scholar?cites=16474646377141220097&as_sdt=2005&sciodt=0,5&hl=en",327,"2020-11-06 21:29:44","PDF","","","",,,,,4,0.33,1,4,12,"In this paper, we describe NineOneOne (9-1-1), a system designed to recognize and translate Spanish emergency calls for better dispatching. We analyze the research challenges in adapting speech translation technology to 9-1-1 domain. We report our initial …"
0,"A Abulimiti, J Weiner, T Schultz","Automatic Speech Recognition for ILSE-Interviews: Longitudinal Conversational Speech Recordings covering Aging and Cognitive Decline",2020,"Proc. Interspeech 2020","isca-speech.org","https://www.isca-speech.org/archive/Interspeech_2020/pdfs/2829.pdf","",328,"2020-11-06 21:29:44","","","","",,,,,0,0.00,0,3,1,"Abstract The Interdisciplinary Longitudinal Study on Adult Development and Aging (ILSE) was initiated with the aim to investigate satisfying and healthy aging. Over 20 years, about 4200 hours of biographic interviews from more than 1,000 participants were recorded …"
0,"L Steinert, F Putze, D Küster, T Schultz","Towards Engagement Recognition of People with Dementia in Care Settings",2020,"Proceedings of the 2020 …","dl.acm.org","https://dl.acm.org/doi/abs/10.1145/3382507.3418856","",329,"2020-11-06 21:29:44","","","","",,,,,0,0.00,0,4,1,"Roughly 50 million people worldwide are currently suffering from dementia. This number is expected to triple by 2050. Dementia is characterized by a loss of cognitive function and changes in behaviour. This includes memory, language skills, and the ability to focus and …"
1,"J Weiner, C Frankenberg, J Schröder…","Speech Reveals Future Risk of Developing Dementia: Predictive Dementia Screening from Biographic Interviews",2019,"2019 IEEE Automatic …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/9003908/?casa_token=RyoDz_MfGOQAAAAA:Gz7l3XK4pRpnqxsnL1HHSA6QBr6iCHXmUwjnDZqRt3KDYlbpkdKbBjLBzw1wgk28rKfUCfLqOA","https://scholar.google.com/scholar?cites=14368283550600804487&as_sdt=2005&sciodt=0,5&hl=en",330,"2020-11-06 21:29:44","","","","",,,,,1,1.00,0,4,1,"Alzheimer's disease is a progressive incurable condition for which the success of any symptomatic therapy depends crucially on the starting time. Ideally it starts before the disease has caused any cognitive impairments. Our work aims at developing speech-based …"
2,"H Liu, T Schultz","A Wearable Real-time Human Activity Recognition System using Biosensors Integrated into a Knee Bandage.",2019,"BIODEVICES","scitepress.org","https://www.scitepress.org/Papers/2019/73988/73988.pdf","https://scholar.google.com/scholar?cites=10145306803949437599&as_sdt=2005&sciodt=0,5&hl=en",331,"2020-11-06 21:29:44","PDF","","","",,,,,2,2.00,1,2,1,"This work introduces an innovative wearable real-time Human Activity Recognition (HAR) system. The system processes and decodes various biosignals that are captured from biosensors integrated into a knee bandage. The presented work includes (1) the selection of …"
3,"L Diener, T Umesh, T Schultz","Improving Fundamental Frequency Generation in EMG-to-Speech Conversion Using a Quantization Approach",2019,"2019 IEEE Automatic Speech …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/9003804/?casa_token=rCcaGH4Q7PwAAAAA:hJAQPUgpGl9Nbfur-JOJLNQam_5dr8sm4TQ7ymLP_MG0mfBm5MMWoyymrADnF1Ds8CDFWR_tHw","https://scholar.google.com/scholar?cites=9558257797444267737&as_sdt=2005&sciodt=0,5&hl=en",332,"2020-11-06 21:29:44","","","","",,,,,3,3.00,1,3,1,"We present a novel approach to generating fundamental frequency (intonation and voicing) trajectories in an EMG-to-Speech conversion Silent Speech Interface, based on quantizing the EMG-to-F 0 mappings target values and thus turning a regression problem into a …"
0,"MY Tachbelie, ST Abate…","Development of Multilingual ASR Using GlobalPhone for Less-Resourced Languages: The Case of Ethiopian Languages",2020,"Proc. Interspeech …","indico2.conference4me.psnc.pl","https://indico2.conference4me.psnc.pl/event/35/contributions/2965/attachments/603/634/Mon-3-1-2.pdf","",333,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,3,1,"In this paper, we present the cross-lingual and multilingual experiments we have conducted using existing resources of other languages for the development of speech recognition system for less-resourced languages. In our experiments, we used the Globalphone corpus …"
3,"ST Abate, MY Tachbelie…","Deep Neural Networks Based Automatic Speech Recognition for Four Ethiopian Languages",2020,"ICASSP 2020-2020 IEEE …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/9053883/?casa_token=8OWqKwRxg3wAAAAA:ELzdKT9vHLsgT1P63ziBn0K5lI-Iur7qjFISY9p0uTCe2h8xuwRz8O6JqyvnJvRx1VYbO4P8uQ","https://scholar.google.com/scholar?cites=14965737312804266413&as_sdt=2005&sciodt=0,5&hl=en",334,"2020-11-06 21:29:44","","","","",,,,,3,3.00,1,3,1,"In this work, we present speech recognition systems for four Ethiopian languages: Amharic, Tigrigna, Oromo and Wolaytta. We have used comparable training corpora of about 20 to 29 hours speech and evaluation speech of about 1 hour for each of the languages. For Amharic …"
0,"D Küster, F Putze, P Alves-Oliveira, M Paetzel…","Modeling Socio-Emotional and Cognitive Processes from Multimodal Data in the Wild",2020,"Proceedings of the …","dl.acm.org","https://dl.acm.org/doi/abs/10.1145/3382507.3420053","",335,"2020-11-06 21:29:44","","","","",,,,,0,0.00,0,5,1,"Detecting, modeling, and making sense of multimodal data from human users in the wild still poses numerous challenges. Starting from aspects of data quality and reliability of our measurement instruments, the multidisciplinary endeavor of developing intelligent adaptive …"
3,"L Diener, M Janke, T Schultz","Codebook clustering for unit selection based EMG-To-speech conversion",2015,"Sixteenth Annual Conference of the …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2015/i15_2420.html","https://scholar.google.com/scholar?cites=10148471351295798103&as_sdt=2005&sciodt=0,5&hl=en",336,"2020-11-06 21:29:44","","","","",,,,,3,0.60,1,3,5,"This paper reports on our recent advances in using Unit Selection to directly synthesize speech from facial surface electromyographic (EMG) signals generated by movement of the articulatory muscles during speech production. We achieve a robust Unit Selection mapping …"
3,"NT Vu, T Schultz, D Povey","Modeling gender dependency in the subspace GMM framework",2012,"2012 IEEE International …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/6288881/?casa_token=xM4X-TkOiC4AAAAA:IgWOSXpFaiLnE4Z3PxhBdvX26SEWJDFgjjeZEv1zo-1i679vM0lRo6IlgWZp11F1nc7UNzIn4g","https://scholar.google.com/scholar?cites=1448581354026040259&as_sdt=2005&sciodt=0,5&hl=en",337,"2020-11-06 21:29:44","","","","",,,,,3,0.38,1,3,8,"The Subspace GMM acoustic model has both globally shared parameters and parameters specific to acoustic states, and this makes it possible to do various kinds of tying. In the past we have investigated sharing the global parameters among systems with distinct acoustic …"
3,"A Kurematsu, Y Akegami, T Schultz, S Burger","Data collection and transliteration of Japanese spontaneous database in the travel arrangement task domain",1999,"Oriental COCOSDA","Citeseer","http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.68.7485&rep=rep1&type=pdf","https://scholar.google.com/scholar?cites=12654615555875974032&as_sdt=2005&sciodt=0,5&hl=en",338,"2020-11-06 21:29:44","PDF","","","",,,,,3,0.14,1,4,21,"This paper describes the method to construct and transcribe Japanese spontaneous speech data for VERBMOBIL, the German research project of speech translation.. Spontaneous spoken dialogue database is the basis for developing speech and language processing for …"
3,"D Heger, C Herff, T Schultz","Combining feature extraction and classification for fnirs bcis by regularized least squares optimization",2014,"2014 36th Annual International …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/6944010/?casa_token=Ht-xh_xAIssAAAAA:cnzDKXLMfsVKeWuSaCbp__ZQuxjZanySBexkyUg8PJhkjiuNSHWGGLKrpFImOuxu2H8IBOmd9g","https://scholar.google.com/scholar?cites=7505271104645312847&as_sdt=2005&sciodt=0,5&hl=en",339,"2020-11-06 21:29:44","","","","",,,,,3,0.50,1,3,6,"In this paper, we show that multiple operations of the typical pattern recognition chain of an fNIRS-based BCI, including feature extraction and classification, can be unified by solving a convex optimization problem. We formulate a regularized least squares problem that learns …"
3,"T Schultz","Rapid language adaptation tools and technologies for multilingual speech processing systems",2008,"Spoken Languages Technologies for Under …","isca-speech.org","https://www.isca-speech.org/archive/SLTU_2008/su08_001.html","https://scholar.google.com/scholar?cites=8516277187494047215&as_sdt=2005&sciodt=0,5&hl=en",340,"2020-11-06 21:29:44","","","","",,,,,3,0.25,3,1,12,"The performance of speech and language processing technologies has improved dramatically over the past decade, with an increasing number of systems being deployed in a large variety of applications, such as spoken dialog systems, speech summarization and …"
3,"S Hagen, S Tanja, W Martin","Recognition of music types",1998,"Proceedings of the 1998 IEEE International …","","","https://scholar.google.com/scholar?cites=8405351273700931218&as_sdt=2005&sciodt=0,5&hl=en",341,"2020-11-06 21:29:44","CITATION","","","",,,,,3,0.14,1,3,22,""
3,"M Angrick, C Herff, E Mugler, MC Tate, MW Slutzky…","Speech synthesis from ECoG using densely connected 3D convolutional neural networks. bioRxiv",2018,"","","","https://scholar.google.com/scholar?cites=2612676040647754013&as_sdt=2005&sciodt=0,5&hl=en",342,"2020-11-06 21:29:44","CITATION","","","",,,,,3,1.50,1,6,2,""
3,"F Putze, M Scherer, T Schultz","Starring into the void",2016,"Proceedings of the 9th Nordic Conference on Human …","","","https://scholar.google.com/scholar?cites=14746615065068551829&as_sdt=2005&sciodt=0,5&hl=en",343,"2020-11-06 21:29:44","CITATION","","","",,,,,3,0.75,1,3,4,""
4,"T Schultz, M Wand, M Janke","Computer-implemented method, computer system and computer program product for automatic transformation of myoelectric signals into audible speech",2016,"US Patent App. 15/105,908","Google Patents","https://patents.google.com/patent/US20160314781A1/en","https://scholar.google.com/scholar?cites=10690399512450273151&as_sdt=2005&sciodt=0,5&hl=en",344,"2020-11-06 21:29:44","","","","",,,,,4,1.00,1,3,4,"In one aspect, the present application is directed to a computer-implemented method, a computer program product, and a computer system for automatic transformation of myoelectric signals into speech output corresponding to audible speech. The computer …"
3,"J Kunzmann, K Choukri, E Jahnke, A Kiessling, K Knill…","Portability of automatic speech recognition technology to new languages: Multilinguality issues and speech/text resources",2001,"Panel Session on Automatic …","","","https://scholar.google.com/scholar?cites=15373718142532904203&as_sdt=2005&sciodt=0,5&hl=en",345,"2020-11-06 21:29:44","CITATION","","","",,,,,3,0.16,1,6,19,""
3,"H Yu, T Schultz","Implicit trajectory modeling through gaussian transition models for speech recognition",2003,"Companion Volume of the Proceedings of HLT-NAACL …","aclweb.org","https://www.aclweb.org/anthology/N03-2038.pdf","https://scholar.google.com/scholar?cites=9701600881001090516&as_sdt=2005&sciodt=0,5&hl=en",346,"2020-11-06 21:29:44","PDF","","","",,,,,3,0.18,2,2,17,"It is well known that frame independence assumption is a fundamental limitation of current HMM based speech recognition systems. By treating each speech frame independently, HMMs fail to capture trajectory information in the acoustic signal. This paper introduces …"
3,"U Nallasamy, M Fuhs, M Woszczyna…","Neighbour selection and adaptation for rapid speaker-dependent ASR",2013,"… IEEE Workshop on …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/6707706/?casa_token=M4e9uTADt9IAAAAA:dLnbfmovCXjcyqVoEw46k0ha_wHnwgTzRe6E5hTLvtGzFgJaj4YR81BvQ9gRE_MWAtdRt3vMFg","https://scholar.google.com/scholar?cites=17068518835554716555&as_sdt=2005&sciodt=0,5&hl=en",347,"2020-11-06 21:29:44","","","","",,,,,3,0.43,1,4,7,"Speaker dependent (SD) ASR systems have significantly lower word error rates (WER) compared to speaker independent (SI) systems. However, SD systems require sufficient training data from the target speaker, which is impractical to collect in a short time. We …"
3,"F Metze, C Fügen, Y Pan, T Schultz","H. Yu. The isl rt-04s meeting transcription system",2004,"Proceedings NIST RT-04S Evaluation Workshop …","","","https://scholar.google.com/scholar?cites=12219062220933012356&as_sdt=2005&sciodt=0,5&hl=en",348,"2020-11-06 21:29:44","CITATION","","","",,,,,3,0.19,1,4,16,""
3,"T Schultz, D Koll, A Waibel","Japanese LVCSR on the Spontaneous Scheduling Task with JANUS-3",1997,"Fifth European Conference on Speech …","isca-speech.org","https://www.isca-speech.org/archive/eurospeech_1997/e97_0367.html","https://scholar.google.com/scholar?cites=3348228066346146951&as_sdt=2005&sciodt=0,5&hl=en",349,"2020-11-06 21:29:44","","","","",,,,,3,0.13,1,3,23,"This paper presents our findings during the development of the recognition engine for the Japanese part of the VERBMOBIL speech-to-speech translation project. We describe an efficient method to bootstrap a large vocabulary speech recognizer for spontaneously …"
3,"W Michael, SS Jou, AR Toth, T Schultz","T.: Impact of Different Speaking Modes on EMGbased Speech Recognition",2009,"In: Proc. Interspeech.(2009","Citeseer","http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.165.6765","https://scholar.google.com/scholar?cites=16011563080613206864&as_sdt=2005&sciodt=0,5&hl=en",350,"2020-11-06 21:29:44","","","","",,,,,3,0.27,1,4,11,"We present our recent results on speech recognition by surface electromyography (EMG), which captures the electric potentials that are generated by the human articulatory muscles. This technique can be used to enable Silent Speech Interfaces, since EMG signals are …"
4,"A Constantinescu, T Schultz","Redundancy versus complexity in auditory displays for object localization-a pilot study",2011,"","smartech.gatech.edu","https://smartech.gatech.edu/handle/1853/51742","https://scholar.google.com/scholar?cites=4078206945173349522&as_sdt=2005&sciodt=0,5&hl=en",351,"2020-11-06 21:29:44","","","","",,,,,4,0.44,2,2,9,"In user interfaces, redundancy is often an indication of good design. Several studies [1, 2, 3], showed that when visual, haptic or other display types were combined with an auditory display, the result was an enhanced user experience and increase in performance …"
0,"M Angrick, C Herff, G Johnson…","Speech Spectrogram Estimation from Intracranial Brain Activity using a Quantization Approach",2020,"Proc …","indico2.conference4me.psnc.pl","https://indico2.conference4me.psnc.pl/event/35/contributions/3594/attachments/1248/1292/Wed-SS-2-7-4.pdf","",352,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,4,1,"Direct synthesis from intracranial brain activity into acoustic speech might provide an intuitive and natural communication means for speech-impaired users. In previous studies we have used logarithmic Mel-scaled speech spectrograms (logMels) as an intermediate …"
4,"M Meier, C Mason, R Porzel, F Putze, T Schultz","Synchronized multimodal recording of a table setting dataset",2018,"","csl.uni-bremen.de","https://www.csl.uni-bremen.de/cms/images/documents/publications/meier_iros_2018.pdf","https://scholar.google.com/scholar?cites=14712140798148245605&as_sdt=2005&sciodt=0,5&hl=en",353,"2020-11-06 21:29:44","PDF","","","",,,,,4,2.00,1,5,2,"We present here a description of our initial efforts in developing a Biosignal Acquisition Space and Environment (BASE) to collect a large open access dataset of human everyday activities. The final dataset is planned to consist of synchronously recorded biosignals from …"
1,"H Schultz, L Abrahamsen, LE Rekvad, U Skræp…","Patient-controlled oral analgesia at acute abdominal pain: A before-and-after intervention study of pain management during hospital stay",2019,"Applied Nursing …","Elsevier","https://www.sciencedirect.com/science/article/pii/S0897189718305883","https://scholar.google.com/scholar?cites=15920963594118357254&as_sdt=2005&sciodt=0,5&hl=en",354,"2020-11-06 21:29:44","","","","",,,,,1,1.00,0,5,1,"Aim To investigate the patient experience of pain management, when patient-controlled oral analgesia was compared with standard care for patients admitted to hospital with acute abdominal pain. The primary outcome measures were pain intensity and patient perception …"
2,"W Doneit, J Lohse, K Glesing, C Simon…","Data-driven analysis of interactions between people with dementia and a tablet device",2017,"Current Directions in …","degruyter.com","https://www.degruyter.com/view/journals/cdbme/3/2/article-p735.xml","https://scholar.google.com/scholar?cites=11493456075264817647&as_sdt=2005&sciodt=0,5&hl=en",355,"2020-11-06 21:29:44","","","","",,,,,2,0.67,0,5,3,"In the project I-CARE a technical system for tablet devices is developed that captures the personal needs and skills of people with dementia. The system provides activation content such as music videos, biographical photographs and quizzes on various topics of interest to …"
0,"H Schultz, TS Larsen, S Möller, N Qvist","The Effect of Patient-Controlled Oral Analgesia for Acute Abdominal Pain after Discharge",2019,"Pain Management Nursing","Elsevier","https://www.sciencedirect.com/science/article/pii/S1524904218301413","",356,"2020-11-06 21:29:44","","","","",,,,,0,0.00,0,4,1,"Background During hospitalization, patients who were admitted with acute abdominal pain must be prepared to care for themselves at home after discharge to continue established treatment, promote recovery, and avoid readmission. Aims Our aim was to investigate the …"
0,"C Herff, L Diener, E Mugler, M Slutzky…","Towards Speech Synthesis from Intracranial Signals",2020,"Brain–Computer …","Springer","https://link.springer.com/chapter/10.1007/978-3-030-49583-1_5","",357,"2020-11-06 21:29:44","","","","",,,,,0,0.00,0,5,1,"Brain-computer interfaces (BCIs) are envisioned to enable individuals with severe disabilities to regain the ability to communicate. Early BCIs have provided users with the ability to type messages one letter at a time, providing an important, but slow, means of …"
1,"M Salous, F Putze, T Schultz, J Hild…","Investigating static and sequential models for intervention-free selection using multimodal data of EEG and eye tracking",2018,"Proceedings of the …","dl.acm.org","https://dl.acm.org/doi/abs/10.1145/3279810.3279841","https://scholar.google.com/scholar?cites=8400432958607069420&as_sdt=2005&sciodt=0,5&hl=en",358,"2020-11-06 21:29:44","","","","",,,,,1,0.50,0,5,2,"Multimodal data is increasingly used in cognitive prediction models to better analyze and predict different user cognitive processes. Classifiers based on such data, however, have different performance characteristics. We discuss in this paper an intervention-free selection …"
0,"MY Tachbelie, ST Abate, T Schultz","DNN-Based Multilingual Automatic Speech Recognition for Wolaytta using Oromo Speech",2020,"… of the 1st Joint Workshop on …","aclweb.org","https://www.aclweb.org/anthology/2020.sltu-1.37/","",359,"2020-11-06 21:29:44","","","","",,,,,0,0.00,0,3,1,"It is known that Automatic Speech Recognition (ASR) is very useful for human-computer interaction in all the human languages. However, due to its requirement for a big speech corpus, which is very expensive, it has not been developed for most of the languages …"
2,"VN Thang, S Tanja","Optimization on Vietnamese Large Vocabulary Speech Recognition",2010,"The 2nd International Workshop on Spoken Language …","","","https://scholar.google.com/scholar?cites=7039361955475927301&as_sdt=2005&sciodt=0,5&hl=en",360,"2020-11-06 21:29:44","CITATION","","","",,,,,2,0.20,1,2,10,""
2,"S Stüker, T Schultz, A Waibel","Automatic Generation of Pronunciation Dictionaries",2002,"","pdfs.semanticscholar.org","https://pdfs.semanticscholar.org/67c5/bc81bc12826c370251134079fab417599d4e.pdf","https://scholar.google.com/scholar?cites=7286862916473089859&as_sdt=2005&sciodt=0,5&hl=en",361,"2020-11-06 21:29:44","PDF","","","",,,,,2,0.11,1,3,18,"In this report we will describe a data driven approach for creating pronunciation dictionaries for a new unseen target language by voting among phoneme recognizers in nine different languages other than the target language. In this process recordings of the new language …"
2,"S Tanja, A Waibel","Experiments on cross-language acoustic modeling",2001,"EURO SPEECH","","","https://scholar.google.com/scholar?cites=15807744055203943839&as_sdt=2005&sciodt=0,5&hl=en",362,"2020-11-06 21:29:44","CITATION","","","",,,,,2,0.11,1,2,19,""
2,"J Kominek, S Badaskar, T Schultz…","Improving Speech Systems Built from Very Little Data",2008,"Ninth Annual Conference …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2008/i08_1833.html","https://scholar.google.com/scholar?cites=12521298989715933753&as_sdt=2005&sciodt=0,5&hl=en",363,"2020-11-06 21:29:44","","","","",,,,,2,0.17,1,4,12,"This paper studies two ways for helping non-specialist users develop speech systems from limited data for new languages. Focused web re-crawling finds additional examples of text matching the domain as specified by the user. This improves the language model and cuts …"
2,"K Laskowski, T Schultz","A supervised factorial acoustic model for simultaneous multiparticipant vocal activity detection in close-talk microphone recordings of meetings",2007,"","pdfs.semanticscholar.org","https://pdfs.semanticscholar.org/445b/032c396fe52469ca731505b262827a7680c0.pdf","https://scholar.google.com/scholar?cites=9042960471746189923&as_sdt=2005&sciodt=0,5&hl=en",364,"2020-11-06 21:29:44","PDF","","","",,,,,2,0.15,1,2,13,"Vocal activity detection in close-talk microphone recordings of multiparty conversation continues to pose problems for meeting recognition systems, as evidenced by a 2-3% absolute gap in word error rates achieved with automatic and manual segmentations. State …"
2,"Y Hua, S Hagen, S Tanja, S Thomas, P Yue, M Florian…","Advances in Meeting Recognition",2001,"Proceedings of the Human …","","","https://scholar.google.com/scholar?cites=14567878011906402371&as_sdt=2005&sciodt=0,5&hl=en",365,"2020-11-06 21:29:44","CITATION","","","",,,,,2,0.11,0,7,19,""
2,"L Bechberger, F Putze, T Schultz","Modeling Human Memory Performance Under Influence Of Cognitive Workload",2012,"Bachelor thesis, Karlsruhe Institute of Technology","","","https://scholar.google.com/scholar?cites=9562767401587621960&as_sdt=2005&sciodt=0,5&hl=en",366,"2020-11-06 21:29:44","CITATION","","","",,,,,2,0.25,1,3,8,""
2,"J Kominek, T Schultz, W Alan","Black.“Voice Building from Insufficient Data-Classroom Experience with web-based Development Tools”",2007,"Proceedings of the 6th ISCA Workshop on Speech …","","","https://scholar.google.com/scholar?cites=8771756097997621613&as_sdt=2005&sciodt=0,5&hl=en",367,"2020-11-06 21:29:44","CITATION","","","",,,,,2,0.15,1,3,13,""
2,"M Woszczyna, P Charoenpornsawat…","Spontaneous Thai speech recognition",2006,"… Conference on Spoken …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2006/i06_1419.html","https://scholar.google.com/scholar?cites=7267403421366053116&as_sdt=2005&sciodt=0,5&hl=en",368,"2020-11-06 21:29:44","","","","",,,,,2,0.14,1,3,14,"This paper expands previous work on Thai speech recognition, investigating pronunciation changes such as syllable and phoneme elisions as well as phoneme shifts in Thai spontaneous speech. We compare several approaches to model these effects in large …"
2,"K Laskowski, T Schultz","Recovering participant identities in meetings from a probabilistic description of vocal interaction",2008,"Ninth Annual Conference of the …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2008/i08_0082.html","https://scholar.google.com/scholar?cites=6154665524117910833&as_sdt=2005&sciodt=0,5&hl=en",369,"2020-11-06 21:29:44","","","","",,,,,2,0.17,1,2,12,"An important decision in the design of automatic conversation understanding systems is the level at which information streams representing specific participants are merged. In the current work, we explore participant-dependence of low-level interactive aspects of …"
2,"T Schultz","Rapid Language Portability of Speech Processing Systems",2006,"Keynote talk-ISCA Tutorial and Research Workshop on …","researchgate.net","https://www.researchgate.net/profile/Tanja_Schultz/publication/36453336_Rapid_Language_Portability_of_Speech_Processing_Systems/links/5478367f0cf293e2da286153/Rapid-Language-Portability-of-Speech-Processing-Systems.pdf","https://scholar.google.com/scholar?cites=1387735735284780551&as_sdt=2005&sciodt=0,5&hl=en",370,"2020-11-06 21:29:44","PDF","","","",,,,,2,0.14,2,1,14,"Page 1. Tanja Schultz Carnegie Mellon University InterACT: Center for Advanced Communication Technologies CMU, 11-733, February 13 2007 Rapid Language Portability of Speech Processing Systems Page 2. 2/53 ➊ Computerization: Speech is key technology ➡ Mobile Devices …"
2,"M Wetphal, H Soltau, T Schultz, A Waibe","Recognition of music type",1998,"Proc. IEEE Int. Conf. Acoustics, Speech …","","","https://scholar.google.com/scholar?cites=3224107671980808963&as_sdt=2005&sciodt=0,5&hl=en",371,"2020-11-06 21:29:44","CITATION","","","",,,,,2,0.09,1,4,22,""
2,"K Schaaff, T Schultz","EEG-Based Emotion Recognition Using Support Vector Machines",2009,"1. Fachtagung Biophysiologische Interfaces, Berlin …","","","https://scholar.google.com/scholar?cites=10275394174824985793&as_sdt=2005&sciodt=0,5&hl=en",372,"2020-11-06 21:29:44","CITATION","","","",,,,,2,0.18,1,2,11,""
2,"Q Jin, K Kumar, T Schultz, R Stern","Compensation approaches for far-field speaker identification",2008,"NIST SRE Workshop","researchgate.net","https://www.researchgate.net/profile/Richard_Stern3/publication/36453485_Compensation_Approaches_for_Far-field_Speaker_Identification/links/542f4f280cf27e39fa995192.pdf","https://scholar.google.com/scholar?cites=13165431188240655046&as_sdt=2005&sciodt=0,5&hl=en",373,"2020-11-06 21:29:44","PDF","","","",,,,,2,0.17,1,4,12,"While speaker identification performance has improved dramatically over the past years, the presence of interfering noise and the variety of channel conditions pose a major obstacle. Particularly the mismatch between training and test condition leads to severe performance …"
2,"L Viet-Bac, L Besacier, T Schultz","Acoustic-Phonetic Unit Similarities for Context-Dependent Acoustic Model Portability",2006,"Proceeding on Acoustics, Speech, and Signal …","","","https://scholar.google.com/scholar?cites=10908661358731379069&as_sdt=2005&sciodt=0,5&hl=en",374,"2020-11-06 21:29:44","CITATION","","","",,,,,2,0.14,1,3,14,""
2,"T Schultz, D Koll","Spontaneously Spoken Japanese Speech Recognition with Janus-3 In",1997,"","EUROSPEECH","","https://scholar.google.com/scholar?cites=12520965972608924795&as_sdt=2005&sciodt=0,5&hl=en",375,"2020-11-06 21:29:44","CITATION","","","",,,,,2,0.09,1,2,23,""
2,"M Erhardt, D Telaar, T Schultz","Error blaming based on decoding output",2013,"","","","https://scholar.google.com/scholar?cites=7792411184186205865&as_sdt=2005&sciodt=0,5&hl=en",376,"2020-11-06 21:29:44","CITATION","","","",,,,,2,0.29,1,3,7,""
2,"A Waibel, T Schultz, S Vogel, C Fugen…","Towards language portability in statistical speech translation",2004,"… , Speech, and Signal …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/1326657/?casa_token=uzy5ofZHgCoAAAAA:WeUmP6BgZRwDQiHGiCx92CkHpr072imsoEJb6mfZP55kRfXDTBk1D_dPPaBvs4RvaYITLu86gQ","https://scholar.google.com/scholar?cites=13606231567858736461&as_sdt=2005&sciodt=0,5&hl=en",377,"2020-11-06 21:29:44","","","","",,,,,2,0.13,0,5,16,"Speech translation has made significant advances over the last years. We believe that we can overcome today's limits of language and domain portable conversational speech translation systems by relying more radically on learning approaches and by the use of …"
2,"L Besacier, E Barnard, A Karpov, T Schultz","Introduction to the special issue on processing under-resourced languages",2014,"","www-nwu-ac-za.web.nwu.ac.za","http://www-nwu-ac-za.web.nwu.ac.za/sites/www.nwu.ac.za/files/files/v-must/Publications%202014/besacier-2014-under-resourced-languages.pdf","https://scholar.google.com/scholar?cites=14079068825565029448&as_sdt=2005&sciodt=0,5&hl=en",378,"2020-11-06 21:29:44","PDF","","","",,,,,2,0.33,1,4,6,"The creation of language and acoustic resources, for any given spoken language, is typically a costly task. For example, a large amount of time and money is required to properly create annotated speech corpora for automatic speech recognition (ASR), domain-specific …"
2,"T Schultz","Globalphone: a Multilingual Speech and Text Database Developed at Karlsruhe",2002,"Proceedings of the International Conference on …","","","https://scholar.google.com/scholar?cites=7887042826104524069&as_sdt=2005&sciodt=0,5&hl=en",379,"2020-11-06 21:29:44","CITATION","","","",,,,,2,0.11,2,1,18,""
2,"R Hsiao, F Metze, T Schultz","Improvements to Generalized Discriminative Feature Transformation for Speech Recognition",2010,"Eleventh Annual Conference of the …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2010/i10_1361.html","https://scholar.google.com/scholar?cites=8561014231011176322&as_sdt=2005&sciodt=0,5&hl=en",380,"2020-11-06 21:29:44","","","","",,,,,2,0.20,1,3,10,"Abstract Generalized Discriminative Feature Transformation (GDFT) is a feature space discriminative training algorithm for automatic speech recognition (ASR). GDFT uses Lagrange relaxation to transform the constrained maximum likelihood linear regression …"
2,"B Ma, H Sun, D Zhu, H Li, KA Lee, KC Sim…","I4U Submission for the 2008 NIST Speaker Recognition Evaluation Submission",2010,"2008 NIST Speaker …","researchgate.net","https://www.researchgate.net/profile/Chien_Lin_Huang3/publication/281786151_I4U_Submission_for_the_2008_NIST_Speaker_Recognition_Evaluation_Submission/links/55f8b8a108ae07629ddebe50.pdf","https://scholar.google.com/scholar?cites=13027954379959390943&as_sdt=2005&sciodt=0,5&hl=en",381,"2020-11-06 21:29:44","PDF","","","",,,,,2,0.20,0,7,10,"The I4U team is a consortium of one institute and four universities comprising of Institute for Infocomm Research (IIR), University of Science and Technology of China (USTC), University of New South Wales (UNSW), Nanyang Technological University (NTU), and Carnegie …"
2,"A Waibel, M Bett, F Metze, K Ries, T Schaaf, T Schultz…","Advances in automatic meeting record creation and access, ICASSP-2001",2001,"Google Scholar Google …","","","https://scholar.google.com/scholar?cites=3858535722753679429&as_sdt=2005&sciodt=0,5&hl=en",382,"2020-11-06 21:29:44","CITATION","","","",,,,,2,0.11,0,7,19,""
2,"M Paulik, S Stuker, C Fugen, T Schultz…","Translating language with technology's help",2007,"IEEE Potentials","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/4205212/?casa_token=sO89UeaziE8AAAAA:-Y8fyZirNDUNF9GAo8E2HkzHCczVg7KpOSrJ_w-QTe47j6nxUVg3BQCOEGDqjGSkiY_U_bSrNQ","https://scholar.google.com/scholar?cites=3073644996467650217&as_sdt=2005&sciodt=0,5&hl=en",383,"2020-11-06 21:29:44","","","","",,,,,2,0.15,0,5,13,"In this article, we introduced an iterative system for improving speech recognition in the context of human mediated translation scenarios. In contrast to related work conducted in this field, we included scenarios in which only spoken language representations are …"
2,"J Kominek, T Schultz, AW Black","Voice Building from Insufficient Data: classroom experiences with web-based development tools",,"6th ISCA Speech Synthesis Workshop","","","https://scholar.google.com/scholar?cites=10757448738989944258&as_sdt=2005&sciodt=0,5&hl=en",384,"2020-11-06 21:29:44","CITATION","","","",,,,,2,0.00,1,3,,""
2,"T Schlippe, IT Schultz","Rapid generation of pronunciation dictionaries for new domains and languages",2014,"","pdfs.semanticscholar.org","https://pdfs.semanticscholar.org/e51d/e3b8977a5765d6ad1131961a2b5e58c3e4d4.pdf","https://scholar.google.com/scholar?cites=15345094181192821357&as_sdt=2005&sciodt=0,5&hl=en",385,"2020-11-06 21:29:44","PDF","","","",,,,,2,0.33,1,2,6,"Automatic speech recognition allows people an intuitive communication with machines. Compared to the keyboard and mouse as input modalities, automatic speech recognition enables a more natural and efficient way where hands and eyes are free for other activities …"
2,"S Leidig, DIT Schlippe, IT Schultz","Single and Combined Features for the Detection of Anglicisms in German and Afrikaans",2014,"Bachelor's Thesis, Karlsruhe …","csl.uni-bremen.de","https://www.csl.uni-bremen.de/cms/images/documents/publications/BA_SebastianLeidig.pdf","https://scholar.google.com/scholar?cites=6402238298644705757&as_sdt=2005&sciodt=0,5&hl=en",386,"2020-11-06 21:29:44","PDF","","","",,,,,2,0.33,1,3,6,"Page 1. Single and Combined Features for the Detection of Anglicisms in German and Afrikaans Bachelor's Thesis at Cognitive Systems Lab Prof. Dr.-Ing. Tanja Schultz Department of Informatics Karlsruhe Institute of Technology by Sebastian Leidig …"
0,"K Prorokovic, K Proroković, M Wand, T Schultz…","Adaptation of an EMG-Based Speech Recognizer via Meta-Learning",2019,"","sigport.org","https://sigport.org/documents/adaptation-emg-based-speech-recognizer-meta-learning","",387,"2020-11-06 21:29:44","","","","",,,,,0,0.00,0,5,1,"In nonacoustic speech recognition based on electromyography, ie on electrical muscle activity captured by noninvasive surface electrodes, differences between recording sessions are known to cause deteriorating system accuracy. Efficient adaptation of an existing system …"
0,"T Schultz, M Angrick, L Diener, D Küster…","Towards Restoration of Articulatory Movements: Functional Electrical Stimulation of Orofacial Muscles",2019,"2019 41st Annual …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/8857670/?casa_token=Uq9pJwuBvsIAAAAA:7jBJWqKxsr0mRoCpePIbfi_lCNnKphMHc8ppXhY5DeTfHATYr874nO-mFRE4gp7k0EbfVs6oog","",388,"2020-11-06 21:29:44","","","","",,,,,0,0.00,0,5,1,"Millions of individuals suffer from impairments that significantly disrupt or completely eliminate their ability to speak. An ideal intervention would restore one's natural ability to physically produce speech. Recent progress has been made in decoding speech-related …"
7,"T Schultz, F Putze, A Kruse","Technische Unterstützung für Menschen mit Demenz: Symposium 30.09.-01.10. 2013",2014,"","books.google.com","https://books.google.com/books?hl=en&lr=&id=UhIPBgAAQBAJ&oi=fnd&pg=PR1&dq=%22tanja+schultz%22&ots=yPQ6P2P-kF&sig=6EAqLuzcRuEO_k0NcalLufI5IZo","https://scholar.google.com/scholar?cites=6526787298551644103&as_sdt=2005&sciodt=0,5&hl=en",389,"2020-11-06 21:29:44","BOOK","","","",,,,,7,1.17,2,3,6,"Demenz ist die häufigste psychiatrische Erkrankung im Alter, an der heute bereits über 1, 2 Millionen Menschen in Deutschland leiden. In den nächsten 20 Jahren rechnet man mit einer Verdopplung von Erkrankungen, die mit einem enormen Anstieg des Pflegebedarfs …"
0,"Y Hartmann, H Liu, T Schultz","Feature Space Reduction for Multimodal Human Activity Recognition.",2020,"BIOSIGNALS","csl.uni-bremen.de","https://www.csl.uni-bremen.de/cms/images/documents/publications/Feature_Space_Reduction_for_Multimodal_Human_Activity_Recognition.pdf","",390,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,3,1,"This work describes the implementation, optimization, and evaluation of a Human Activity Recognition (HAR) system using 21-channel biosignals. These biosignals capture multiple modalities, such as motion and muscle activity based on two 3D-inertial sensors, one 2D …"
0,"M Salous, F Putze, M Ihrig…","Visual and Memory-based HCI Obstacles: Behaviour-based Detection and User Interface Adaptations Analysis",2019,"2019 IEEE International …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/8914233/?casa_token=9jGRgpc48hcAAAAA:JmQdE916FoFo4y5kXfMgoRLsAwwkgPxyjMnyOcWCfE5JceUCX8mAXu6wTwWfLh5aOqsfzi8RmQ","",391,"2020-11-06 21:29:44","","","","",,,,,0,0.00,0,4,1,"Human Computer Interaction (HCI) performance can be impaired by several HCI obstacles. Cognitive adaptive systems should dynamically detect such obstacles and compensate them with suitable User Interface (UI) adaptation. In this paper, we discuss the detection of …"
1,"A Abulimiti, T Schultz","Automatic Speech Recognition for Uyghur through Multilingual Acoustic Modeling",2020,"Proceedings of The 12th Language Resources …","aclweb.org","https://www.aclweb.org/anthology/2020.lrec-1.793/","https://scholar.google.com/scholar?cites=16575240343915060664&as_sdt=2005&sciodt=0,5&hl=en",392,"2020-11-06 21:29:44","","","","",,,,,1,1.00,1,2,1,"Low-resource languages suffer from lower performance of Automatic Speech Recognition (ASR) system due to the lack of data. As a common approach, multilingual training has been applied to achieve more context coverage and has shown better performance over the …"
1,"C Herff, F Putze, T Schultz","Evaluating fNIR-based workload discrimination in a realistic driving scenario",2017,"The First Biannual Neuroadaptive …","core.ac.uk","https://core.ac.uk/download/pdf/189934577.pdf#page=73","https://scholar.google.com/scholar?cites=8388749994494524809&as_sdt=2005&sciodt=0,5&hl=en",393,"2020-11-06 21:29:44","PDF","","","",,,,,1,0.33,0,3,3,"The detection of mental workload during driving could provide valuable information to car electronics such as the navigation system. Functional Near Infrared Spectroscopy (fNIRS) is a promising candidate for unobtrusive measurement of brain activity and has shown …"
3,"F Putze, T Schultz, R Pröpper","Dummy Model based Workload Modeling",2015,"2015 IEEE International …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/7379303/?casa_token=epfeNKs7N_AAAAAA:2TaYwOARJAZnI1-AVZwCb0PJo4FfWc-BPubXVsHtckQYWjTn4e0El-L-R_fSgboX0d-XPYYdZw","https://scholar.google.com/scholar?cites=6937760724001020872&as_sdt=2005&sciodt=0,5&hl=en",394,"2020-11-06 21:29:44","","","","",,,,,3,0.60,1,3,5,"In this paper, we show how a model of human cognition based on ACT-R can be improved to accurately predict cognitive performance under different workload levels. For this purpose, we propose a novel approach which uses an EEG-based workload model to (de-) activate a …"
0,"S Manghat, S Manghat, T Schultz","Malayalam-English Code-Switched: Speech Corpus Development and Analysis",2020,"WSTCSMC 2020","festvox.org","http://festvox.org/cedar/WSTCSMC2020.pdf#page=20","",395,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,3,1,"In multilingual communities, code-switching is a common phenomenon and is predominant in most of the low resource languages as well. Many of the Indic languages fall under the category of low resource languages. Malayalam is a Dravidian language and is the official …"
1,"M Meier, C Mason, F Putze, T Schultz","Comparative Analysis of Think-aloud Methods for Everyday Activities in the Context of Cognitive Robotics",2019,"detail","isca-speech.org","https://www.isca-speech.org/archive/Interspeech_2019/pdfs/3072.pdf","https://scholar.google.com/scholar?cites=8224303412460294391&as_sdt=2005&sciodt=0,5&hl=en",396,"2020-11-06 21:29:44","","","","",,,,,1,1.00,0,4,1,"We describe our efforts to compare data collection methods using two think-aloud protocols in preparation to be used as a basis for automatic structuring and labeling of a large database of high-dimensional human activities data into a valuable resource for research in …"
1,"S Lesaja, C Herff, GD Johnson, JJ Shih…","Decoding Lip Movements During Continuous Speech using Electrocorticography",2019,"2019 9th …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/8716914/?casa_token=CqRw1u8QRo0AAAAA:0xdgb0WeuzQsV74LafYvoMXawuWfwbWrmSzz7yCHzSXjjMaI25r25efu7vTFz-vssqp7GrA9Lw","https://scholar.google.com/scholar?cites=15671461633648234409&as_sdt=2005&sciodt=0,5&hl=en",397,"2020-11-06 21:29:44","","","","",,,,,1,1.00,0,5,1,"Recent work has shown that it is possible to decode aspects of continuously-spoken speech from electrocorticographic (ECoG) signals recorded on the cortical surface. The ultimate objective is to develop a speech neuroprosthetic that can provide seamless, real-time …"
1,"T Schultz","Szu-Chen (Stan) Jou, Automatic Speech Recognition based on Electromyographic Biosignals, Selected best papers of BIOSTEC 2008 in …",2008,"","Springer, November","","https://scholar.google.com/scholar?cites=6603005231154573208&as_sdt=2005&sciodt=0,5&hl=en",398,"2020-11-06 21:29:44","CITATION","","","",,,,,1,0.08,1,1,12,""
1,"R Dillmann, J Beyerer, UD Hanebeck, T Schultz","KI 2010: Advances in Artificial Intelligence: 33rd Annual German Conference on AI, Karlsruhe, Germany, September 21-24, 2010, Proceedings",2010,"","books.google.com","https://books.google.com/books?hl=en&lr=&id=7_aqCAAAQBAJ&oi=fnd&pg=PR4&dq=%22tanja+schultz%22&ots=ZtqMfat-bX&sig=nlIyz2NJQdoXrXVcpkRd314XZ6Y","https://scholar.google.com/scholar?cites=13771328991403369627&as_sdt=2005&sciodt=0,5&hl=en",399,"2020-11-06 21:29:44","BOOK","","","",,,,,1,0.10,0,4,10,"The 33rd Annual German Conference on Arti? cial Intelligence (KI 2010) took place at the Karlsruhe Institute of Technology KIT, September 21–24, 2010, under the motto “Anthropomatic Systems.” In this volume you will? nd the keynote paper and 49 papers of …"
1,"D Heger, C Herff, F Putze…","Joint optimization for discriminative, compact and robust brain-computer interfacing",2015,"2015 7th International IEEE …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/7146565/?casa_token=btDEJi2ATaAAAAAA:GduQGXj0K_HL0n_WUI4HWtIfoA-qe4Cwp0WLVFhEKFZXR95dtEMG697PmQ3RggOeDsFXeAlXzw","https://scholar.google.com/scholar?cites=12791107757080772229&as_sdt=2005&sciodt=0,5&hl=en",400,"2020-11-06 21:29:44","","","","",,,,,1,0.20,0,4,5,"We present a new pattern recognition framework for Brain-Computer Interfacing that learns discriminative brain activity patterns, compact modeling, and robustness against signal variabilities by a single joint optimization. We present an algorithm based on the Alternating …"
1,"M Jiang, T Schultz","Paper# 3 Review of Speech Technologies",,"pdfs.semanticscholar.org","","https://pdfs.semanticscholar.org/6e3e/6dc84fd6e5291a83a198480e5249b387011b.pdf","https://scholar.google.com/scholar?cites=13155215809322932078&as_sdt=2005&sciodt=0,5&hl=en",401,"2020-11-06 21:29:44","PDF","","","",,,,,1,0.00,1,2,,"The purpose of this report is to identify and recommend specific speech recognition and synthesis systems to be used in the E-language system. In addition, the report not only describes the strengths and weaknesses of the technology, but also how they can be used …"
1,"JC Martin, T Schultz","6. Multimodal and Speech Technology",2012,"Handbook of Technical Communication","books.google.com","https://books.google.com/books?hl=en&lr=&id=24keJTRbtrAC&oi=fnd&pg=PA189&dq=%22tanja+schultz%22&ots=UYHJl1z-3q&sig=iE-umq79t3OUdPFEV4sRKaptclU","https://scholar.google.com/scholar?cites=13878486683273212517&as_sdt=2005&sciodt=0,5&hl=en",402,"2020-11-06 21:29:44","","","","",,,,,1,0.13,1,2,8,"This chapter introduces into technologies for speech processing and multimodal interfaces.'Multimodal'stands for a channel of communication involving more than one human output-input combination, eg oral-auditory, gesture-visual (Gibbon et al …"
1,"F Putze, T Schultz","Towards cognitive dialog systems",2009,"","csl.uni-bremen.de","https://www.csl.uni-bremen.de/cms/images/documents/publications/cognitive_dialog_systems_01.pdf","https://scholar.google.com/scholar?cites=15121194926407044974&as_sdt=2005&sciodt=0,5&hl=en",403,"2020-11-06 21:29:44","PDF","","","",,,,,1,0.09,1,2,11,"In this paper, we report on our initial setup and ongoing research on the development of cognitive dialog systems for dynamic environments. We describe the main components that we consider necessary to build dialog systems that estimate the user's mental processes …"
1,"J Krell, S Benzinger, K Boes…","Physical Activity, Brain Function And Cognitive Performance In Young Adults-A Cross-sectional Study",2012,"… in Sports and …","LIPPINCOTT WILLIAMS & WILKINS …","","https://scholar.google.com/scholar?cites=12351342754731752797&as_sdt=2005&sciodt=0,5&hl=en",404,"2020-11-06 21:29:44","CITATION","","","",,,,,1,0.13,0,4,8,""
1,"T Schultz","I-CARE",1995,"Education","researchgate.net","https://www.researchgate.net/profile/Tanja_Schultz/amp/27","https://scholar.google.com/scholar?cites=11328214281563483366&as_sdt=2005&sciodt=0,5&hl=en",405,"2020-11-06 21:29:44","","","","",,,,,1,0.04,1,1,25,"Osteoarthritis is the most common joint disease worldwide. It is accompanied by a substantial reduction of life quality and results in significant economic losses. One major pillar of the therapy is movement, which creates essential prerequisites for the nutrition of the …"
1,"T Schultz, K Schaaff, DMM Wand","EEG-based Emotion Recognition",2008,"Universitat Karlsruhe, Institut …","csl.uni-bremen.de","https://csl.uni-bremen.de/cms/images/documents/publications/DA-schaaff.pdf","https://scholar.google.com/scholar?cites=2437504349683438923&as_sdt=2005&sciodt=0,5&hl=en",406,"2020-11-06 21:29:44","PDF","","","",,,,,1,0.08,0,3,12,"In the area of human-computer interaction information about the emotional state of a user becomes more and more important. For instance, this information could be used to make communication with computers more human-like or to make computer learning …"
2,"F Stahlberg, T Schlippe, S Vogel…","Cross-lingual lexical language discovery from audio data using multiple translations",2015,"2015 IEEE International …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/7179088/?casa_token=8DrjVnpIRHUAAAAA:4CQuYh4hhTKV6sa1PzsypPFhleCtszcuEfl3gwrZ-yPk49V6pqX7x2qy-d5Zp5SrNGFhBMM5HQ","https://scholar.google.com/scholar?cites=4608443703990517026&as_sdt=2005&sciodt=0,5&hl=en",407,"2020-11-06 21:29:44","","","","",,,,,2,0.40,1,4,5,"Zero-resource Automatic Speech Recognition (ZR ASR) addresses target languages without given pronunciation dictionary, transcribed speech, and language model. Lexical discovery for ZR ASR aims to extract word-like chunks from speech. Lexical discovery benefits from the …"
1,"F Putze, DV Holt, T Schultz, J Funke","Model-based Identification of EEG Markers for Learning Opportunities in an Associative Learning Task with Delayed Feedback",2014,"International Conference on Artificial …","Springer","https://link.springer.com/chapter/10.1007/978-3-319-11179-7_49","https://scholar.google.com/scholar?cites=7074266849526361823&as_sdt=2005&sciodt=0,5&hl=en",408,"2020-11-06 21:29:44","","","","",,,,,1,0.17,0,4,6,"This paper combines a reinforcement learning (RL) model and EEG data analysis to identify learning situations in a associative learning task with delayed feedback. We investigated neural correlates in occipital alpha and prefrontal theta band power of learning …"
1,"A Johnson, M Hebert, Y Liu, Y Xu, B Liang…","Home/Publications",1997,"Journal Article","ri.cmu.edu","https://www.ri.cmu.edu/pubs/page/79/?wpv_view_count=4514-TCPID4515&wpv_paged=80","https://scholar.google.com/scholar?cites=16944491215070196788&as_sdt=2005&sciodt=0,5&hl=en",409,"2020-11-06 21:29:44","CITATION","","","",,,,,1,0.04,0,6,23,""
4,"T Schultz, F Putze, R Mikut, N Weinberger…","Technische Unterstützung für Menschen mit Demenz–Ein Überblick",2014,"… von Netzwerken in …","researchgate.net","https://www.researchgate.net/profile/Nora_Weinberger/publication/271833785_Chapter_1/links/54d3368b0cf250179181aef8.pdf","https://scholar.google.com/scholar?cites=15834648827705672528&as_sdt=2005&sciodt=0,5&hl=en",410,"2020-11-06 21:29:44","PDF","","","",,,,,4,0.67,1,5,6,"Page 1. 1 Technische Unterstützung für Menschen mit Demenz – Ein Überblick Tanja Schultz1, Felix Putze1, Ralf Mikut2, Nora Weinberger3, Katrin Boch4, Eric Schmitt4, Michael Decker3, Dagmar Lind-Matthäus5, Brigitte R. Metz5 1Karlsruher Institut für Technologie, Institut für …"
4,"S Jekat, C Scheer, T Schultz","VMII Szenario I: Instruktionen für alle Sprachstellungen",1997,"Verbmobil Technisches Dokument","","","https://scholar.google.com/scholar?cites=8697573776760509195&as_sdt=2005&sciodt=0,5&hl=en",411,"2020-11-06 21:29:44","CITATION","","","",,,,,4,0.17,1,3,23,""
0,"T Schultz","Biosignal Processing for Human-Machine Interaction.",2019,"INTERSPEECH","isca-speech.org","https://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs6.html","",412,"2020-11-06 21:29:44","","","","",,,,,0,0.00,0,1,1,"Human interaction is a complex process involving modalities such as speech, gestures, motion, and brain activities emitting a wide range of biosignals, which can be captured by a broad panoply of sensors. The processing and interpretation of these biosignals offer an …"
1,"F Putze, J Hild, A Sano, E Kasneci, E Solovey…","Modeling Cognitive Processes from Multimodal Signals",2018,"Proceedings of the 20th …","dl.acm.org","https://dl.acm.org/doi/abs/10.1145/3242969.3265861","https://scholar.google.com/scholar?cites=15948855434437336505&as_sdt=2005&sciodt=0,5&hl=en",413,"2020-11-06 21:29:44","","","","",,,,,1,0.50,0,6,2,"Multimodal signals allow us to gain insights into internal cognitive processes of a person, for example: speech and gesture analysis yields cues about hesitations, knowledgeability, or alertness, eye tracking yields information about a person's focus of attention, task, or …"
1,"T Schultz, T Hueber, DJ Krusienski…","Introduction to the Special Issue on Biosignal-Based Spoken Communication",2017,"… /ACM Transactions on …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/8114385/","https://scholar.google.com/scholar?cites=5960995304098750120&as_sdt=2005&sciodt=0,5&hl=en",414,"2020-11-06 21:29:44","","","","",,,,,1,0.33,0,4,3,"The papers in this special section focus on biosignal-based spoken communication. Speech production is a complex process resulting from human activities initiated in the brain, eventually leading to muscle activities that produce respiratory, laryngeal, and articulatory …"
3,"SJ Jekat, T Schultz","Evaluation sprachverarbeitender Systeme",2004,"… und Sprachtechnologie: eine …","digitalcollection.zhaw.ch","https://digitalcollection.zhaw.ch/handle/11475/4938","https://scholar.google.com/scholar?cites=8831419160582230976&as_sdt=2005&sciodt=0,5&hl=en",415,"2020-11-06 21:29:44","CITATION","","","",,,,,3,0.19,2,2,16,"Skip navigation …"
0,"P Alku, A Belouchrani, SC Cheung, CY Chi…","SPS Fellows and Award Winners Recognized",2020,"CALL FOR PAPERS …","ieee.org","http://www.ieee.org/ns/periodicals/NxtBooks/SP/PDF/SP_Mar2020.pdf?fbclid=IwAR2-e3kc_Yb8SR_RAKXoJPXWEf-a6IN9GaExek18SG8ZosONGqg2e4x6eTA#page=6","",416,"2020-11-06 21:29:44","","","","",,,,,0,0.00,0,5,1,"37 SPS members elevated to IEEE Fellow Each year, the IEEE Board of Directors confers the grade of Fellow on up to onetenth of 1% of the voting Members. To qualify for consideration, an individual must have been a Member, normally for five years or more, and …"
0,"J Weiner, L Diener, S Stelter, E Externest…","Bremen Big Data Challenge 2017: Predicting University Cafeteria Load",2017,"Joint German/Austrian …","Springer","https://link.springer.com/chapter/10.1007/978-3-319-67190-1_35","",417,"2020-11-06 21:29:44","","","","",,,,,0,0.00,0,5,3,"Big data is a hot topic in research and industry. The availability of data has never been as high as it is now. Making good use of the data is a challenging research topic in all aspects of industry and society. The Bremen Big Data Challenge invites students to dig deep into big …"
0,"S Mcn, L Ewald, T Schultz, L Bmsc, S Möller…","Patient-controlled oral analgesia at acute abdominal pain: A before-and-after intervention study of pain management during hospital stay",2019,"","Elsevier","","",418,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,6,1,""
0,"H Schultz, L Abrahamsen, LE Rekvad, U SkrÊp…","Patient-controlled oral analgesia for acute abdominal pain: A before-and-after intervention study on the quality of pain management during hospital stay",2018,"Applied Nursing Research","","","",419,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,5,2,""
2,"S Ehret, F Putze, H Miller-Teynor, A Kruse…","Technikbasiertes Spiel von Tagespflegebesuchern mit und ohne Demenz",2017,"… für Gerontologie und …","Springer","https://idp.springer.com/authorize/casa?redirect_uri=https://link.springer.com/content/pdf/10.1007/s00391-016-1093-2.pdf&casa_token=TNGMAKOkR-YAAAAA:Y5P_otF8OLvZ3Z2pEXgUd_dfXw7E-f0mTmJDe3EWWyWyME_u_VWAFIzq5nXmbN6nKO9RxnJj7XPibimg","https://scholar.google.com/scholar?cites=2895840593126652644&as_sdt=2005&sciodt=0,5&hl=en",420,"2020-11-06 21:29:44","PDF","","","",,,,,2,0.67,0,5,3,"Zusammenfassung Hintergrund Spielen von alten Menschen, auch mit demenziellen Erkrankungen, ist bisher nicht substanziell untersucht. Ziel der Arbeit Die vorliegende Studie befasst sich mit der Akzeptanz und der Wirkung eines technikbasierten Memory-Spiels, das …"
0,"T Schultz","Bio signal-based Spoken Communication.",2018,"IberSPEECH","iberspeech2018.talp.cat","http://iberspeech2018.talp.cat/download/IberS18_KN1_Schultz.pdf","",421,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,1,2,"T. Schultz, http://csl.uni-bremen.de … T. Schultz, http://csl.uni-bremen.de … T. Schultz, C. Amma, D. Heger, F. Putze, M. Wand Biosignale-basierte Mensch- Maschine-Schnittstellen, In at - Automatisierungstechnik, 2013, volume 61, 2013 … T. Schultz, http://csl.uni-bremen.de …"
3,"T Schultz, F Putze, A Kruse","Technische Unterstuetzung fuer Menschen mit Demenz: Symposium 30.09.-01.10",2013,"","KIT Scientific Publishing","","https://scholar.google.com/scholar?cites=543455924112647228&as_sdt=2005&sciodt=0,5&hl=en",422,"2020-11-06 21:29:44","CITATION","","","",,,,,3,0.43,1,3,7,""
2,"C Amma, A Fischer, T Stein…","Emotionserkennung auf der basis von gangmustern",2010,"… , Tagung der dvs …","csl.uni-bremen.de","https://www.csl.uni-bremen.de/cms/images/documents/publications/Sportinformatik2010_Beitrag_Emotionserkennung_Christoph_Amma_et_al.pdf","https://scholar.google.com/scholar?cites=8362993651119353291&as_sdt=2005&sciodt=0,5&hl=en",423,"2020-11-06 21:29:44","PDF","","","",,,,,2,0.20,1,4,10,"Zwischenmenschliche Kommunikation ist ein vielschichtiger Prozess, bei dem Informationen auf unterschiedlichen Ebenen und durch verschiedene Modalitäten ausgetauscht werden. Es werden sowohl faktische als auch emotionale Inhalte übermittelt. Dies geschieht sowohl …"
0,"P Muir, J Horner, M Chen, T Kanade, D Pomerleau…","Home/Publications",1998,"Workshop …","ri.cmu.edu","https://www.ri.cmu.edu/pubs/page/146/?wpv_view_count=4514-TCPID4515&wpv_paged=56","",424,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,6,22,"A 30ch 1bit Ultrasonic Echo Wave Memory System for Detecting Multiple Objects–a mobile robot sonar ring sensor system measuring the bearing angle to the reflecting points: the 5th rep."
0,"T Schultz","Category: Evening Talks",,"interdisciplinary-college.org","","https://interdisciplinary-college.org/category/ik2020_courses/evening-talks/","",425,"2020-11-06 21:29:44","HTML","","","",,,,,0,0.00,0,1,,"gestures, motion, and brain activities emitting a wide range of biosignals, which can be captured by a broad panoply of sensors. The processing and interpretation of these biosignals offer an inside perspective on human physical and mental activities and thus …"
0,"C Paredis, P Khosla, A Rizzi, J Gowdy, R Hollis…","Home/Publications",1997,"Workshop …","ri.cmu.edu","https://www.ri.cmu.edu/pubs/page/160/?wpv_view_count=4514-TCPID4515&wpv_paged=42","",426,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,6,23,""
0,"P Charoenpornsawat, T Schultz","IMPROVING WORD SEGMENTATION FOR THAI SPEECH TRANSLATION SYSTEM",,"","","","",427,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,2,,""
0,"A Waibel, T Schultz, DIM Paulik","Bulgarian Speech Recognition and Multilingual Language Modeling",,"cs.cmu.edu","","http://www.cs.cmu.edu/~tanja/Papers/SA-Mircheva.pdf","",428,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,3,,"The following report describes the work at the interAct on Bulgarian speech recognition, including the collection of data, training a Bulgarian speech recognizer and experimenting with Russian text data to improve the recognition. It also gives an overview of the unique …"
0,"F Putze, M Müller, D Heger, T Schultz","Session-independent EEG-based Workload Recognition.",2013,"BIOSIGNALS","scitepress.org","https://www.scitepress.org/Papers/2013/42507/42507.pdf","",429,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,4,7,"In this paper, we investigate the development of a session-independent EEG-based workload recognition system with minimal calibration time. On a corpus of ten sessions with the same subject, we investigate three different approaches: Accumulation of training data …"
0,"M Raab, R Gruhn, E Nöth, D Vasquez, G Aradilla…","Foreword 5 Programme committee 6 Programme 7 Keynote I: Recent developments, challenges and opportunities in spoken dialogue systems technology …",,"","","","",430,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,6,,""
0,"M Wand, M Janke, T Schultz","EMG-UKA Trial Corpus",,"","","","",431,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,3,,""
0,"T Schultz","Multilingual Speech Processing in the context of Under-resourced Languages",,"core.ac.uk","","https://core.ac.uk/download/pdf/197559886.pdf","",432,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,1,,"Writing systems–basic unit is a Grapheme: Logographic: based on semantic units, grapheme represents meaning Chinese:> 10.000 hanzi; Japanese~ 7000 kanji, Korean to some extend Phonographic: based on sound units, grapheme represents sound Segmental …"
0,"AW Black, T Schultz","ISCA Workshop on Multilingual Speech and Language Processing (MULTILING 2006)",,"","","","",433,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,2,,""
0,"T Schultz","Ian Lane Assistant Research Professor Carnegie Mellon University Moffett Field, CA 94035, USA",,"","","","",434,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,1,,""
0,"G Plantier, T Schultz, A Fred, H Gamboa","Biomedical Engineering Systems and Technologies",2015,"","Springer","https://link.springer.com/content/pdf/10.1007/978-3-319-26129-4.pdf","",435,"2020-11-06 21:29:44","","","","",,,,,0,0.00,0,4,5,"The present book includes extended and revised versions of a set of selected papers from the 7th International Joint Conference on Biomedical Engineering Systems and Technologies (BIOSTEC 2014), held in Angers, Loire Valley, France, during March 3–6 …"
0,"DIC Fügen, T Schaaf, T Schultz, JB Mariño","Anton Prevosti Vives",2006,"","","","",436,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,4,14,""
0,"A Porbadnigk, M Wester, JP Calliess, T Schultz","EEG-BASED SPEECH RECOGNITION",,"core.ac.uk","","https://core.ac.uk/download/pdf/197555837.pdf","",437,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,4,,"In this paper, we investigate the use of electroencephalograhic signals for the purpose of recognizing unspoken speech. The term unspoken speech refers to the process in which a subject imagines speaking a given word without moving any articulatory muscle or …"
0,"C Amma, H Volk, T Schultz","Compressed signal representation for inertial sensor signals",2013,"Proceedings of the 2013 ACM conference …","dl.acm.org","https://dl.acm.org/doi/abs/10.1145/2494091.2494140","",438,"2020-11-06 21:29:44","","","","",,,,,0,0.00,0,3,7,"We present and evaluate a method to generate a compressed representation of multi-dimensional inertial sensor signals using a piecewise linear approximation. The representation can be computed on small sensor nodes and thus allows for a reduction of …"
0,"A Waibel, A Badran, AW Black, R Frederking…","Conference on Speech Communication and Technology",2003,"","mt-archive.info","http://mt-archive.info/Eurospeech-2003-Waibel-abs.pdf","",439,"2020-11-06 21:29:44","","","","",,,,,0,0.00,0,5,17,"This paper describes a working two-way speech-to-speech translation system that runs in near real-time on a consumer handheld computer. It can translate from English to Arabic and Arabic to English in the domain of medical interviews. We describe the general architecture and frameworks …"
0,"AW Black, AF Llitjos, M Killer, S Stuker, T Schultz","Focus Papers",,"cs.cmu.edu","","http://www.cs.cmu.edu/afs/cs.cmu.edu/Web/People/cbennett/SyRG/SyRG_02-12-04.pdf","",440,"2020-11-06 21:29:44","","","","",,,,,0,0.00,0,5,,"Page 1. Grapheme Based Speech Synthesis and Speech Recognition SP Kishore skishore@cs.cmu.edu Carnegie Mellon University & International Institute of Information Technology Page 2. 2 Focus Papers • Alan W Black and Ariadana Font Llitjos, “Unit Selection …"
0,"DIC Fiigen, T Schaaf, T Schultz, JB Marino","Anton Prevosti Vives",2006,"","","","",441,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,4,14,""
0,"Q Jin, T Schultz","Robust Far-Field Speaker Identification under Mismatched Conditions",2008,"Ninth Annual Conference of the International …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2008/i08_1893.html","",442,"2020-11-06 21:29:44","","","","",,,,,0,0.00,0,2,12,"While speaker identification performance has improved dramatically over the past years, the presence of interfering noise and the variety of channel conditions pose a major obstacle. Particularly the mismatch between training and test condition leads to severe performance …"
0,"A Himmelsbach, T Schultz","Application of Electrode Arrays for Artifact Removal in an Electromyographic Silent Speech Interface",2014,"Biomedical Engineering Systems …","books.google.com","https://books.google.com/books?hl=en&lr=&id=ubcjBQAAQBAJ&oi=fnd&pg=PA300&dq=%22tanja+schultz%22&ots=fQm17xwrHJ&sig=bU0gv5jbYP7pI28GIkngAvCJPvc","",443,"2020-11-06 21:29:44","","","","",,,,,0,0.00,0,2,6,"An electromygraphic (EMG) Silent Speech Interface is a system which recognizes speech by capturing the electric potentials of the human articulatory muscles, thus enabling the user to communicate silently. This study deals with the introduction of multi-channel electrode …"
0,"T Schultz","To be Defined.",2016,"ICPRAM","","","",444,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,1,4,""
0,"T Schultz, M Wand, M Janke, C Herff","Q1 Project Report (Month 1-3, June-August 2012) on Quiet Phone Communication using Whispered Speech",,"","","","",445,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,4,,""
0,"MC Fuhs, Q Jin, T Schultz","Detecting bandlimited audio in broadcast television shows",2009,"2009 IEEE International …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/4960652/?casa_token=Ej8zN9Tq4LMAAAAA:QP8R1fShZh_8O1j6Lfl9lP1KV-UexIgGD-L2IlJPJZxliktG9sGL9oHDavL3ZHFE-oeEyJEd0g","",446,"2020-11-06 21:29:44","","","","",,,,,0,0.00,0,3,11,"For TV and radio shows containing narrowband speech, Speech-to-text (STT) accuracy on the narrowband audio can be improved by using an acoustic model trained on acoustically matched data. To selectively apply it, one must first be able to accurately detect which audio …"
0,"F Putze, T Schultz","Investigating Intrusiveness of Workload Adaptation",2014,"Proceedings of the 16th International Conference on …","dl.acm.org","https://dl.acm.org/doi/abs/10.1145/2663204.2663279","",447,"2020-11-06 21:29:44","","","","",,,,,0,0.00,0,2,6,"In this paper, we investigate how an automatic task assistant which can detect and react to a user's workload level is able to support the user in a complex, dynamic task. In a user study, we design a dispatcher scenario with low and high workload conditions and compare the …"
0,"T Schultz, M Wand, M Janke, C Herff","Q3 Project Report (Month 7-9, December 2012–March 2013) on Quiet Phone Communication using Whispered Speech",2013,"","","","",448,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,4,7,""
0,"T Schultz","What's involved in building systems? Example: Mandarin Chinese BN",,"","","","",449,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,1,,""
1,"M Wand, M Janke, T Heistermann, C Schulte…","Application of Electrode Arrays for Artifact Removal in an Electromyographic Silent Speech Interface",2013,"… Joint Conference on …","Springer","https://link.springer.com/chapter/10.1007/978-3-662-44485-6_21","https://scholar.google.com/scholar?cites=8918884325857191706&as_sdt=2005&sciodt=0,5&hl=en",450,"2020-11-06 21:29:44","","","","",,,,,1,0.14,0,5,7,"Abstract An electromygraphic (EMG) Silent Speech Interface is a system which recognizes speech by capturing the electric potentials of the human articulatory muscles, thus enabling the user to communicate silently. This study deals with the introduction of multi-channel …"
0,"F Putze, D Heger, M Müller, C Waldkirch…","Profiling Arousal in Response to Complex Stimuli using Biosignals.",2013,"…","pdfs.semanticscholar.org","https://pdfs.semanticscholar.org/5dcc/d90b70e7ae7c89545fa726e9b90dfad81502.pdf","",451,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,5,7,"We investigate the use of biosignals (blood volume pressure and electrodermal activity) for person-independent profiling of arousal responses to complex, long-term stimuli. We report the design of a user study with 14 subjects to elicitate affective responses with films of …"
0,"L Besacier, H Blanchon, C Boitet, J Caelen, R Cattoni…","List of Personnel Associated with the Proposal",,"cs.cmu.edu","","http://www.cs.cmu.edu/afs/cs.cmu.edu/project/cmt-40/Nespole/Proposal/Spectrum/personnel.pdf","",452,"2020-11-06 21:29:44","","","","",,,,,0,0.00,0,6,,"Page 1. List of Personnel Associated with the Proposal • Laurent Besacier, Université Joseph Fourier, Grenoble, France. (Senior Personnel) • Hervé Blanchon, Université Joseph Fourier, Grenoble, France. (Technical Manager) • Christian Boitet, Université Joseph Fourier, Grenoble …"
0,"T Schultz, M Wand, M Janke","Q1 Project Report (Month 1-3, August-November 2012) on Silent Communication over Cell Phones based on ElectroMyoGraphy",2012,"variations","","","",453,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,3,8,""
0,"T Köhler, S Vogel, N Bach, M Eck…","The CMU TransTac 2007 Eyes-free and Hands-free Two-way Speech-to-Speech Translation System",,"cs.cmu.edu","","https://www.cs.cmu.edu/~nbach/papers/CMUTransTac2007-slides.pdf","",454,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,5,,"English ASR 3-state subphonetically tied, fully-continuous HMM 4000 models, max. 64 Gaussians per model, 234K Gaussians in total 13 MFCC, 15 frames stacking, LDA-> 42 dimensions Trained on 138h of American BN data, 124h Meeting data Merge-and-split …"
0,"C Fügen, T Schultz, JC Hu, A Waibel","RECENT ADVANCES IN LINGWEAR: A WEARABLE LINGUISTIC ASSISTANT FOR TOURISTS",,"cs.cmu.edu","","http://www.cs.cmu.edu/~tanja/Papers/ICASSP03-Fuegen.pdf","",455,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,4,,"In this paper we describe our recent advances in Ling-Wear, a wearable linguistic assistant for tourists. Ling-Wear allows uninformed users to find their way in foreign cities or to ask for information about sightseeing, accommodations, and other places of interest. Moreover, the …"
0,"U Nallasamy, AW Black, T Schultz…","Speech Translation for Triage of Emergency Phonecalls in Minority Languages",2008,"… 2008: Proceedings of …","aclweb.org","https://www.aclweb.org/anthology/W08-1509.pdf","",456,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,4,12,"We describe Ayudame, a system designed to recognize and translate Spanish emergency calls for better dispatching. We analyze the research challenges in adapting speech translation technology to 9-1-1 domain. We report our initial research in 9-1-1 translation …"
0,"S Möller, I Wechsung, C Kühnel, B Weiss, T Polzehl…","Evaluation of Cognitive Interactive Systems: Problem Formulation and First Insights",,"","","","",457,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,6,,""
0,"O Pastor, C Sinoquet, G Plantier, T Schultz, A Fred…","Proceedings of the 5th International Conference on Bioinformatics Models, Methods and Algorithms (Bioinformatics2014)",2014,"","hal.archives-ouvertes.fr","https://hal.archives-ouvertes.fr/hal-01169027/","",458,"2020-11-06 21:29:44","","","","",,,,,0,0.00,0,6,6,"Proceedings of the 5th International Conference on Bioinformatics Models, Methods and Algorithms (Bioinformatics2014): O. Pastor, C. Sinoquet, G. Plantier, T. Schultz, ALN Fred and H. Gamboa (eds.). Bioinformatics2014 – Proceedings of the 5th International Conference on Bioinformatics …"
0,"M Bienkiewicz, C Verdier, G Plantier, T Schultz, A Fred…","HEALTHINF 2014-Proceedings of the International Conference on Health Informatics SciTePress 2014, ISBN 978-989-758-010-9",2014,"","hal.univ-grenoble-alpes.fr","http://hal.univ-grenoble-alpes.fr/hal-01744418","",459,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,6,6,"Accéder directement au contenu Accéder directement à la navigation Toggle navigation CCSD. HAL: HAL; HALSHS; TEL; MédiHAL; Liste des portails; AURéHAL; API; Data; Documentation. Episciences.org: Episciences.org; Revues; Documentation. Sciencesconf.org; Support. Connexion …"
0,"T Schultz, M Wand, M Janke","Q2 Project Report (Month 4-6, November 2012-February 2013) on Silent Communication over Cell Phones based on ElectroMyoGraphy",2013,"","","","",460,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,3,7,""
0,"R Sargent, B Bailey, C Witty, A Wright, NS Pollard…","Home/Publications",1997,"Workshop …","ri.cmu.edu","https://www.ri.cmu.edu/pubs/page/160/?wpv_view_count=4514-TCPID4515&wpv_paged=79","",461,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,6,23,""
0,"M Eck, T Schultz","Developing Deployable Spoken Language Translation Systems given Limited Resources",,"d-nb.info","","https://d-nb.info/1013721462/34","",462,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,2,,"Zusammenfassung Die Leistung maschineller Ubersetzungssysteme in Forschungseinrichtungen hat in den letzten Jahren beträchtliche Fortschritte gemacht. Dies ist insbesondere für Statistische Maschinenübersetzung der Fall. Seit ihrer Einführung …"
0,"T Schultz","Biosignal-based Cognitive Systems.",2016,"PhyCS","","","",463,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,1,4,""
0,"T Schultz, M Wand, M Janke","Q3 Project Report (Month 7-9, March 2013-June 2013) on Silent Communication over Cell Phones based on ElectroMyoGraphy",2013,"","","","",464,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,3,7,""
0,"CL Sidner, T Schultz, M Stone, CX Zhai","Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the …",2007,"… Language Technologies 2007 …","aclweb.org","https://www.aclweb.org/anthology/N07-1000.pdf","",465,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,4,13,"This year the annual conference organized by the North American chapter of the Association for Computational Linguistics (NAACL) has undergone a name change to NAACL HLT. This change reflects the integral part that all of Human Language Technology plays in the …"
0,"C Lieske, Y Mori, M Siegel, T Schultz, M Woszczyna","Verbmobil desu keredomo: The Japanese Part of the Verbmobil Spontaneous Spoken Language Machine Translation System",,"","","","",466,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,5,,""
0,"T Schultz, AW Black","Rapid Language Adaptation Tools and p gg p Technologies for Multilingual Speech Processing Systems",,"pdfs.semanticscholar.org","","https://pdfs.semanticscholar.org/1c8b/992ce9dbdad701fddf1fc94284af888308d8.pdf","",467,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,2,,"Writing systems–basic unit is a Grapheme: Writing systems basic unit is a Grapheme: Logographic: based on semantic units, grapheme represents meaning Chinese:> 10.000 hanzi; Japanese~ 7000 kanji, Korean to some extend Phonographic: based on sound units …"
0,"B Denby, T Schultz, K Honda","Special Issue on ''Silent Speech''Interfaces",,"","","","",468,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,3,,""
0,"A Waibel, L Levin, A Lavie, T Schultz","Interactive Systems Laboratories Spontaneous Speech Translation Project Report on ATR Funded Research April 2001 to September 2001",,"","","","",469,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,4,,""
0,"T Schultz, K Schaaff","Challenges on Emotion Induction with the International Affective Picture System",,"Citeseer","","http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.212.6071&rep=rep1&type=pdf","",470,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,2,,"During the last decades, the interest in studying human emotional behavior has been constantly increasing. To analyze emotional behavior in scientific studies, it is necessary to have a method to induce different emotions. Therefore, numerous methods have been …"
0,"T Schultz, SC Jou, S Vogel, S Saleem","Jeju Island, Korea October 4-8, 2004",2004,"","mt-archive.info","http://mt-archive.info/Interspeech-2004-Schultz-abs.pdf","",471,"2020-11-06 21:29:44","","","","",,,,,0,0.00,0,4,16,"In this paper we present first experiments towards a tighter coupling between Automatic Speech Recognition (ASR) and Statistical Machine Translation (SMT) to improve the overall performance of our speech translation system. In coventional speech translation systems …"
0,"B Denby, T Schultz, K Honda","Special Issue Silent Speech Interfaces",2010,"","… SCIENCE BV PO BOX 211, 1000 …","","",472,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,3,10,""
0,"T Schultz, M Wand, M Janke, C Herff","Q2 Project Report (Month 4-6, September–December 2012) on Quiet Phone Communication using Whispered Speech",2012,"","","","",473,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,4,8,""
0,"W Macherey, M McTear, M Ostendorf, J Polifroni…","Sachin Kajarekar, SRI International, USA Philipp Koehn University of Edinburgh, Edinburgh, UK Roland Eric Kuhn, University of Quebec, Gatineau …",2008,"Computer Speech and …","","","",474,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,5,12,""
0,"C Amma, M Georgi, T Schultz","Airwriting: Mobile text-entry by 3d-space handwriting",,"… DC 4D94 3BAB E34 D 73A","Citeseer","http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.671.6213&rep=rep1&type=pdf#page=15","",475,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,3,,"We demonstrate a wearable text-entry system. Users can write text in the air, as if they were writing on an imaginary blackboard. Motion is sensed by inertial sensors attached to the back of the hand. Written text is spotted and recognized by a two-stage approach using …"
0,"L Besacier, E Barnard, A Karpov, T Schultz","Special Issue on Processing Under-Resourced Languages-Speech Communication Journal",2014,"","hal.archives-ouvertes.fr","https://hal.archives-ouvertes.fr/hal-00959237/","",476,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,4,6,"no abstract."
0,"T Schultz, M Westphal, A Waibel","The GlobalPhone Project: Multilingual LVCSR",,"isl.anthropomatik.kit.edu","","http://isl.anthropomatik.kit.edu/pdf/Schultz1997b.pdf","",477,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,3,,"This paper describes our recent effort in developing the Global-Phone database for multilingual large vocabulary continuous speech recognition. In particular we present the current status of the GlobalPhone corpus containing high quality speech data for the 9 …"
0,"F Gregersen, S Ratté, C Samuelsson, KV Beaman…","1. Changes across linguistic levels and across life stages: In search of a pattern Frans Gregersen (University of Copenhagen)",,"helsinki.fi","","https://www.helsinki.fi/sites/default/files/atoms/files/clare_book_of_abstracts.docx","",478,"2020-11-06 21:29:44","DOC","","","",,,,,0,0.00,0,5,,"This paper aims at providing a corpus linguistic counterpart to the current hypotheses about the effects of ageing on the various subsystem of language. The LANCHART Corpus, a corpus composed of more than 1000 hours of audio material, where we have studied …"
0,"B Denby, T Schultz, K Honda","Guest Editorial| Speech Communication-Volume 52, Issue 4",2010,"","North-Holland","","",479,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,3,10,""
0,"M Jiang, T Schultz","Speech Technologies for E-language Project",,"researchgate.net","","https://www.researchgate.net/profile/Minghu_Jiang/publication/255447340_Paper_3_Review_of_Speech_Technologies/links/540a88620cf2df04e7492821/Paper-3-Review-of-Speech-Technologies.pdf","",480,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,2,,"According to ELL program and system design, this report describes the role of state-of-the-art speech technologies, clarifies challenges and evaluation criteria, Our aim is to identify and recommend the most suitable specific speech recognition and synthesis systems to be …"
0,"AR Toth, M Wand, SCS Jou, T Schultz…","Synthesizing speech from surface electromyography and acoustic Doppler sonar.",2010,"The Journal of the …","asa.scitation.org","https://asa.scitation.org/doi/abs/10.1121/1.3384186","",481,"2020-11-06 21:29:44","","","","",,,,,0,0.00,0,5,10,"Numerous techniques have been devised to process speech audio in noise, but automatic speech recognition is difficult when the noise is too great. An alternative approach is to collect data that represent the speech production process but is less affected by noise in the …"
0,"MF Secca, J Schier, G Plantier, T Schultz, ALN Fred…","BIOIMAGING 2014-Proceedings of the International Conference on Bioimaging, ESEO, Angers, Loire Valley, France, 3-6 March, 2014",2014,"","hal.archives-ouvertes.fr","https://hal.archives-ouvertes.fr/hal-01498057/","",482,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,6,6,"no abstract."
0,"A Gelhard, U Schmidt, T Schultz","Stillstellen Medien, Aufzeichnung, Zeit",2004,"","philpapers.org","https://philpapers.org/rec/GELSMA","",483,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,3,16,"Sign in | Create an account. PhilPapers PhilPeople PhilArchive PhilEvents PhilJobs. PhilPapers home. Syntax; Advanced Search. New: All new items; Books; Journal articles; Manuscripts. Topics: All Categories; Metaphysics and Epistemology: Metaphysics and Epistemology; Epistemology; …"
0,"T Schlippe, M Merz, T Schultz","Methods for Efficient Semi-Automatic Pronunciation Dictionary Bootstrapping",2014,"Fifteenth Annual Conference of the …","isca-speech.org","https://www.isca-speech.org/archive/interspeech_2014/i14_2867.html","",484,"2020-11-06 21:29:44","","","","",,,,,0,0.00,0,3,6,"In this paper we propose efficient methods which contribute to a rapid and economic semi-automatic pronunciation dictionary development and evaluate them on English, German, Spanish, Vietnamese, Swahili, and Haitian Creole. First we determine optimal strategies for …"
0,"M Westphal, T Schultz, A Waibel, R Hollis, J Gowdy…","Home/Publications",1998,"Workshop …","ri.cmu.edu","https://www.ri.cmu.edu/pubs/page/145/?wpv_view_count=4514-TCPID4515&wpv_paged=49","",485,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,6,22,""
0,"R Hsiao, T Schultz","Towards single pass discriminative training for speech recognition",2012,"2012 IEEE International Conference on …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/6288818/?casa_token=eyiVQiz8iWgAAAAA:6yHuXOyNmLhRdcVEpKthBc63LpMXlAT9Ts7A-K_IlZwcG-jpXyOwZdrzlyPcxc8uaV1mBmWDtg","",486,"2020-11-06 21:29:44","","","","",,,,,0,0.00,0,2,8,"This paper describes how we can combine our previously proposed fast extended Baum-Welch algorithm and generalized discriminative feature transformation to achieve single pass discriminative training, which we only process the data once. Compared to the state of …"
0,"T Schultz","Biosignals and Interfaces.",2011,"BIODEVICES","","","",487,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,1,9,""
0,"M Klusch, J Contreras, F Wu, O Shehory, R Voyles…","Home/Publications",1997,"Workshop …","ri.cmu.edu","https://www.ri.cmu.edu/pubs/page/160/?wpv_view_count=4514-TCPID4515&wpv_paged=8","",488,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,6,23,""
0,"T Schultz","Rapid Deployment of Speech Processing Systems to New Languages and Domains",,"Šeste konference JEZIKOVNE TEHNOLOGIJE","researchgate.net","https://www.researchgate.net/profile/Tanja_Schultz/publication/266507374_Rapid_Deployment_of_Speech_Processing_Systems_to_New_Languages_and_Domains/links/5478368f0cf293e2da286179.pdf","",489,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,1,,"Prerequisites and Costs: o Community itself must want it, Surrounding culture must respect it o Funding for courses, materials, and teachers, support the community o Crystal estimates about $80.000/year per language o 3000 endangered languages is about $700 Mio… o …"
0,"T Schultz, A Waibel, M Westphal, R Hollis, J Gowdy…","Home/Publications",1998,"Workshop …","ri.cmu.edu","https://www.ri.cmu.edu/pubs/page/150/?wpv_view_count=4514-TCPID4515&wpv_paged=62","",490,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,6,22,""
0,"C Mason, K Gadzicki, M Meier, F Ahrens, T Kluss…","From Human to Robot Everyday Activity",,"csl.uni-bremen.de","","https://www.csl.uni-bremen.de/cms/images/documents/publications/mason_iros2020.pdf","",491,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,6,,"The Everyday Activities Science and Engineering (EASE) Collaborative Research Consortium's mission to enhance the performance of cognition-enabled robots establishes its foundation in the EASE Human Activities Data Analysis Pipeline. Through collection of …"
0,"F Putze, J Meyer, J Borné, T Schultz, DV Holt, J Funke","Combining cognitive modeling and EEG to predict user behavior in a search task",,"Citeseer","","http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.444.2814&rep=rep1&type=pdf","",492,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,6,,"Method The task was adapted from the maze search task used by Fu & Anderson (2006), which is a multi-step decision and learning paradigm. In this task, participants have to find a goal node in a hierarchical tree structure. For purposes of this study, the tree structure was …"
0,"T Schultz","SPICE-An Interactive Toolkit for Rapid Portability of Speech Processing Systems to new Languages",2006,"Multilingual Speech and Language Processing","isca-speech.org","https://www.isca-speech.org/archive_open/ml06/ml06_KN1.html","",493,"2020-11-06 21:29:44","","","","",,,,,0,0.00,0,1,14,"In recent years, speech processing products had been widely distributed all over the world, reflecting a general believe that speech technologies have a huge potential to let everyone participate in today's information revolution and to bridge the language barrier gap. In spite …"
0,"T Schultz, T Hueber, DJ Krusienski, J Brumberg","Special Issue on Biosignal-based Spoken Communication",,"signalprocessingsociety.org","","https://signalprocessingsociety.org/sites/default/files/uploads/special_issues_deadlines/TASLP_SI_biosignal.pdf","",494,"2020-11-06 21:29:44","","","","",,,,,0,0.00,0,4,,"Speech is a complex process emitting a wide range of biosignals, including, but not limited to, acoustics. These biosignals–stemming from the articulators, the articulator muscle activities, the neural pathways, or the brain itself–can be used to circumvent limitations of …"
0,"M Best, K Takahashi, N Hatsopoulos, C Herff…","Program in Chronological Order",,"ieeexplore.ieee.org","","https://ieeexplore.ieee.org/abstract/document/7146536/","",495,"2020-11-06 21:29:44","","","","",,,,,0,0.00,0,5,,"Brain Computer Interfaces-Poster Session (Poster Session) … Comparing Decoding Performance between Functionally Defined Neural Populations Best, Matthew (Univ. of Chicago); Takahashi, Kazutaka* (Univ. of Chicago); Hatsopoulos, Nicholas (Univ. of Chicago) … Hybrid …"
0,"T Schultz","Text-to-Speech Synthesis",,"pdfs.semanticscholar.org","","https://pdfs.semanticscholar.org/9a0f/ff9611832cd78a82a32f47b8ca917fbd4077.pdf","",496,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,1,,"• This is a pen.• My cat who lives dangerously has nine lives.• He stole $100 from the bank.• He stole 1996 cattle on 25 Nov 1996.• He stole $100 million from the bank.• It's 13 St. Andrew St. near the bank.• Its a PIII 650Mhz, 128MB RAM, 13.6 Gb SCSI, 24x cdrom and 19"" …"
0,"D Heger, A de Pesters, C Herff, D Telaar…","Brain-to-text: Decoding spoken phrases from phone representations in the brain",2015,"","Health Research, Inc. Menands …","","",497,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,5,5,""
0,"T Schultz, M Wand, M Janke","Q4 Project Report (Month 10-12, July 2013-September 2013) on Silent Communication over Cell Phones based on ElectroMyoGraphy",2013,"","","","",498,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,3,7,""
0,"TU Lipreading, U Meier, R Stiefelhagen, J Yang…","Home/Publications",1999,"Journal Article","ri.cmu.edu","https://www.ri.cmu.edu/pubs/page/141/","",499,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,5,21,""
0,"S Sachdev, Y Wang, A Waibel, T Schultz, M Westphal…","Home/Publications",1998,"Workshop …","ri.cmu.edu","https://www.ri.cmu.edu/pubs/page/144/?wpv_view_count=4514-TCPID4515&wpv_paged=6","",500,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,6,22,""
0,"T Schultz, M Stone, CX Zhai","Preface from the program co-chairs",2007,"… 2007: The Conference of the North …","experts.illinois.edu","https://experts.illinois.edu/en/publications/preface-from-the-program-co-chairs","",501,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,3,13,"Schultz, T., Stone, M., & Zhai, CX (2007). Preface from the program co-chairs. NAACL HLT 2007 - Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics, Proceedings of the Main Conference, VII-VIII … Preface …"
0,"N Srisuwan, M Wand, M Janke…","Enhancement of EMG-based Thai number words classification using frame-based time domain features with stacking filter",2014,"… Annual Summit and …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/7041549/?casa_token=kJSGi8G9wM0AAAAA:MPyZy8oDlPqsI919x19RXKHL6Siq2WeCmMlom2VhoqWIJXgT5CErOyF3KH0GY1D9EVGdmfH3tQ","",502,"2020-11-06 21:29:44","","","","",,,,,0,0.00,0,4,6,"In order to overcome a problem existing in a classical automatic speech recognition (eg ambient noise and loss of privacy), Electromyography (EMG) from speech production muscles was used in place of a human speech signal. We aim to investigate the EMG …"
0,"T Schultz-Mirbach, B Reichenbacher","Reconstruction of Oligocene and Neogene freshwater fish faunas",2006,"Acta palaeontologica polonica","doc.rero.ch","https://doc.rero.ch/record/15556","",503,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,2,14,"Schultz-Mirbach, Tanja; Reichenbacher, Bettina."
1,"IT Schultz, M Pruzinec","Facial Expression Recognition using Surface Electromyography",,"pdfs.semanticscholar.org","","https://pdfs.semanticscholar.org/7370/f7109318a0ed91ae8a87371bb01d774e696e.pdf","https://scholar.google.com/scholar?cites=17376353647417017931&as_sdt=2005&sciodt=0,5&hl=en",504,"2020-11-06 21:29:44","PDF","","","",,,,,1,0.00,1,2,,"Facial expressions are an essential part of human communication. The integration of information transferred by these expressions into the human-computer interaction can lead to affective systems that are able to adapt their behavior according to reactions shown by the …"
0,"IT Schultz, D Lemcke, DIT Schlippe","A Game for Pronunciation Generation through Crowdsourcing",,"csl.uni-bremen.de","","https://csl.uni-bremen.de/cms/images/documents/publications/SA-Daniel-Lemcke.pdf","",505,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,3,,"With the online tool Keynounce we prove, that it is possible to generate pronunciation dictionaries with the help of an unknown and potentially unskilled crowd on the Internet. By providing a keyboard of sounds, as well as a synthesizer, the users actually have fun …"
0,"IT Schultz, C Amma, DID Gehrig","Airwriting Recognition using Wearable Motion Sensors",,"Citeseer","","http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.207.1883&rep=rep1&type=pdf","",506,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,3,,"In my work, I introduce a wearable computing device for recognition of text written in the air, like on an imaginary blackboard. For that purpose, I designed and implemented a data glove, based on inertial sensors. The data glove is equipped with three orthogonal …"
0,"IT Schultz, L Gren, DIT Schlippe, DINT Vu","Unsupervised Language Model Adaptation for Automatic Speech Recognition of Broadcast News Using Web 2.0",,"csl.uni-bremen.de","","https://www.csl.uni-bremen.de/cms/images/documents/publications/DA_LukaszGren.pdf","",507,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,4,,"We improve the automatic speech recognition of broadcast news using paradigms from Web 2.0 to obtain time-and topic-relevant text data for language modeling. We elaborate an unsupervised text collection and decoding strategy that includes crawling appropriate texts …"
0,"IT Schultz, Z Mihaylova, DIT Schlippe","An Architecture of a Telephone-based System for Speech Data Collection",,"csl.uni-bremen.de","","https://www.csl.uni-bremen.de/cms/images/documents/publications/SA_ZlatkaMihaylova.pdf","",508,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,3,,"The work describes the process of building a telephone-based interactive voice response (IVR) system. For the collection of audio data for speech recognition, webbased audio recorders are used so that technical audio equipment does not have to be shipped to the …"
0,"IT Schultz, G Feng, DMM Wand","Initialization Methods for an EMG-based Silent Speech Recognizer",,"Citeseer","","http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.184.8403&rep=rep1&type=pdf","",509,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,3,,"The application of surface electromyography (EMG) to automatic speech recognition is a relatively new research field which has been developing rapidly in recent years. Previous works in this area were usually limited to distinguishing whole utterances, but a short time …"
0,"F Putze, IT Schultz","Adaptive Cognitive Interaction Systems",2014,"","d-nb.info","https://d-nb.info/106106915X/34","",510,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,2,6,"In this chapter, we introduce the concept of empirical cognitive modeling to detect user states from sensor data. We start by discussing the related work in this field. We then present three examples of empirical cognitive models to detect the user states workload level …"
0,"IT Schultz, D Ernst","Bootstrapping Pronunciation Dictionaries with Multilingual Phoneme Recognition",,"csl.uni-bremen.de","","https://csl.uni-bremen.de/cms/images/documents/publications/BA-DarioErnst.pdf","",511,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,2,,"In this thesis, we present an unsupervised approach to automatically bootstrap pronunciation dictionaries from speech data. We use phoneme recognizers to retrieve phoneme sequences for a given corpus of speech data and associated transcriptions. Then …"
0,"IT Schultz, K El Kara, DMM Wand","Session-Adaptive Speech Recognition Based On Surface Electromyography",,"csl.uni-bremen.de","","https://www.csl.uni-bremen.de/cms/images/documents/publications/SA_Elkara.pdf","",512,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,3,,"Abstract The development of Silent Speech Interfaces, which allow speech-based communication without uttering any sound, has gained increasing popularity in the recent years. One of the best-developed methods to enable this technology is surface …"
0,"IT Schultz, EGK Djomgang, DIT Schlippe, DIT Vu","Hausa Large Vocabulary Continuous Speech Recognition",,"csl.uni-bremen.de","","https://csl.uni-bremen.de/cms/images/documents/publications/SA_EdyGuevaraKomgang.pdf","",513,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,4,,"Africa is the continent with a second largest number of languages in the world. According to [46], 32.8% of the world languages is spoken in Asia, while 30.3% is spoken in Africa. However, a lot of African languages do not have a developed writing system and for those …"
0,"IT Schultz, L Gren, DINT Vu, DIT Schlippe","Enhancing Language Models for ASR using RSS Feeds",,"csl.uni-bremen.de","","https://www.csl.uni-bremen.de/cms/images/documents/publications/SA_LukaszGren.pdf","",514,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,4,,"In this work, we improve the automatic speech recognition of broadcast news with time-and topic-relevant text data. Our previous method for collecting large amounts of text data for language modelling was to use the crawler in the Rapid Language Adaptation Toolkit …"
0,"IT Schultz, S Sitto, DID Gehrig","Developing a Human Motion Recognition System by Applying Automatic Segmentation and Model Transfer",,"csl.uni-bremen.de","","https://csl.uni-bremen.de/cms/images/documents/publications/DA_Sandro_Sitto.pdf","",515,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,3,,"In this thesis the development of a human motion recognition system using automatic segmentation and model transfer is investigated. Complex human motions are modeled using Hidden Markov Models (HMMs) for primitive motion units. The training data for the …"
0,"IT Schultz, Q He, DIT Schlippe","Automatic Pronunciation Dictionary Generation from Wiktionary and Wikipedia",,"Citeseer","","http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.170.199&rep=rep1&type=pdf","",516,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,3,,"In this work we show that dictionaries from the World Wide Web which contain phonetic notations may represent a good basis for the rapid pronunciation dictionary creation within the speech recognition and speech synthesis system building process. As a representative …"
0,"MT Schultz, MR Schlüter","Reducing development costs of large vocabulary speech recognition systems",,"afcp-parole.org","","http://www.afcp-parole.org/doc/theses/these_TF14.pdf","",517,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,2,,"One of the outstanding challenges in large vocabulary automatic speech recognition (ASR) is the reduction of development costs required to build a new recognition system or adapt an existing one to a new task, language or dialect. The state-of-the-art ASR systems are based …"
0,"IT Schultz","Lexical and Acoustic Adaptation for Multiple Non-Native English Accents",2011,"","csl.uni-bremen.de","https://csl.uni-bremen.de/cms/images/documents/publications/DA_ZlatkaMihaylova.pdf","",518,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,1,9,"This work investigates the impact of non-native English accents on the performance of an large vocabulary continuous speech recognition (LVCSR) system. Based on the GlobalPhone corpus [1], a speech corpus was collected consisting of English sentences …"
0,"IT Schultz","Error Blaming based on Decoding Output",2012,"","csl.uni-bremen.de","https://www.csl.uni-bremen.de/cms/images/documents/publications/ba_mark_erhardt.pdf","",519,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,1,8,"Creating new and improving existing Automatic Speech Recognition (ASR) systems is arduous work, requiring the manual optimization of parameters and elimination of errors. Even for an experienced user it can be challenging to recognize and utilize potential for …"
0,"W Quaschningk, DIT Schlippe, IT Schultz","Analyzing Single and Combined G2P Converter Outputs over Training Data",,"csl.uni-bremen.de","","https://csl.uni-bremen.de/cms/images/documents/publications/SA_WolfQuaschningk.pdf","",520,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,3,,"In this work we present the combination of grapheme-tp-phoneme (G2P) converter outputs in order to improve the outputs gained by single G2P converters. This is beneficial where low resources are available to train the single converters. Our experiments are conducted …"
0,"IT Schultz, W Breiter, DIT Schlippe, DINT Vu","Rapid Bootstrapping of Haitian Creole Large Vocabulary Continuous Speech Recognition",,"csl.uni-bremen.de","","https://csl.uni-bremen.de/cms/images/documents/publications/SA_WojtekBreiter.pdf","",521,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,4,,"In this work we present an automatic speech recognition system (ASR) for Haitian Creole. We bootstrap the system with the Rapid Language Adaptation Toolkit and improve both, the acoustic and the language model. The acoustic model mainly benefits from the usage of …"
0,"IT Schultz, P Fung, J Gebhardt, DIT Schlippe","Speech Recognition on English-Mandarin Code-Switching Data using Factored Language Models",,"csl.uni-bremen.de","","https://csl.uni-bremen.de/cms/images/documents/publications/DA_JanGebhardt.pdf","",522,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,4,,"Code-switching is defined as” the alternate use of two or more languages in the same utterance or conversation”[1]. CS is a wide-spread phenomenon in multilingual communities, where multiple languages are concurrently used in a conversation. For …"
0,"TS Rosenqvist, EJ Heimdal","The making of a mock-up",2011,"Participatory …","University of Southern Denmark","","",523,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,2,9,""
0,"EJ Heimdal, TS Rosenqvist","Mocking-up textile solutions for hospitals: Position Paper for the Materialities in the Design Process Workshop",2010,"… Designing Interactive Systems","forskningsdatabasen.dk","https://www.forskningsdatabasen.dk/en/catalog/2389434081","",524,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,2,10,""
0,"TS Rosenqvist, H Lindegaard…","ENGAGING ACTORS IN CO-CREATING HETEROGENEOUS INNOVATIONS",2011,"DS 68-1: Proceedings …","designsociety.org","https://www.designsociety.org/publication/30443/engaging_actors_in_co-creating_heterogeneous_innovations","",525,"2020-11-06 21:29:44","","","","",,,,,0,0.00,0,3,9,"In this paper we share and analyze our experiences staging a co-design process in which we through different interventions engage important stakeholders in designing. Our experiences are taking from a innovation and research project about user-involvement in …"
0,"QJT Schultz, A Waibel","SPEAKER IDENTIFICATION USING MULTILINGUAL PHONE STRINGS",,"ieeexplore.ieee.org","","https://ieeexplore.ieee.org/abstract/document/1005697/","",526,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,2,,"Far-field speaker identification is very challenging since varying recording conditions often result in un-matching training and testing situations. Although the widely used Gaussian Mixture Models (GMM) approach achieves reasonable good results when training and …"
0,"RDJ Beyerer, UDHT Schultz","Advances in Artificial Intelligence",,"Springer","","https://link.springer.com/content/pdf/10.1007/978-3-642-16111-7.pdf","",527,"2020-11-06 21:29:44","","","","",,,,,0,0.00,0,2,,"The 33rd Annual German Conference on Artificial Intelligence (KI 2010) took place at the Karlsruhe Institute of Technology KIT, September 21–24, 2010, under the motto “Anthropomatic Systems.” In this volume you will find the keynote paper and 49 papers of …"
0,"V Becker, ITS KIT, DIFP KIT","Adaptation of a Cognitive Decision-Making Model through the Application of Workload Recognition",,"researchgate.net","","https://www.researchgate.net/profile/Vincent_Becker2/publication/320922457_Adaptation_of_a_Cognitive_Decision-Making_Model_through_the_Application_of_Workload_Recognition/links/5bd3192b4585150b2b88b81f/Adaptation-of-a-Cognitive-Decision-Making-Model-through-the-Application-of-Workload-Recognition.pdf","",528,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,3,,"Human performance in cognitive tasks is highly dependent on the human's workload. To simulate a human performing a task, cognitive models are used which are fit to human data. The workload conditions prevailing during an experiment are susceptible to change. It is the …"
1,"T Schultz, H Soltau","Automatische Identifizierung spontan gesprochener Sprachen mit neuronalen Netzen.",1996,"KONVENS","isl.anthropomatik.kit.edu","http://isl.anthropomatik.kit.edu/pdf/Schultz1996.pdf","https://scholar.google.com/scholar?cites=13201402972065673014&as_sdt=2005&sciodt=0,5&hl=en",529,"2020-11-06 21:29:44","PDF","","","",,,,,1,0.04,1,2,24,"Automatic language idenfication (LID) is one of the keyproblems in building multilingual speech recognition and translation systems. ln this paper we present a front-end module to identify one out of four languages German, English, Spanisch and Japanese for use in …"
2,"T Schultz, C Amma, M Wand, D Heger…","Biosignale-basierte Mensch-Maschine Schnittstellen.",2013,"…","csl.uni-bremen.de","https://www.csl.uni-bremen.de/cms/images/documents/publications/Biosignals.TSchultz.10012014.pdf","https://scholar.google.com/scholar?cites=12007852134444498976&as_sdt=2005&sciodt=0,5&hl=en",530,"2020-11-06 21:29:44","PDF","","","",,,,,2,0.29,0,5,7,"Zusammenfassung Menschliche Kommunikation basiert auf Signalen wie Sprache, Mimik oder Gestik und deren Interpretation erscheint uns Menschen sehr natürlich. Aus diesem Grund wird seit langem daran geforscht, diese Fähigkeiten auf die Mensch-Maschine …"
1,"D GEHRIG, H KÜHNE, T SCHULTZ","Erkennung von menschlichen Bewegungen mit Hidden Markov Modellen",2010,"… , Tagung der dvs-Sektion …","csl.uni-bremen.de","https://csl.uni-bremen.de/cms/images/documents/publications/Gehrig_DVS10_Bewegungserkennung_mit_HMMs.pdf","https://scholar.google.com/scholar?cites=14198733704801431374&as_sdt=2005&sciodt=0,5&hl=en",531,"2020-11-06 21:29:44","PDF","","","",,,,,1,0.10,0,3,10,"Ein wichtiges und ständig wachsendes Forschungsgebiet innerhalb der Robotik sind Humanoide Roboter. Diese sollen ein menschenähnliches Aussehen haben und sich menschlich verhalten. Dazu ist es notwendig, dass sie menschliche Tätigkeiten und …"
1,"R Mikut, M Reischl, F Putze…","Data-Mining-Methoden für die Demenzforschung: Stand und Potenziale",2013,"… für Menschen mit Demenz …","researchgate.net","https://www.researchgate.net/profile/Ralf_Mikut/publication/270819836_Data-Mining-Methoden_fur_die_Demenzforschung_Stand_und_Potenziale/links/54b53ea80cf2318f0f973e69.pdf","https://scholar.google.com/scholar?cites=9191046686016753271&as_sdt=2005&sciodt=0,5&hl=en",532,"2020-11-06 21:29:44","PDF","","","",,,,,1,0.14,0,4,7,"91 dem Zeitpunkt des Auftretens TEvent [kE, n]. Sie werden auch als Zeitstempeldaten bezeichnet und häufig in Logfiles abgelegt. Optional können noch KPE Parameter ergänzt werden, die das Ereignis näher beschreiben. Solche Events können zB aus Zeitreihen mit …"
1,"T Schultz","Technik und Demenz",2019,"… und Prävention für Menschen mit Demenz","Springer","https://link.springer.com/chapter/10.1007/978-3-662-58130-8_16","https://scholar.google.com/scholar?cites=1483322379491791017&as_sdt=2005&sciodt=0,5&hl=en",533,"2020-11-06 21:29:44","","","","",,,,,1,1.00,1,1,1,"Intelligente technische Systeme ermöglichen die Früherkennung demenzieller Entwicklungen sowie die bedarfsgerechte und individualisierte Unterstützung, Aktivierung und Betreuung von Menschen mit Demenz. Durch die allzeitige Verfügbarkeit solcher …"
0,"T Schultz, F Putze","Perspektive der Informatik",2018,"","d-nb.info","https://d-nb.info/1185985808/34","",534,"2020-11-06 21:29:44","BOOK","","","",,,,,0,0.00,0,2,2,"Die technische Unterstützung von Menschen mit Demenz gewinnt aus unserer Sicht zunehmend an Bedeutung, da in naher Zukunft zahlreiche ungünstige Entwicklungen bei der umfänglichen Pflege von Menschen mit Demenz zu erwarten sind: Bedingt durch den …"
0,"S Fuchs, C Amma, T Schultz","Völlig losgelöst-Berührungslose Smartphone-Eingabe durch Airwriting-Campusreport am 26.03. 2013",2013,"","publikationen.bibliothek.kit.edu","https://publikationen.bibliothek.kit.edu/1000111261","",535,"2020-11-06 21:29:44","","","","",,,,,0,0.00,0,3,7,"Für Luftgitarre gibt es bereits einen eigenen Wettbewerb. Luftschreiben dagegen ist noch weitgehend unbekannt. Das wird sich mit großer Wahrscheinlichkeit bald ändern. Ein junger Wissen-schaftler am Karlsruher Institut für Technologie hat mit dem? Airwri-ting? eine …"
0,"DMM Wand, T Schultz","Methoden der Biosignalverarbeitung",,"","","","",536,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,2,,""
0,"T Schultz, DIF Putze, DIT Schlippe","Multilinguale Mensch-Maschine Kommunikation",,"informatik.kit.edu","","https://www.informatik.kit.edu/922_4326.php","",537,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,3,,"Multilinguale Mensch-Maschine-Kommunikation. Multilinguale Mensch-Maschine-Kommunikation. Typ: Vorlesung. Lehrstuhl: Fakultät für Informatik. Semester: Sommersemester 2010. Zeit: Dienstag, 14:00-15:30 wöchentlich Raum -101 (-1. Stock) 50.34 Informatik, Kollegiengebäude am …"
0,"P Geutner, FD Buoe, T Kemp, AE Mcnair, I Rogina…","NACH OBEN",,"","","","",538,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,6,,""
0,"T Schultz, A Waibel","Das Projekt GlobalPhone: Multilinguale Spracherkennung",1998,"… Sprache und Sprechen: Tagungsband der 4 …","researchgate.net","https://www.researchgate.net/profile/Tanja_Schultz/publication/36453247_Das_Projekt_GlobalPhone_Multilinguale_Spracherkennung/links/547836950cf293e2da286180.pdf","",539,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,2,22,"Zusammenfassung Dieser Artikel beschreibt die Entwicklung eines Spracherkennungssystems GlobalPhone für den Einsatz in multilingualer kontinuierlicher Spracherkennung für große Vokabulare. In diesem Projekt der Universität Karlsruhe wer …"
0,"T Schultz, H Soltau","11 Automatische Identifizierung spontan gesprochener Sprachen mit neuronalen",1996,"… and Speech Technology: Results of the 3rd …","books.google.com","https://books.google.com/books?hl=en&lr=&id=jiZMAvrvxhsC&oi=fnd&pg=PA102&dq=%22tanja+schultz%22&ots=sNJvSav2X9&sig=XiKZXx45JvCXPst78dcwfWotNFM","",540,"2020-11-06 21:29:44","","","","",,,,,0,0.00,0,2,24,"Automatic language idenfication (LID) is one of the key problems in building multilingual speech recognition and translation systems. In this paper we present a front-end module to identify one out of the four languages German, English, Spanish and Japanese for use in …"
0,"T Schultz, DMM Wand","Biosignale und Benutzerschnittstellen",,"","","","",541,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,2,,""
0,"T Schultz","Vorlesung SS 2013 Multilinguale Mensch-Maschine Kommunikation",,"","","","",542,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,1,,""
0,"B Suhm, P Geutner, T Kemp, I Rogina, T Schultz…","NACH OBEN",,"","","","",543,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,6,,""
0,"T Schultz, C Amma, D Heger…","Human-Machine Interfaces Based on Biosignals",2013,"AT …","WALTER DE GRUYTER GMBH …","","",544,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,4,7,""
0,"T Schultz","Akustische Modellierung sprachlicher und nichtsprachlicher Ger ausche",,"cs.cmu.edu","","http://www.cs.cmu.edu/~tanja/Papers/schultz_SA.ps.gz","",545,"2020-11-06 21:29:44","PS","","","",,,,,0,0.00,0,1,,"J ungster Forschungsgegenstand in der Spracherkennung ist spontan gesprochene Sprache. Charakteristisches Ph anomen spontaner Sprache ist der mangelnde Sprach u, der unter anderem durch Sprechpausen bedingt wird, die mit verschiedenartigen Ger …"
0,"IT Schultz, H Volk","Optimierte Signalvorverarbeitung am Beispiel eines Cloud basierten Airwriting Systems für Smartphones",,"","","","",546,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,2,,""
0,"MT Schultz","Réduction des coûts de développement de systèmes de reconnaissance de la parole à grand vocabulaire",2014,"","pdfs.semanticscholar.org","https://pdfs.semanticscholar.org/a5e6/a541bffe09b5443320e490038bbb50e172e8.pdf","",547,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,1,6,"Le but principal de la reconnaissance automatique de la parole (RAP) est d'effectuer la conversion entre un énoncé oral, représenté par un flux audio continu, vers une séquence discrète de mots écrits. La RAP peut être utile pour des différentes applications, telles que la …"
0,"IT Schultz, M Zahner, DIM Janke","Konvertierung von myoelektrischen Signalen der Gesichtsmuskulatur zu Sprache: Ein Unit Selection-Ansatz",,"csl.uni-bremen.de","","https://csl.uni-bremen.de/cms/images/documents/publications/MA_Zahner_Druckversion_bunt_korrigiert.pdf","",548,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,3,,"In dieser Masterarbeit wird ein neuer Ansatz zur Konvertierung von Muskelsignalen zu hörbarer Sprache vorgestellt. Allein die elektrischen Signale der Gesichtsmuskulatur werden mittels Oberflächenelektroden aufgezeichnet, ohne dass der Sprecher hörbare …"
0,"IKD Müller-Glaser, IT Schultz","Systeme und Methoden zur Erfassung der persönlichen Fitness",2008,"","","","",549,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,2,12,""
0,"IT Schultz, A Himmelsbach, DMM Wand","Rauschunterdrückung durch Quellenseparation in der EMG-basierten Spracherkennung",,"csl.uni-bremen.de","","https://csl.uni-bremen.de/cms/images/documents/publications/BA_Adam_Himmelsbach.pdf","",550,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,3,,"Ein Problem der EMG-basierten Spracherkennung resultiert aus der Messmethodik. Die Erfassung der relativ schwachen Muskelaktivitäten führt dazu, dass Rauschsignale den Signalverlauf des gemessenen Signals häufig stark manipulieren. Ein naheliegender …"
0,"IT Schultz, M Ikkert, DMM Wand, DINT Vu","Implementierung und Evaluation eines Large Margin Estimation Algorithmus für HMMs",,"csl.uni-bremen.de","","https://www.csl.uni-bremen.de/cms/images/documents/publications/DA_MichaelIkkert.pdf","",551,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,4,,"Zusammenfassung Kontinuierliche Hidden-Markov-Modelle stellen für viele moderne Spracherkenner die zentrale Komponente dar. Diese Modelle werden aus Beispielaufzeichnungen von Sprache mit bekanntem Inhalt automatisch geschätzt. Da …"
0,"IT Schultz, M Georgi, DIC Amma","Eine Pilotstudie zur EMG-basierten Klassifikation von Fingergesten mittels Elektrodenarrays",,"","","","",552,"2020-11-06 21:29:44","CITATION","","","",,,,,0,0.00,0,3,,""
0,"IT Schultz, M Janke, DMM Wand","Spektrale Methoden zur EMG-basierten Erkennung lautloser Sprache",,"csl.uni-bremen.de","","https://csl.uni-bremen.de/cms/images/documents/publications/DA-Janke.pdf","",553,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,3,,"Diese Arbeit präsentiert neue Analysen und Resultate für die Spracherkennung mittels Elektromyographie (EMG), bei der die Aktivität der artikulatorischen Muskeln mittels geeigneter Elektroden direkt an der Hautoberfläche abgegriffen wird. Diese Technik …"
0,"IT Schultz, R Oxler, DIF Putze","Planung und Aufbau eines realistischen Fahrsimulators für die Untersuchung von kognitiven Dialogsystemen",,"csl.uni-bremen.de","","https://csl.uni-bremen.de/cms/images/documents/publications/studienarbeit_rikard_01.pdf","",554,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,3,,"Die vorliegende Studienarbeit beschäftigt sich mit dem Aufbau eines Fahrsimulators zu Forschungszwecken. Der Schwerpunkt liegt dabei bei der dafür notwendigen Software. Das Dokument beschreibt, welche Anforderungen an solch ein System gestellt werden, welche …"
0,"IT Schultz, S Werfel, DID Gehrig","Integration von Objektwissen in die automatische Erkennung menschlicher Bewegungen",,"csl.uni-bremen.de","","https://www.csl.uni-bremen.de/cms/images/documents/publications/BachelorarbeitWerfel.pdf","",555,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,3,,"Die vorliegende Arbeit beschäftigt sich mit der Nutzung von Objektwissen bei der automatischen Erkennung menschlicher Bewegungen. Dabei werden Kategorisierungen von menschlichen Bewegungen vorgestellt und die Rolle von Objektwissen für …"
0,"IT Schultz, D Adigüzel, DMM Wand","Signalinterpolation für Elektrodenarrays in der EMG-basierten Spracherkennung",,"csl.uni-bremen.de","","https://csl.uni-bremen.de/cms/images/documents/publications/BA-Adiguezel.pdf","",556,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,3,,"Spracherkennung bezeichnet das Ableiten von Sprache aus vom Menschen bzw. menschlichen Körper ausgesandten Biosignalen, die an der Spracherzeugung beteiligt sind. Das sind unter anderem akustische, visuelle, aber auch elektrische Signale. Letztere …"
0,"IT Schultz, L Alexandrov, DIM Janke, DMM Wand","F0-Erkennung bei elektromyographischer Sprachsynthese mit Elektrodenarrays",,"csl.uni-bremen.de","","https://www.csl.uni-bremen.de/cms/images/documents/publications/BA_Luben_Alexandrov.pdf","",557,"2020-11-06 21:29:44","PDF","","","",,,,,0,0.00,0,4,,"Zusammenfassung Elektromyographische Sprachsynthese bezeichnet den Prozess, bei dem elektrische Signale der artikulatorischen Gesichtsmuskeln gemessen werden und mit deren Hilfe Sprache synthetisiert wird. Eines der größten Probleme in der Sprachsynthese …"
